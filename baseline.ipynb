{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75d937c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\takumi_inoue\\projects\\github\\TakumiInoue0628\\manufacturing-dx-purchase-prediction\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import optuna\n",
    "from catboost import CatBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_fontja\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a721af",
   "metadata": {},
   "source": [
    "データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a440e75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "sample_submit = pd.read_csv(\"data/sample_submit.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d563d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# アンケートデータ分析\n",
    "def analyze_survey_data(df, survey_column, target_column, figsize=(5, 3)):\n",
    "    category_counts = df[survey_column].value_counts().sort_index()\n",
    "    plt.figure(figsize=figsize)\n",
    "    bars = plt.bar(category_counts.index, category_counts.values)\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(\n",
    "            x=bar.get_x() + bar.get_width() / 2,  # X座標 (棒の中央)\n",
    "            y=height,                            # Y座標 (棒の高さ)\n",
    "            s=f'{height}',                       # 表示するテキスト (整数で表示)\n",
    "            ha='center',                         # 水平方向の位置揃え (中央)\n",
    "            va='bottom'                          # 垂直方向の位置揃え (棒の下端に合わせる)\n",
    "        )\n",
    "    plt.xlabel(str(survey_column)+' 選択肢')\n",
    "    plt.ylabel('回答数')\n",
    "    plt.xticks(category_counts.index)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    average_purchase_by_survey = train.groupby(survey_column)[target_column].mean()\n",
    "    plt.figure(figsize=figsize)\n",
    "    bars = plt.bar(average_purchase_by_survey.index, average_purchase_by_survey.values)\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.3f}', va='bottom', ha='center')\n",
    "    plt.xlabel(str(survey_column)+' 選択肢')\n",
    "    plt.ylabel(str(target_column)+' 割合')\n",
    "    plt.xticks(average_purchase_by_survey.index) # X軸の目盛りをカテゴリ名に設定\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f9fa9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyze_survey_data(train, 'アンケート１１', '購入フラグ', figsize=(5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae42767f",
   "metadata": {},
   "source": [
    "データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32f96fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量エンジニアリング関数\n",
    "def feature_engineering(df):\n",
    "    # 財務指標の作成 (分母が0になる可能性を考慮)\n",
    "    df['自己資本比率'] = df['自己資本'] / (df['総資産'] + 1e-6)\n",
    "    df['売上高営業利益率'] = df['営業利益'] / (df['売上'] + 1e-6)\n",
    "    df['総資産回転率'] = df['売上'] / (df['総資産'] + 1e-6)\n",
    "    df['負債比率'] = df['負債'] / (df['自己資本'] + 1e-6)\n",
    "    df['従業員数_x_売上高営業利益率'] = df['従業員数'] * df['売上高営業利益率']\n",
    "    return df\n",
    "\n",
    "# カテゴリ変数のエンコード関数\n",
    "def encode_categorical(df, categorical_cols):\n",
    "    encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        encoder = LabelEncoder()\n",
    "        df[col] = encoder.fit_transform(df[col].astype(str))\n",
    "        encoders[col] = encoder\n",
    "    df = df.drop(columns=categorical_cols)\n",
    "    return df, encoders\n",
    "\n",
    "# 組織図を特徴量化する関数\n",
    "def org_chart_features(df, keyword_features = {\n",
    "    'dx_it': r'DX|デジタル|IT|情報システム',\n",
    "    'planning': r'経営企画|経営戦略|事業企画',\n",
    "    'quality': r'品質管理|品質保証|プロセス改善|業務改革',\n",
    "    'rd': r'R&D|研究開発|新技術',\n",
    "    'risk': r'リスク管理|内部監査|コンプライアンス',\n",
    "    'mfg': r'製造|工場|生産技術' # 製造業向け商材のため\n",
    "}):\n",
    "    df = df.fillna('')\n",
    "    org_df = pd.DataFrame()\n",
    "    # 組織の規模（行数）\n",
    "    org_df[df.name + '_line_count'] = df.apply(lambda x: len(x.split('\\n')))\n",
    "    # 組織単位数を（├, └, ┌の数）\n",
    "    org_df[df.name + '_unit_count']= df.str.count(r'[├└┌]')\n",
    "    # 特定部門の有無\n",
    "    for col_name, pattern in keyword_features.items():\n",
    "        org_df[df.name + \"_has_\" + col_name] = df.str.contains(pattern, case=False, na=False).astype(int)\n",
    "    return org_df\n",
    "\n",
    "# テキストデータの特徴量化関数（文章量）\n",
    "def text_length_features(df):\n",
    "    df = df.fillna('')\n",
    "    length = [len(text) for text in df]\n",
    "    length_df = pd.DataFrame(length, index=df.index, columns=[df.name + \"_length\"])\n",
    "    return length_df\n",
    "\n",
    "# テキストデータの特徴量化関数（ポジネガ出現率）\n",
    "def pos_neg_ratio(df, positive_words, negative_words):\n",
    "    df = df.fillna('')\n",
    "    pos_neg_features = []\n",
    "    for text in df:\n",
    "        pos_count = sum(text.count(word) for word in positive_words)\n",
    "        neg_count = sum(text.count(word) for word in negative_words)\n",
    "        total_count = len(text.split())\n",
    "        pos_ratio = pos_count / total_count if total_count > 0 else 0\n",
    "        neg_ratio = neg_count / total_count if total_count > 0 else 0\n",
    "        pos_neg_features.append([pos_ratio, neg_ratio])\n",
    "    pos_neg_df = pd.DataFrame(pos_neg_features, index=df.index, columns=[df.name + \"_pos_ratio\", df.name + \"_neg_ratio\"])\n",
    "    return pos_neg_df\n",
    "\n",
    "# テキストデータの特徴量化関数（TF-IDF）\n",
    "def tfidf_vectorization(df, max_features=100, ngram_range=(1, 2)):\n",
    "    df = df.fillna('')\n",
    "    vectorizer = TfidfVectorizer(max_features=max_features, ngram_range=ngram_range)\n",
    "    X_tfidf = vectorizer.fit_transform(df).toarray()\n",
    "    df_idfs = pd.DataFrame(X_tfidf, index=df.index)\n",
    "    df_idfs.columns = df.name + \"_\" + vectorizer.get_feature_names_out()\n",
    "    return df_idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0724353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xとyの分割\n",
    "target_col = '購入フラグ'\n",
    "X_train_df = train.drop(columns=[target_col])\n",
    "y_train_df = train[target_col]\n",
    "X_test_df = test.copy()\n",
    "\n",
    "# 学習・テストデータの結合\n",
    "X_train_df.index = \"train_\" + X_train_df.index.astype(str)\n",
    "X_test_df.index = \"test_\" + X_test_df.index.astype(str)\n",
    "X_df = pd.concat([X_train_df, X_test_df], axis=0)\n",
    "\n",
    "# 不要な列の削除\n",
    "drop_cols = ['企業ID', '企業名']\n",
    "X_df = X_df.drop(columns=drop_cols)\n",
    "\n",
    "# 指標の組み合わせによる新規指標の作成\n",
    "X_df = feature_engineering(X_df)\n",
    "\n",
    "# カテゴリ変数を数値にエンコード\n",
    "categorical_cols = ['業界', '上場種別', '特徴']\n",
    "X_df, encoders = encode_categorical(X_df, categorical_cols)\n",
    "\n",
    "# 組織図の特徴量化\n",
    "org_df = org_chart_features(X_df['組織図'])\n",
    "X_df = pd.concat([X_df, org_df], axis=1)\n",
    "X_df = X_df.drop(columns=['組織図'])\n",
    "\n",
    "# 企業概要テキストデータの特徴量化（TF-IDF）\n",
    "tfidf_df = tfidf_vectorization(X_df['企業概要'], max_features=100, ngram_range=(1, 2))\n",
    "X_df = pd.concat([X_df, tfidf_df], axis=1)\n",
    "X_df = X_df.drop(columns=['企業概要'])\n",
    "\n",
    "# 今後のDX展望テキストデータの特徴量化（文章量, ポジネガ出現率, TF-IDF）\n",
    "length_df = text_length_features(X_df['今後のDX展望'])\n",
    "posneg_df = pos_neg_ratio(X_df['今後のDX展望'],\n",
    "                          positive_words = [\n",
    "                            # 実行・推進\n",
    "                            '積極', '強化', '推進', '加速', '導入', '構築', '注力',\n",
    "                            # 拡大・投資\n",
    "                            '投資', '拡大', '新た', '創出',\n",
    "                            # 改善・高度化\n",
    "                            '最適化', '効率化', '自動化', '活用', '高度化',\n",
    "                            # 意欲・目標\n",
    "                            '図る', '目指す'],\n",
    "                           negative_words = [\n",
    "                            # 慎重・停滞\n",
    "                            '慎重', '限定', '停滞', '見直',\n",
    "                            # 課題・懸念\n",
    "                            '課題', '懸念', '困難', '不足', '負担', 'コスト', '難し',\n",
    "                            # 未確定\n",
    "                            '検討', '未定', '具体的ではない' ],)\n",
    "tfidf_df = tfidf_vectorization(X_df['今後のDX展望'], max_features=100, ngram_range=(1, 2))\n",
    "X_df = pd.concat([X_df, length_df, posneg_df, tfidf_df], axis=1)\n",
    "X_df = X_df.drop(columns=['今後のDX展望'])\n",
    "\n",
    "# 学習・テストデータの再分割\n",
    "X_train_df = X_df.loc[X_train_df.index].reset_index(drop=True)\n",
    "X_test_df = X_df.loc[X_test_df.index].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76da372",
   "metadata": {},
   "source": [
    "モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88d373f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from typing import Dict, Any, Callable\n",
    "\n",
    "# --- 添削・改善した最適化関数 ---\n",
    "def optimize_model(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    model_name: str,\n",
    "    params_base: Dict[str, Any],\n",
    "    define_params_func: Callable[[optuna.trial.Trial], Dict[str, Any]],\n",
    "    n_folds: int = 5,\n",
    "    n_trials: int = 50,\n",
    "    early_stopping_rounds: int = 50,\n",
    "    thresholds: np.ndarray = np.arange(0.1, 0.5, 0.01),\n",
    "    random_state: int = 42\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    指定されたモデルのハイパーパラメータをOptunaで最適化する汎用関数。\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): 学習データの特徴量\n",
    "        y_train (pd.Series): 学習データの目的変数\n",
    "        model_name (str): モデル名 ('lightgbm', 'xgboost', 'catboost'のいずれか)\n",
    "        params_base (Dict[str, Any]): 全ての試行で固定する基本パラメータ\n",
    "        define_params_func (Callable): Optunaのtrialオブジェクトを引数とし、\n",
    "                                     探索するパラメータ範囲を定義して辞書を返す関数\n",
    "        n_folds (int): 交差検証の分割数\n",
    "        n_trials (int): Optunaの試行回数\n",
    "        early_stopping_rounds (int):早期終了のラウンド数\n",
    "        thresholds (np.ndarray): F1スコアを計算するための閾値の範囲\n",
    "        random_state (int): 乱数シード\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: 最適化結果を含む辞書\n",
    "                        {'best_params': dict, 'best_score': float, 'study': optuna.study.Study}\n",
    "    \"\"\"\n",
    "    print(f\"--- Optimizing {model_name} ---\")\n",
    "\n",
    "    folds = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    def objective(trial: optuna.trial.Trial) -> float:\n",
    "        # trialごとに探索するパラメータを動的に生成する\n",
    "        if model_name == \"xgboost\":\n",
    "            params_base['early_stopping_rounds'] = early_stopping_rounds\n",
    "        params_opt = define_params_func(trial)\n",
    "        params = params_base | params_opt\n",
    "\n",
    "        oof_preds = np.zeros(X_train.shape[0])\n",
    "\n",
    "        for _, (train_idx, valid_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "            X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "            X_valid_fold, y_valid_fold = X_train.iloc[valid_idx], y_train.iloc[valid_idx]\n",
    "\n",
    "            if model_name == \"lightgbm\":\n",
    "                model = lgb.LGBMClassifier(**params)\n",
    "                model.fit(X_train_fold, y_train_fold,\n",
    "                            eval_set=[(X_valid_fold, y_valid_fold)],\n",
    "                            callbacks=[lgb.early_stopping(early_stopping_rounds, verbose=False)])\n",
    "            elif model_name == \"xgboost\":\n",
    "                model = xgb.XGBClassifier(**params)\n",
    "                model.fit(X_train_fold, y_train_fold,\n",
    "                            eval_set=[(X_valid_fold, y_valid_fold)],\n",
    "                            verbose=False)\n",
    "            elif model_name == \"catboost\":\n",
    "                model = CatBoostClassifier(**params)\n",
    "                model.fit(X_train_fold, y_train_fold,\n",
    "                            eval_set=[(X_valid_fold, y_valid_fold)],\n",
    "                            use_best_model=True,\n",
    "                            early_stopping_rounds=early_stopping_rounds,\n",
    "                            verbose=False)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported model_name: {model_name}\")\n",
    "\n",
    "            oof_preds[valid_idx] = model.predict_proba(X_valid_fold)[:, 1]\n",
    "\n",
    "        f1_scores = [f1_score(y_train, (oof_preds > t).astype(int)) for t in thresholds]\n",
    "        return np.max(f1_scores)\n",
    "\n",
    "    # Optunaによる最適化実行\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    print(\"\\n--- Optimization Finished ---\")\n",
    "    print(f\"Best trial for {model_name}:\")\n",
    "    best_trial = study.best_trial\n",
    "    print(f\"  Value (Best F1 Score): {best_trial.value:.5f}\")\n",
    "    print(\"  Best Params:\")\n",
    "    for key, value in best_trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "\n",
    "    # 最適パラメータと結果を返す\n",
    "    best_params = params_base | best_trial.params\n",
    "    \n",
    "    return {\n",
    "        'best_params': best_params,\n",
    "        'best_score': best_trial.value,\n",
    "        'study': study\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98dbc15",
   "metadata": {},
   "source": [
    "パラメータ最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f373604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-19 20:59:33,043] A new study created in memory with name: no-name-ee12aaf9-3881-4e20-b58a-a347ee1e57a6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Optimizing lightgbm ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-19 20:59:34,820] Trial 0 finished with value: 0.659400544959128 and parameters: {'learning_rate': 0.018896908448836163, 'num_leaves': 54, 'max_depth': 7, 'min_child_samples': 25, 'subsample': 0.6851203699147352, 'colsample_bytree': 0.7136102584817325, 'reg_alpha': 4.963581891432016e-07, 'reg_lambda': 3.058294256424744e-08}. Best is trial 0 with value: 0.659400544959128.\n",
      "[I 2025-10-19 20:59:35,840] Trial 1 finished with value: 0.6684636118598383 and parameters: {'learning_rate': 0.07573852409779788, 'num_leaves': 79, 'max_depth': 11, 'min_child_samples': 38, 'subsample': 0.7875249850471882, 'colsample_bytree': 0.9754521665200815, 'reg_alpha': 5.1610917668155544e-05, 'reg_lambda': 2.944498230528873e-08}. Best is trial 1 with value: 0.6684636118598383.\n",
      "[I 2025-10-19 20:59:38,282] Trial 2 finished with value: 0.6772486772486772 and parameters: {'learning_rate': 0.011890663162420042, 'num_leaves': 67, 'max_depth': 10, 'min_child_samples': 51, 'subsample': 0.6791292234275206, 'colsample_bytree': 0.9405229788602716, 'reg_alpha': 0.00025966736810563364, 'reg_lambda': 0.00029927843557682324}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 20:59:39,506] Trial 3 finished with value: 0.6252983293556086 and parameters: {'learning_rate': 0.07846834318389927, 'num_leaves': 36, 'max_depth': 10, 'min_child_samples': 9, 'subsample': 0.9229900988669418, 'colsample_bytree': 0.9116855765377674, 'reg_alpha': 7.298783214008998e-07, 'reg_lambda': 0.028797781735248423}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 20:59:40,219] Trial 4 finished with value: 0.6748768472906403 and parameters: {'learning_rate': 0.062428171077219895, 'num_leaves': 51, 'max_depth': 3, 'min_child_samples': 35, 'subsample': 0.6775825229642249, 'colsample_bytree': 0.9797862354561657, 'reg_alpha': 9.049598356014695e-06, 'reg_lambda': 5.16294256805441e-08}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 20:59:40,970] Trial 5 finished with value: 0.6715686274509803 and parameters: {'learning_rate': 0.06446498026957057, 'num_leaves': 43, 'max_depth': 4, 'min_child_samples': 97, 'subsample': 0.8404051536865019, 'colsample_bytree': 0.858312078801753, 'reg_alpha': 0.8102331219808181, 'reg_lambda': 1.9312970222493446e-07}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 20:59:43,168] Trial 6 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.010074690734744924, 'num_leaves': 61, 'max_depth': 12, 'min_child_samples': 60, 'subsample': 0.8217718519462494, 'colsample_bytree': 0.9497006502796209, 'reg_alpha': 0.001741950077050068, 'reg_lambda': 0.0033237426736346916}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 20:59:45,225] Trial 7 finished with value: 0.65625 and parameters: {'learning_rate': 0.015949629572655357, 'num_leaves': 50, 'max_depth': 3, 'min_child_samples': 30, 'subsample': 0.7893211611947906, 'colsample_bytree': 0.6538726145062587, 'reg_alpha': 5.204369737954305, 'reg_lambda': 0.019939821774899714}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 20:59:46,869] Trial 8 finished with value: 0.651685393258427 and parameters: {'learning_rate': 0.029504849790656804, 'num_leaves': 41, 'max_depth': 8, 'min_child_samples': 14, 'subsample': 0.7380209693905263, 'colsample_bytree': 0.6209987877323616, 'reg_alpha': 2.5800348446724198e-08, 'reg_lambda': 2.543538410713275e-05}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 20:59:48,491] Trial 9 finished with value: 0.6600985221674877 and parameters: {'learning_rate': 0.020913939089359974, 'num_leaves': 80, 'max_depth': 11, 'min_child_samples': 41, 'subsample': 0.7173604158887228, 'colsample_bytree': 0.9850900700582301, 'reg_alpha': 2.575173686055862, 'reg_lambda': 1.1625305491647955e-08}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 20:59:49,503] Trial 10 finished with value: 0.6734177215189874 and parameters: {'learning_rate': 0.04002991734965059, 'num_leaves': 26, 'max_depth': 8, 'min_child_samples': 69, 'subsample': 0.6060289490897927, 'colsample_bytree': 0.7879477657847773, 'reg_alpha': 0.007211238598861871, 'reg_lambda': 7.404581007032784}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 20:59:50,209] Trial 11 finished with value: 0.6698564593301436 and parameters: {'learning_rate': 0.04930641097070058, 'num_leaves': 67, 'max_depth': 5, 'min_child_samples': 74, 'subsample': 0.6066841367986353, 'colsample_bytree': 0.8848276856953163, 'reg_alpha': 1.5544677528609953e-05, 'reg_lambda': 1.3408070484009516e-05}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 20:59:52,207] Trial 12 finished with value: 0.6682808716707022 and parameters: {'learning_rate': 0.01134955330226726, 'num_leaves': 66, 'max_depth': 6, 'min_child_samples': 48, 'subsample': 0.6629161681960962, 'colsample_bytree': 0.8164634544589517, 'reg_alpha': 0.015072936141617463, 'reg_lambda': 3.955845728356084e-06}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 20:59:53,320] Trial 13 finished with value: 0.6649076517150396 and parameters: {'learning_rate': 0.029497587066197286, 'num_leaves': 58, 'max_depth': 9, 'min_child_samples': 55, 'subsample': 0.9861952055206891, 'colsample_bytree': 0.928979682063758, 'reg_alpha': 9.77721941162945e-05, 'reg_lambda': 1.8163807613450305}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 20:59:54,036] Trial 14 finished with value: 0.6715686274509803 and parameters: {'learning_rate': 0.04453271426707003, 'num_leaves': 71, 'max_depth': 3, 'min_child_samples': 83, 'subsample': 0.6570831512936652, 'colsample_bytree': 0.8159291762681771, 'reg_alpha': 3.230523827691395e-06, 'reg_lambda': 0.00038002427776076596}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 20:59:56,020] Trial 15 finished with value: 0.6742857142857143 and parameters: {'learning_rate': 0.013843830312823819, 'num_leaves': 21, 'max_depth': 6, 'min_child_samples': 28, 'subsample': 0.7479685513382784, 'colsample_bytree': 0.9973366586794332, 'reg_alpha': 0.0006859206422861424, 'reg_lambda': 0.00028463469047930695}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 20:59:56,583] Trial 16 finished with value: 0.6568627450980392 and parameters: {'learning_rate': 0.09490437504236077, 'num_leaves': 46, 'max_depth': 9, 'min_child_samples': 44, 'subsample': 0.8696826063360195, 'colsample_bytree': 0.8681477520148668, 'reg_alpha': 0.08550838057428917, 'reg_lambda': 7.969474865030434e-07}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 20:59:57,270] Trial 17 finished with value: 0.6684210526315789 and parameters: {'learning_rate': 0.057312946119794705, 'num_leaves': 35, 'max_depth': 12, 'min_child_samples': 62, 'subsample': 0.6998969242077744, 'colsample_bytree': 0.7761263843988716, 'reg_alpha': 1.7994220503114356e-07, 'reg_lambda': 0.1944544675225471}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 20:59:58,722] Trial 18 finished with value: 0.6592797783933518 and parameters: {'learning_rate': 0.022886708785173522, 'num_leaves': 59, 'max_depth': 10, 'min_child_samples': 19, 'subsample': 0.6426103439385938, 'colsample_bytree': 0.9373362147513538, 'reg_alpha': 2.0241069007255847e-05, 'reg_lambda': 8.906695078993957e-05}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 20:59:59,638] Trial 19 finished with value: 0.6495726495726496 and parameters: {'learning_rate': 0.033828969588730017, 'num_leaves': 74, 'max_depth': 5, 'min_child_samples': 34, 'subsample': 0.7530278198394418, 'colsample_bytree': 0.7353272640923187, 'reg_alpha': 0.0003674419925954992, 'reg_lambda': 7.600894147661501e-07}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 21:00:00,625] Trial 20 finished with value: 0.6702412868632708 and parameters: {'learning_rate': 0.025305314118039417, 'num_leaves': 51, 'max_depth': 7, 'min_child_samples': 51, 'subsample': 0.6369477430853233, 'colsample_bytree': 0.9023113329644197, 'reg_alpha': 1.1202166002836209e-08, 'reg_lambda': 0.002020856975485194}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 21:00:02,717] Trial 21 finished with value: 0.6720867208672087 and parameters: {'learning_rate': 0.01359883195780183, 'num_leaves': 20, 'max_depth': 5, 'min_child_samples': 23, 'subsample': 0.7554711631989582, 'colsample_bytree': 0.9981240356410338, 'reg_alpha': 0.00022655411618846465, 'reg_lambda': 0.00039216470795903967}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 21:00:04,486] Trial 22 finished with value: 0.6722222222222223 and parameters: {'learning_rate': 0.014371088180181124, 'num_leaves': 29, 'max_depth': 6, 'min_child_samples': 32, 'subsample': 0.7099149201411097, 'colsample_bytree': 0.963583182784365, 'reg_alpha': 0.0012904557482395402, 'reg_lambda': 7.898641944858686e-05}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 21:00:06,770] Trial 23 finished with value: 0.6579634464751958 and parameters: {'learning_rate': 0.01668336675086546, 'num_leaves': 65, 'max_depth': 4, 'min_child_samples': 7, 'subsample': 0.6731186652489054, 'colsample_bytree': 0.9957779674141615, 'reg_alpha': 4.5739404696973145e-06, 'reg_lambda': 3.130135251639526e-06}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 21:00:08,579] Trial 24 finished with value: 0.6630434782608695 and parameters: {'learning_rate': 0.012593916179187283, 'num_leaves': 20, 'max_depth': 6, 'min_child_samples': 42, 'subsample': 0.7346004555288007, 'colsample_bytree': 0.9489619564139272, 'reg_alpha': 0.06281963584809792, 'reg_lambda': 0.0013172258868013593}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 21:00:10,774] Trial 25 finished with value: 0.6684636118598383 and parameters: {'learning_rate': 0.010006969626929145, 'num_leaves': 36, 'max_depth': 4, 'min_child_samples': 27, 'subsample': 0.7716641515864123, 'colsample_bytree': 0.8492290049381601, 'reg_alpha': 0.0010784489041059443, 'reg_lambda': 0.020795124848741495}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 21:00:12,836] Trial 26 finished with value: 0.6685082872928176 and parameters: {'learning_rate': 0.017292193128656902, 'num_leaves': 54, 'max_depth': 9, 'min_child_samples': 17, 'subsample': 0.7119025591644811, 'colsample_bytree': 0.9174047807265161, 'reg_alpha': 4.004349506382928e-06, 'reg_lambda': 0.12871841671125883}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 21:00:13,507] Trial 27 finished with value: 0.675603217158177 and parameters: {'learning_rate': 0.036278756649650724, 'num_leaves': 30, 'max_depth': 3, 'min_child_samples': 57, 'subsample': 0.6339476677574273, 'colsample_bytree': 0.9661724530297171, 'reg_alpha': 0.007358974206335734, 'reg_lambda': 1.629415457020896e-07}. Best is trial 2 with value: 0.6772486772486772.\n",
      "[I 2025-10-19 21:00:14,551] Trial 28 finished with value: 0.6861313868613139 and parameters: {'learning_rate': 0.03619544118688672, 'num_leaves': 46, 'max_depth': 3, 'min_child_samples': 73, 'subsample': 0.6386263605915126, 'colsample_bytree': 0.956195623166564, 'reg_alpha': 0.00596055345803014, 'reg_lambda': 1.4296575005918243e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:15,449] Trial 29 finished with value: 0.6788511749347258 and parameters: {'learning_rate': 0.03529800735939377, 'num_leaves': 44, 'max_depth': 7, 'min_child_samples': 71, 'subsample': 0.6161864190192867, 'colsample_bytree': 0.8954476085127627, 'reg_alpha': 0.18394078172306805, 'reg_lambda': 2.8109534380007385e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:16,520] Trial 30 finished with value: 0.675392670157068 and parameters: {'learning_rate': 0.026486764625376188, 'num_leaves': 47, 'max_depth': 7, 'min_child_samples': 83, 'subsample': 0.6004894661839117, 'colsample_bytree': 0.8889232898508456, 'reg_alpha': 0.2916046938732275, 'reg_lambda': 4.807601706665646e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:17,387] Trial 31 finished with value: 0.673469387755102 and parameters: {'learning_rate': 0.036243179703213606, 'num_leaves': 40, 'max_depth': 4, 'min_child_samples': 73, 'subsample': 0.6252069804200209, 'colsample_bytree': 0.9535462472245986, 'reg_alpha': 0.009010377095370387, 'reg_lambda': 1.1507870079598344e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:18,117] Trial 32 finished with value: 0.671957671957672 and parameters: {'learning_rate': 0.04809844618750381, 'num_leaves': 33, 'max_depth': 3, 'min_child_samples': 65, 'subsample': 0.6315597578832376, 'colsample_bytree': 0.9256499728034224, 'reg_alpha': 0.04113558718952947, 'reg_lambda': 1.78482999903807e-08}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:19,057] Trial 33 finished with value: 0.6804123711340206 and parameters: {'learning_rate': 0.03800450487459725, 'num_leaves': 31, 'max_depth': 10, 'min_child_samples': 82, 'subsample': 0.6838384344717935, 'colsample_bytree': 0.8415326785103928, 'reg_alpha': 0.3536436674558263, 'reg_lambda': 1.0197318435008027e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:20,001] Trial 34 finished with value: 0.6779661016949152 and parameters: {'learning_rate': 0.040483734649395295, 'num_leaves': 39, 'max_depth': 10, 'min_child_samples': 83, 'subsample': 0.6869288606984173, 'colsample_bytree': 0.8553217666856393, 'reg_alpha': 0.26758771195900266, 'reg_lambda': 4.021645755846857e-06}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:20,923] Trial 35 finished with value: 0.6699029126213593 and parameters: {'learning_rate': 0.040283317783163, 'num_leaves': 44, 'max_depth': 11, 'min_child_samples': 85, 'subsample': 0.6861667190225813, 'colsample_bytree': 0.8336632178998343, 'reg_alpha': 0.3349625082094443, 'reg_lambda': 4.932865115827874e-08}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:21,679] Trial 36 finished with value: 0.671875 and parameters: {'learning_rate': 0.05259152591650865, 'num_leaves': 38, 'max_depth': 10, 'min_child_samples': 91, 'subsample': 0.6562109135709584, 'colsample_bytree': 0.8809896791791612, 'reg_alpha': 1.2090280487053868, 'reg_lambda': 2.271964868788367e-06}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:22,481] Trial 37 finished with value: 0.6632124352331606 and parameters: {'learning_rate': 0.04344695129388787, 'num_leaves': 26, 'max_depth': 8, 'min_child_samples': 76, 'subsample': 0.6909554263387299, 'colsample_bytree': 0.7573164968930985, 'reg_alpha': 0.27792823327217886, 'reg_lambda': 3.076047677392043e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:23,113] Trial 38 finished with value: 0.6735751295336787 and parameters: {'learning_rate': 0.06963795600361786, 'num_leaves': 31, 'max_depth': 11, 'min_child_samples': 100, 'subsample': 0.8176366019410494, 'colsample_bytree': 0.8387238729730289, 'reg_alpha': 0.14362530301083515, 'reg_lambda': 5.6988849418074495e-08}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:24,052] Trial 39 finished with value: 0.659846547314578 and parameters: {'learning_rate': 0.03215837252436143, 'num_leaves': 41, 'max_depth': 9, 'min_child_samples': 91, 'subsample': 0.8862276407219263, 'colsample_bytree': 0.899033201496868, 'reg_alpha': 1.104365456024189, 'reg_lambda': 7.700215359024904e-06}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:25,201] Trial 40 finished with value: 0.6359223300970874 and parameters: {'learning_rate': 0.027925672976431053, 'num_leaves': 54, 'max_depth': 12, 'min_child_samples': 79, 'subsample': 0.6549111464007118, 'colsample_bytree': 0.6874480462452809, 'reg_alpha': 9.114454935830873, 'reg_lambda': 1.4131964002634397e-06}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:26,047] Trial 41 finished with value: 0.6703910614525139 and parameters: {'learning_rate': 0.035459816804747725, 'num_leaves': 47, 'max_depth': 10, 'min_child_samples': 69, 'subsample': 0.6188765695797354, 'colsample_bytree': 0.8654554104722998, 'reg_alpha': 0.024532978399143136, 'reg_lambda': 1.0311409798029393e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:27,203] Trial 42 finished with value: 0.6775067750677507 and parameters: {'learning_rate': 0.02351733717779405, 'num_leaves': 50, 'max_depth': 10, 'min_child_samples': 69, 'subsample': 0.6823394958295455, 'colsample_bytree': 0.9099186322597872, 'reg_alpha': 0.0030271574416382506, 'reg_lambda': 3.831061608051753e-05}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:28,172] Trial 43 finished with value: 0.6649616368286445 and parameters: {'learning_rate': 0.02314331723279907, 'num_leaves': 44, 'max_depth': 11, 'min_child_samples': 90, 'subsample': 0.6782816756268962, 'colsample_bytree': 0.8204684543525961, 'reg_alpha': 0.0029013680662204537, 'reg_lambda': 5.112704084796337e-05}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:29,069] Trial 44 finished with value: 0.6594594594594595 and parameters: {'learning_rate': 0.04036094678213915, 'num_leaves': 49, 'max_depth': 10, 'min_child_samples': 68, 'subsample': 0.719344599207271, 'colsample_bytree': 0.873824612022414, 'reg_alpha': 0.6551483187192257, 'reg_lambda': 1.2768307053632197e-05}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:30,193] Trial 45 finished with value: 0.6717557251908397 and parameters: {'learning_rate': 0.019730926949704106, 'num_leaves': 39, 'max_depth': 8, 'min_child_samples': 80, 'subsample': 0.6481329920806717, 'colsample_bytree': 0.9141315141988249, 'reg_alpha': 0.004796471639504405, 'reg_lambda': 2.946902601889083e-08}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:31,102] Trial 46 finished with value: 0.6770025839793282 and parameters: {'learning_rate': 0.03163661604574884, 'num_leaves': 53, 'max_depth': 9, 'min_child_samples': 72, 'subsample': 0.6685253528913581, 'colsample_bytree': 0.8549956192329489, 'reg_alpha': 0.023097991021520263, 'reg_lambda': 4.1483606843851023e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:31,979] Trial 47 finished with value: 0.624 and parameters: {'learning_rate': 0.02329588826666574, 'num_leaves': 37, 'max_depth': 11, 'min_child_samples': 87, 'subsample': 0.6219763767824739, 'colsample_bytree': 0.8986699494444217, 'reg_alpha': 3.047437249651908, 'reg_lambda': 4.976830276777028e-06}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:32,869] Trial 48 finished with value: 0.6556603773584906 and parameters: {'learning_rate': 0.02979625902986804, 'num_leaves': 42, 'max_depth': 9, 'min_child_samples': 96, 'subsample': 0.7316304484566881, 'colsample_bytree': 0.7941993368293371, 'reg_alpha': 0.19889435425068996, 'reg_lambda': 2.4249453628046928e-05}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:33,522] Trial 49 finished with value: 0.6702702702702703 and parameters: {'learning_rate': 0.056696490886550835, 'num_leaves': 57, 'max_depth': 12, 'min_child_samples': 62, 'subsample': 0.7769677970865561, 'colsample_bytree': 0.8441664677443836, 'reg_alpha': 0.08555812127563545, 'reg_lambda': 1.0286027485272498e-08}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:34,380] Trial 50 finished with value: 0.6576819407008087 and parameters: {'learning_rate': 0.044709513373401545, 'num_leaves': 26, 'max_depth': 10, 'min_child_samples': 75, 'subsample': 0.7011908065427418, 'colsample_bytree': 0.9344292773327731, 'reg_alpha': 2.7443933912668257, 'reg_lambda': 1.3908359878654043e-06}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:35,136] Trial 51 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.03865963171725387, 'num_leaves': 62, 'max_depth': 10, 'min_child_samples': 58, 'subsample': 0.690201715499387, 'colsample_bytree': 0.9745396869228948, 'reg_alpha': 0.00016798712877006555, 'reg_lambda': 0.00020925426549699247}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:35,907] Trial 52 finished with value: 0.6788511749347258 and parameters: {'learning_rate': 0.048855893276097205, 'num_leaves': 76, 'max_depth': 11, 'min_child_samples': 79, 'subsample': 0.6716608931119027, 'colsample_bytree': 0.9397504126327509, 'reg_alpha': 0.0005547815671905094, 'reg_lambda': 0.004480812752936952}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:36,636] Trial 53 finished with value: 0.670076726342711 and parameters: {'learning_rate': 0.048873734386766496, 'num_leaves': 45, 'max_depth': 11, 'min_child_samples': 78, 'subsample': 0.6097585575038642, 'colsample_bytree': 0.9183736417136263, 'reg_alpha': 4.8272153478412455e-05, 'reg_lambda': 0.006314612317670238}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:37,286] Trial 54 finished with value: 0.6648351648351648 and parameters: {'learning_rate': 0.060618549052757244, 'num_leaves': 75, 'max_depth': 11, 'min_child_samples': 66, 'subsample': 0.9944946273547074, 'colsample_bytree': 0.9444376558121078, 'reg_alpha': 0.003537300365912922, 'reg_lambda': 0.006623576127305327}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:38,087] Trial 55 finished with value: 0.6766169154228856 and parameters: {'learning_rate': 0.04351767903372968, 'num_leaves': 48, 'max_depth': 12, 'min_child_samples': 80, 'subsample': 0.961258777224085, 'colsample_bytree': 0.8818131187907636, 'reg_alpha': 0.0008198793813707656, 'reg_lambda': 0.0008341062382327863}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:38,673] Trial 56 finished with value: 0.6732673267326733 and parameters: {'learning_rate': 0.08231502657183075, 'num_leaves': 34, 'max_depth': 9, 'min_child_samples': 71, 'subsample': 0.6680004912602119, 'colsample_bytree': 0.8109639923798905, 'reg_alpha': 0.01710364386384627, 'reg_lambda': 7.090383413471612e-08}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:39,384] Trial 57 finished with value: 0.6702412868632708 and parameters: {'learning_rate': 0.05170579349245008, 'num_leaves': 52, 'max_depth': 10, 'min_child_samples': 87, 'subsample': 0.6450735921577226, 'colsample_bytree': 0.9017384162841192, 'reg_alpha': 0.5711621361263813, 'reg_lambda': 1.8289354729534098e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:40,302] Trial 58 finished with value: 0.6821705426356589 and parameters: {'learning_rate': 0.03326592979199206, 'num_leaves': 56, 'max_depth': 8, 'min_child_samples': 83, 'subsample': 0.6984537982089478, 'colsample_bytree': 0.8621386565935881, 'reg_alpha': 0.00047746038556414227, 'reg_lambda': 9.189292366371507e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:41,102] Trial 59 finished with value: 0.6613756613756614 and parameters: {'learning_rate': 0.033149119874681894, 'num_leaves': 72, 'max_depth': 7, 'min_child_samples': 96, 'subsample': 0.6994294094452739, 'colsample_bytree': 0.826096047045066, 'reg_alpha': 3.017439513083211e-05, 'reg_lambda': 9.51387133653028e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:41,965] Trial 60 finished with value: 0.6732186732186732 and parameters: {'learning_rate': 0.03869347408814799, 'num_leaves': 76, 'max_depth': 8, 'min_child_samples': 83, 'subsample': 0.7254838943901901, 'colsample_bytree': 0.859067777856503, 'reg_alpha': 0.00043179725741352066, 'reg_lambda': 2.9199959776266946e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:43,086] Trial 61 finished with value: 0.6632653061224489 and parameters: {'learning_rate': 0.025192732110137603, 'num_leaves': 56, 'max_depth': 10, 'min_child_samples': 75, 'subsample': 0.6775207741687075, 'colsample_bytree': 0.8701321898479861, 'reg_alpha': 0.00010944668443428804, 'reg_lambda': 7.458801842368923e-06}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:44,023] Trial 62 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.029639107610865374, 'num_leaves': 62, 'max_depth': 6, 'min_child_samples': 82, 'subsample': 0.6619779499901505, 'colsample_bytree': 0.893163360365753, 'reg_alpha': 0.0026623215437382598, 'reg_lambda': 2.5200476511718716e-06}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:44,926] Trial 63 finished with value: 0.6649746192893401 and parameters: {'learning_rate': 0.035467508930489784, 'num_leaves': 50, 'max_depth': 5, 'min_child_samples': 87, 'subsample': 0.6484330575612473, 'colsample_bytree': 0.960119351783091, 'reg_alpha': 0.00048701918457310674, 'reg_lambda': 6.484977874762773e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:45,941] Trial 64 finished with value: 0.6770833333333334 and parameters: {'learning_rate': 0.027587600612288026, 'num_leaves': 43, 'max_depth': 9, 'min_child_samples': 77, 'subsample': 0.7469381483712091, 'colsample_bytree': 0.7781693736846904, 'reg_alpha': 0.046625491087471965, 'reg_lambda': 0.06791293639694153}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:46,722] Trial 65 finished with value: 0.684863523573201 and parameters: {'learning_rate': 0.045130875982226294, 'num_leaves': 79, 'max_depth': 10, 'min_child_samples': 64, 'subsample': 0.6153429366273511, 'colsample_bytree': 0.9347744657145454, 'reg_alpha': 0.0014322941682141305, 'reg_lambda': 2.288695323987476e-05}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:47,511] Trial 66 finished with value: 0.6684491978609626 and parameters: {'learning_rate': 0.04580488515713568, 'num_leaves': 78, 'max_depth': 8, 'min_child_samples': 62, 'subsample': 0.6157818486559801, 'colsample_bytree': 0.9330391253602369, 'reg_alpha': 0.0017048450016100278, 'reg_lambda': 0.739487842118737}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:48,324] Trial 67 finished with value: 0.6754617414248021 and parameters: {'learning_rate': 0.04156351375778479, 'num_leaves': 80, 'max_depth': 11, 'min_child_samples': 72, 'subsample': 0.6375799781068838, 'colsample_bytree': 0.9787959766377458, 'reg_alpha': 8.844146492534757e-05, 'reg_lambda': 1.6420331025576693e-05}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:49,066] Trial 68 finished with value: 0.6618004866180048 and parameters: {'learning_rate': 0.05383844230646749, 'num_leaves': 69, 'max_depth': 7, 'min_child_samples': 66, 'subsample': 0.6029454896781539, 'colsample_bytree': 0.9446854901768275, 'reg_alpha': 0.011919079416910578, 'reg_lambda': 0.00017284992162216076}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:49,923] Trial 69 finished with value: 0.6650124069478908 and parameters: {'learning_rate': 0.038017943119048124, 'num_leaves': 72, 'max_depth': 11, 'min_child_samples': 53, 'subsample': 0.6293893502173405, 'colsample_bytree': 0.8053587992207917, 'reg_alpha': 0.0002804838344016564, 'reg_lambda': 2.546667573698118e-08}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:50,933] Trial 70 finished with value: 0.6714975845410628 and parameters: {'learning_rate': 0.034261242815720606, 'num_leaves': 77, 'max_depth': 8, 'min_child_samples': 93, 'subsample': 0.7092720322637205, 'colsample_bytree': 0.8307292735960936, 'reg_alpha': 0.09844919848684394, 'reg_lambda': 1.5479333807275096e-06}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:51,753] Trial 71 finished with value: 0.679144385026738 and parameters: {'learning_rate': 0.042298249699090115, 'num_leaves': 24, 'max_depth': 10, 'min_child_samples': 70, 'subsample': 0.6847912658675489, 'colsample_bytree': 0.912912486595385, 'reg_alpha': 0.0008373553472038331, 'reg_lambda': 3.048989349642618e-05}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:52,477] Trial 72 finished with value: 0.6635514018691588 and parameters: {'learning_rate': 0.04795763006563727, 'num_leaves': 22, 'max_depth': 10, 'min_child_samples': 85, 'subsample': 0.6628351564838597, 'colsample_bytree': 0.6014797194691412, 'reg_alpha': 0.000736510036663383, 'reg_lambda': 0.00012563397114156278}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:53,319] Trial 73 finished with value: 0.6751918158567775 and parameters: {'learning_rate': 0.03737354042341536, 'num_leaves': 28, 'max_depth': 9, 'min_child_samples': 80, 'subsample': 0.6980166105096708, 'colsample_bytree': 0.918427672773517, 'reg_alpha': 0.0013010142588007988, 'reg_lambda': 0.0006190645742202691}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:54,074] Trial 74 finished with value: 0.6699266503667481 and parameters: {'learning_rate': 0.041940475431101056, 'num_leaves': 22, 'max_depth': 10, 'min_child_samples': 64, 'subsample': 0.617150173806905, 'colsample_bytree': 0.8499332956441934, 'reg_alpha': 0.005796516818198708, 'reg_lambda': 2.7371356797909703e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:54,903] Trial 75 finished with value: 0.6648501362397821 and parameters: {'learning_rate': 0.04580330616887668, 'num_leaves': 24, 'max_depth': 11, 'min_child_samples': 75, 'subsample': 0.6364043607442519, 'colsample_bytree': 0.88143114116646, 'reg_alpha': 1.2102654072751058, 'reg_lambda': 6.610159468828569e-06}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:55,503] Trial 76 finished with value: 0.6784810126582278 and parameters: {'learning_rate': 0.06728837715726861, 'num_leaves': 65, 'max_depth': 12, 'min_child_samples': 72, 'subsample': 0.6488724962253369, 'colsample_bytree': 0.9279898266176685, 'reg_alpha': 0.4653464183594746, 'reg_lambda': 9.517653232179753e-08}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:56,103] Trial 77 finished with value: 0.6700507614213198 and parameters: {'learning_rate': 0.06674443014031499, 'num_leaves': 64, 'max_depth': 12, 'min_child_samples': 71, 'subsample': 0.6259637257270132, 'colsample_bytree': 0.9554723422167627, 'reg_alpha': 0.00014791355723912377, 'reg_lambda': 1.117463526228848e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:56,631] Trial 78 finished with value: 0.6519337016574586 and parameters: {'learning_rate': 0.07539986411371791, 'num_leaves': 69, 'max_depth': 12, 'min_child_samples': 59, 'subsample': 0.6525909295856823, 'colsample_bytree': 0.9248188634524585, 'reg_alpha': 5.674028892166359e-07, 'reg_lambda': 5.0557326306281646e-08}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:57,197] Trial 79 finished with value: 0.6528735632183909 and parameters: {'learning_rate': 0.09054637325232169, 'num_leaves': 68, 'max_depth': 12, 'min_child_samples': 68, 'subsample': 0.6729880571649112, 'colsample_bytree': 0.9077032655419921, 'reg_alpha': 0.03419904655812433, 'reg_lambda': 1.660528420623897e-08}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:58,219] Trial 80 finished with value: 0.6410256410256411 and parameters: {'learning_rate': 0.03087877749413691, 'num_leaves': 60, 'max_depth': 5, 'min_child_samples': 49, 'subsample': 0.6421682912811906, 'colsample_bytree': 0.9702983950028243, 'reg_alpha': 5.7748400589746645, 'reg_lambda': 1.8202333949528547e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:00:59,019] Trial 81 finished with value: 0.672 and parameters: {'learning_rate': 0.056124240379681126, 'num_leaves': 33, 'max_depth': 11, 'min_child_samples': 77, 'subsample': 0.681616616711354, 'colsample_bytree': 0.9386937309516624, 'reg_alpha': 0.4506200180095556, 'reg_lambda': 3.3893101136906436e-06}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:01:00,143] Trial 82 finished with value: 0.675603217158177 and parameters: {'learning_rate': 0.033770993714179236, 'num_leaves': 31, 'max_depth': 10, 'min_child_samples': 82, 'subsample': 0.6002445882438087, 'colsample_bytree': 0.8891206561296185, 'reg_alpha': 0.1328242978312035, 'reg_lambda': 4.8697644328052e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:01:00,959] Trial 83 finished with value: 0.6599496221662469 and parameters: {'learning_rate': 0.05021508286982087, 'num_leaves': 74, 'max_depth': 4, 'min_child_samples': 85, 'subsample': 0.6608292948755273, 'colsample_bytree': 0.926749439671473, 'reg_alpha': 1.8275404113369702, 'reg_lambda': 9.793830680701177e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:01:01,627] Trial 84 finished with value: 0.6650485436893204 and parameters: {'learning_rate': 0.060028208840278104, 'num_leaves': 46, 'max_depth': 11, 'min_child_samples': 73, 'subsample': 0.6886122480180897, 'colsample_bytree': 0.9834001425101473, 'reg_alpha': 0.3056355773339502, 'reg_lambda': 1.2742795477669937e-05}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:01:02,406] Trial 85 finished with value: 0.6681715575620768 and parameters: {'learning_rate': 0.03953592226541279, 'num_leaves': 39, 'max_depth': 9, 'min_child_samples': 70, 'subsample': 0.7104189595160643, 'colsample_bytree': 0.8606806231091653, 'reg_alpha': 0.0003800528934702013, 'reg_lambda': 3.9641487753261705e-05}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:01:03,172] Trial 86 finished with value: 0.6858638743455497 and parameters: {'learning_rate': 0.04128513128753056, 'num_leaves': 80, 'max_depth': 10, 'min_child_samples': 89, 'subsample': 0.8622072330664178, 'colsample_bytree': 0.9524316890789641, 'reg_alpha': 0.16815413217741781, 'reg_lambda': 7.642750138414731e-08}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:01:03,929] Trial 87 finished with value: 0.6563307493540051 and parameters: {'learning_rate': 0.042179837556229866, 'num_leaves': 78, 'max_depth': 12, 'min_child_samples': 56, 'subsample': 0.807549815869512, 'colsample_bytree': 0.9893421976581566, 'reg_alpha': 0.0019132712335198359, 'reg_lambda': 7.598192715129844e-08}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:01:04,808] Trial 88 finished with value: 0.6505376344086021 and parameters: {'learning_rate': 0.03672578432448778, 'num_leaves': 80, 'max_depth': 10, 'min_child_samples': 67, 'subsample': 0.8585956681099404, 'colsample_bytree': 0.9507955624866015, 'reg_alpha': 0.008871809365414604, 'reg_lambda': 3.971656820180896e-08}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:01:05,553] Trial 89 finished with value: 0.6583541147132169 and parameters: {'learning_rate': 0.04563989227012368, 'num_leaves': 73, 'max_depth': 11, 'min_child_samples': 63, 'subsample': 0.9177111050394572, 'colsample_bytree': 0.9614854271086021, 'reg_alpha': 0.8923999635085402, 'reg_lambda': 1.2365850411337743e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:01:06,456] Trial 90 finished with value: 0.6838046272493573 and parameters: {'learning_rate': 0.03259111220305879, 'num_leaves': 76, 'max_depth': 9, 'min_child_samples': 88, 'subsample': 0.8532509030043661, 'colsample_bytree': 0.936608496614485, 'reg_alpha': 1.7983919051322997e-07, 'reg_lambda': 2.0240728873630882e-08}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:01:07,423] Trial 91 finished with value: 0.6751269035532995 and parameters: {'learning_rate': 0.032230539265685774, 'num_leaves': 78, 'max_depth': 9, 'min_child_samples': 90, 'subsample': 0.8351982152269429, 'colsample_bytree': 0.9069984897838008, 'reg_alpha': 0.16161129225113102, 'reg_lambda': 2.4632517625099993e-08}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:01:08,303] Trial 92 finished with value: 0.671875 and parameters: {'learning_rate': 0.03524018111321215, 'num_leaves': 76, 'max_depth': 9, 'min_child_samples': 93, 'subsample': 0.88271731117095, 'colsample_bytree': 0.9372477769456524, 'reg_alpha': 0.0006027105555380372, 'reg_lambda': 8.28355610381253e-08}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:01:09,278] Trial 93 finished with value: 0.672 and parameters: {'learning_rate': 0.02861154133844157, 'num_leaves': 71, 'max_depth': 8, 'min_child_samples': 78, 'subsample': 0.8603634192529572, 'colsample_bytree': 0.9262341332729563, 'reg_alpha': 1.2790093714620314e-07, 'reg_lambda': 1.342313203587725e-08}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:01:10,286] Trial 94 finished with value: 0.6720430107526881 and parameters: {'learning_rate': 0.030650163311480058, 'num_leaves': 76, 'max_depth': 7, 'min_child_samples': 89, 'subsample': 0.9035901202009251, 'colsample_bytree': 0.9474000302273338, 'reg_alpha': 1.0229817504257312e-05, 'reg_lambda': 3.851527707853334e-08}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:01:11,174] Trial 95 finished with value: 0.6702702702702703 and parameters: {'learning_rate': 0.03338326221787333, 'num_leaves': 79, 'max_depth': 10, 'min_child_samples': 80, 'subsample': 0.8452686493729434, 'colsample_bytree': 0.9162931496707547, 'reg_alpha': 1.5467938660701256e-06, 'reg_lambda': 0.0025078259330971677}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:01:12,192] Trial 96 finished with value: 0.6770833333333334 and parameters: {'learning_rate': 0.026084500604162272, 'num_leaves': 74, 'max_depth': 9, 'min_child_samples': 93, 'subsample': 0.6111470808005057, 'colsample_bytree': 0.9554962695811534, 'reg_alpha': 6.334051911620329e-08, 'reg_lambda': 3.5571459460306855e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:01:13,112] Trial 97 finished with value: 0.6743119266055045 and parameters: {'learning_rate': 0.03715168168825022, 'num_leaves': 55, 'max_depth': 10, 'min_child_samples': 99, 'subsample': 0.8378089573475661, 'colsample_bytree': 0.9706462966778933, 'reg_alpha': 0.00024537543713840077, 'reg_lambda': 1.7405163208787323e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:01:13,853] Trial 98 finished with value: 0.6766169154228856 and parameters: {'learning_rate': 0.04824620800594388, 'num_leaves': 79, 'max_depth': 8, 'min_child_samples': 74, 'subsample': 0.8770929059542796, 'colsample_bytree': 0.8945597303807922, 'reg_alpha': 0.0009635160439517518, 'reg_lambda': 6.161659320595148e-07}. Best is trial 28 with value: 0.6861313868613139.\n",
      "[I 2025-10-19 21:01:14,753] Trial 99 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.039903605144615883, 'num_leaves': 64, 'max_depth': 3, 'min_child_samples': 84, 'subsample': 0.8948731149003922, 'colsample_bytree': 0.8772737182970152, 'reg_alpha': 0.06206254833016091, 'reg_lambda': 2.0258996724058747e-08}. Best is trial 28 with value: 0.6861313868613139.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optimization Finished ---\n",
      "Best trial for lightgbm:\n",
      "  Value (Best F1 Score): 0.68613\n",
      "  Best Params:\n",
      "    learning_rate: 0.03619544118688672\n",
      "    num_leaves: 46\n",
      "    max_depth: 3\n",
      "    min_child_samples: 73\n",
      "    subsample: 0.6386263605915126\n",
      "    colsample_bytree: 0.956195623166564\n",
      "    reg_alpha: 0.00596055345803014\n",
      "    reg_lambda: 1.4296575005918243e-07\n"
     ]
    }
   ],
   "source": [
    "# 基本パラメータ\n",
    "lgbm_params_base = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'n_estimators': 1000,\n",
    "    'is_unbalance': True,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'verbose': -1\n",
    "    }\n",
    "\n",
    "# 探索するパラメータを定義する「関数」\n",
    "def define_lgbm_params(trial):\n",
    "    return {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 80),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "    }\n",
    "\n",
    "# LightGBMモデルの最適化実行\n",
    "lgbm_results = optimize_model(\n",
    "    X_train_df,\n",
    "    y_train_df,\n",
    "    model_name=\"lightgbm\",\n",
    "    params_base=lgbm_params_base,\n",
    "    define_params_func=define_lgbm_params,\n",
    "    n_trials=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90372f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-19 21:01:14,770] A new study created in memory with name: no-name-ee4c900d-e877-4e58-ba8f-96d81836af8e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Optimizing xgboost ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-19 21:01:23,782] Trial 0 finished with value: 0.6584766584766585 and parameters: {'learning_rate': 0.04162211822586593, 'max_depth': 10, 'min_child_weight': 13, 'subsample': 0.68168937255644, 'colsample_bytree': 0.6032293605452643, 'reg_alpha': 8.157286577166329e-05, 'reg_lambda': 0.0001755669533539243}. Best is trial 0 with value: 0.6584766584766585.\n",
      "[I 2025-10-19 21:01:32,116] Trial 1 finished with value: 0.6564102564102564 and parameters: {'learning_rate': 0.0555169762091263, 'max_depth': 12, 'min_child_weight': 13, 'subsample': 0.8556086896333883, 'colsample_bytree': 0.9373564929829289, 'reg_alpha': 0.09617714041367485, 'reg_lambda': 1.7165086976720852e-06}. Best is trial 0 with value: 0.6584766584766585.\n",
      "[I 2025-10-19 21:01:51,024] Trial 2 finished with value: 0.6714975845410628 and parameters: {'learning_rate': 0.015784177233360473, 'max_depth': 12, 'min_child_weight': 17, 'subsample': 0.7391733869109491, 'colsample_bytree': 0.6825272142418453, 'reg_alpha': 0.011224349006434183, 'reg_lambda': 0.0010807476897334645}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:01:53,933] Trial 3 finished with value: 0.4143646408839779 and parameters: {'learning_rate': 0.047905327758274815, 'max_depth': 3, 'min_child_weight': 97, 'subsample': 0.8222584610048812, 'colsample_bytree': 0.8332429179210794, 'reg_alpha': 0.0040902224370867836, 'reg_lambda': 5.739765068597108}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:01:56,786] Trial 4 finished with value: 0.38870792616720956 and parameters: {'learning_rate': 0.014070060413830106, 'max_depth': 8, 'min_child_weight': 81, 'subsample': 0.6521229809560224, 'colsample_bytree': 0.6116826269873366, 'reg_alpha': 6.211034750327594, 'reg_lambda': 1.8424622809729074e-05}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:02:04,775] Trial 5 finished with value: 0.6393088552915767 and parameters: {'learning_rate': 0.06046427175781178, 'max_depth': 10, 'min_child_weight': 29, 'subsample': 0.6580343657786342, 'colsample_bytree': 0.9168375266430431, 'reg_alpha': 1.3251982332401369, 'reg_lambda': 7.561870244900186e-08}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:02:07,079] Trial 6 finished with value: 0.38870792616720956 and parameters: {'learning_rate': 0.019660852505936237, 'max_depth': 12, 'min_child_weight': 93, 'subsample': 0.6079645897497878, 'colsample_bytree': 0.9209010322465918, 'reg_alpha': 0.0037412447629171885, 'reg_lambda': 0.8824994570633483}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:02:14,286] Trial 7 finished with value: 0.6464646464646465 and parameters: {'learning_rate': 0.06091387331289989, 'max_depth': 4, 'min_child_weight': 25, 'subsample': 0.7021132354818292, 'colsample_bytree': 0.9638805861363631, 'reg_alpha': 0.00010458772513569257, 'reg_lambda': 3.762815717112162e-05}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:02:16,236] Trial 8 finished with value: 0.38870792616720956 and parameters: {'learning_rate': 0.0712165109004205, 'max_depth': 8, 'min_child_weight': 98, 'subsample': 0.7012756266250182, 'colsample_bytree': 0.654279542322462, 'reg_alpha': 2.435126522493129e-06, 'reg_lambda': 8.882706398162528e-05}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:02:36,454] Trial 9 finished with value: 0.636568848758465 and parameters: {'learning_rate': 0.024694018776571573, 'max_depth': 5, 'min_child_weight': 43, 'subsample': 0.8300212166651135, 'colsample_bytree': 0.8640340672265127, 'reg_alpha': 0.27476765192417063, 'reg_lambda': 2.914035673216827e-06}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:03:00,347] Trial 10 finished with value: 0.6164383561643836 and parameters: {'learning_rate': 0.011638914702116095, 'max_depth': 6, 'min_child_weight': 61, 'subsample': 0.9930528782056732, 'colsample_bytree': 0.7398994811386009, 'reg_alpha': 1.4053752540318378e-08, 'reg_lambda': 0.03979690769303112}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:03:09,438] Trial 11 finished with value: 0.6553398058252428 and parameters: {'learning_rate': 0.037223330726602416, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.7514680567389561, 'colsample_bytree': 0.7055156860213575, 'reg_alpha': 9.049411263502873e-06, 'reg_lambda': 0.004688375106496507}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:03:24,091] Trial 12 finished with value: 0.6308411214953271 and parameters: {'learning_rate': 0.03204076535848942, 'max_depth': 10, 'min_child_weight': 42, 'subsample': 0.7552365683690949, 'colsample_bytree': 0.6032272894370733, 'reg_alpha': 0.00472914562043008, 'reg_lambda': 0.0013361993684788175}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:03:46,680] Trial 13 finished with value: 0.6579634464751958 and parameters: {'learning_rate': 0.017585161573425188, 'max_depth': 11, 'min_child_weight': 20, 'subsample': 0.8957761461952254, 'colsample_bytree': 0.7565736577338515, 'reg_alpha': 9.451623883487042e-05, 'reg_lambda': 0.05597687699507066}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:03:51,375] Trial 14 finished with value: 0.6466512702078522 and parameters: {'learning_rate': 0.090841494370808, 'max_depth': 9, 'min_child_weight': 6, 'subsample': 0.7684421880778031, 'colsample_bytree': 0.6698695240390946, 'reg_alpha': 1.3965063936085996e-06, 'reg_lambda': 0.001734686533781877}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:04:04,490] Trial 15 finished with value: 0.5914221218961625 and parameters: {'learning_rate': 0.024753340126391993, 'max_depth': 12, 'min_child_weight': 61, 'subsample': 0.7128193615400241, 'colsample_bytree': 0.6679836937042635, 'reg_alpha': 0.02864258991881984, 'reg_lambda': 1.2955764252610793e-08}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:04:30,118] Trial 16 finished with value: 0.6338028169014085 and parameters: {'learning_rate': 0.010558015680321015, 'max_depth': 7, 'min_child_weight': 35, 'subsample': 0.6061608535568966, 'colsample_bytree': 0.782940515179199, 'reg_alpha': 8.294584400704357e-08, 'reg_lambda': 0.016088961797495898}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:04:47,569] Trial 17 finished with value: 0.6296296296296297 and parameters: {'learning_rate': 0.038801959205507996, 'max_depth': 11, 'min_child_weight': 50, 'subsample': 0.9119011589541213, 'colsample_bytree': 0.7244458290362074, 'reg_alpha': 0.0002994922806188804, 'reg_lambda': 0.0003375627543494704}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:05:05,157] Trial 18 finished with value: 0.6682577565632458 and parameters: {'learning_rate': 0.024257808416252153, 'max_depth': 9, 'min_child_weight': 14, 'subsample': 0.6567315656478132, 'colsample_bytree': 0.6367618827493503, 'reg_alpha': 2.0004832113129513e-05, 'reg_lambda': 0.2717523205666773}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:05:29,756] Trial 19 finished with value: 0.6567901234567901 and parameters: {'learning_rate': 0.015901037633471993, 'max_depth': 7, 'min_child_weight': 21, 'subsample': 0.7916529041996431, 'colsample_bytree': 0.682267655470751, 'reg_alpha': 6.260978639299587e-06, 'reg_lambda': 0.45066627907334633}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:05:39,844] Trial 20 finished with value: 0.572 and parameters: {'learning_rate': 0.023005518758657483, 'max_depth': 9, 'min_child_weight': 70, 'subsample': 0.6437631152886854, 'colsample_bytree': 0.6440653712827261, 'reg_alpha': 3.2565218051318e-07, 'reg_lambda': 9.905871332569694}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:05:51,622] Trial 21 finished with value: 0.6475195822454308 and parameters: {'learning_rate': 0.03171371340057279, 'max_depth': 11, 'min_child_weight': 16, 'subsample': 0.6926560086757152, 'colsample_bytree': 0.6349536555390923, 'reg_alpha': 6.538720052855738e-05, 'reg_lambda': 0.29879243985974413}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:06:15,424] Trial 22 finished with value: 0.6401869158878505 and parameters: {'learning_rate': 0.013475196224330256, 'max_depth': 9, 'min_child_weight': 31, 'subsample': 0.7271712228987363, 'colsample_bytree': 0.6072076977785402, 'reg_alpha': 0.0012176206970268128, 'reg_lambda': 0.00030427768818804283}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:06:29,173] Trial 23 finished with value: 0.670299727520436 and parameters: {'learning_rate': 0.021735209632528826, 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.6695136083245187, 'colsample_bytree': 0.7008625006034268, 'reg_alpha': 2.4169698493729696e-05, 'reg_lambda': 5.374349569143805e-06}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:06:45,415] Trial 24 finished with value: 0.6580310880829016 and parameters: {'learning_rate': 0.019615518080399432, 'max_depth': 11, 'min_child_weight': 6, 'subsample': 0.6295558971616241, 'colsample_bytree': 0.7031952605270494, 'reg_alpha': 1.1743390601684746e-05, 'reg_lambda': 2.576548747663276e-06}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:07:00,585] Trial 25 finished with value: 0.6386946386946387 and parameters: {'learning_rate': 0.025524684676561778, 'max_depth': 9, 'min_child_weight': 37, 'subsample': 0.6730670627476799, 'colsample_bytree': 0.8206695719310981, 'reg_alpha': 0.0008664239926432547, 'reg_lambda': 3.141924397340095e-07}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:07:19,271] Trial 26 finished with value: 0.6439024390243903 and parameters: {'learning_rate': 0.020683425167560106, 'max_depth': 12, 'min_child_weight': 25, 'subsample': 0.7392505957583947, 'colsample_bytree': 0.7632415607019591, 'reg_alpha': 0.020934009738706447, 'reg_lambda': 9.344730308780404e-06}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:07:32,189] Trial 27 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.028640791713091095, 'max_depth': 8, 'min_child_weight': 14, 'subsample': 0.7719298839489327, 'colsample_bytree': 0.6941795007185246, 'reg_alpha': 2.4229418422582882e-05, 'reg_lambda': 3.6371401283305665e-07}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:07:48,407] Trial 28 finished with value: 0.6611111111111111 and parameters: {'learning_rate': 0.015929155271975592, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.63259057259238, 'colsample_bytree': 0.7282338406516443, 'reg_alpha': 1.2452197633024161e-06, 'reg_lambda': 0.0044582026980913144}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:08:13,439] Trial 29 finished with value: 0.6600496277915633 and parameters: {'learning_rate': 0.012851208497967328, 'max_depth': 10, 'min_child_weight': 16, 'subsample': 0.6683891144576741, 'colsample_bytree': 0.6443978527424447, 'reg_alpha': 0.000342622401951748, 'reg_lambda': 1.796149476146454}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:08:35,898] Trial 30 finished with value: 0.66 and parameters: {'learning_rate': 0.016419642924632265, 'max_depth': 10, 'min_child_weight': 21, 'subsample': 0.6802407661464364, 'colsample_bytree': 0.7933500280653075, 'reg_alpha': 1.6710143443825585e-07, 'reg_lambda': 0.09810773744150952}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:08:49,707] Trial 31 finished with value: 0.6631016042780749 and parameters: {'learning_rate': 0.026518740103905005, 'max_depth': 8, 'min_child_weight': 12, 'subsample': 0.7830262873739342, 'colsample_bytree': 0.6936510495689727, 'reg_alpha': 2.6170619649186046e-05, 'reg_lambda': 4.007482709694297e-07}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:09:02,551] Trial 32 finished with value: 0.6618705035971223 and parameters: {'learning_rate': 0.029701706732699434, 'max_depth': 7, 'min_child_weight': 13, 'subsample': 0.7312536891350029, 'colsample_bytree': 0.7120259909710397, 'reg_alpha': 3.2605529338650966e-05, 'reg_lambda': 7.080861655794883e-07}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:09:11,908] Trial 33 finished with value: 0.6632911392405063 and parameters: {'learning_rate': 0.04551660367263126, 'max_depth': 6, 'min_child_weight': 12, 'subsample': 0.8172083727304171, 'colsample_bytree': 0.6307370678012929, 'reg_alpha': 0.0005022078538503964, 'reg_lambda': 1.1170961347462173e-07}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:09:31,713] Trial 34 finished with value: 0.6483790523690773 and parameters: {'learning_rate': 0.022103258859745026, 'max_depth': 8, 'min_child_weight': 26, 'subsample': 0.8474451639661125, 'colsample_bytree': 0.682949230680429, 'reg_alpha': 0.013686608711153504, 'reg_lambda': 9.86544563143639e-06}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:09:46,074] Trial 35 finished with value: 0.6650366748166259 and parameters: {'learning_rate': 0.035020295111176464, 'max_depth': 6, 'min_child_weight': 17, 'subsample': 0.7664167613395412, 'colsample_bytree': 0.75435956276475, 'reg_alpha': 5.239221218159538e-07, 'reg_lambda': 1.761082812534009e-08}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:09:58,868] Trial 36 finished with value: 0.6631016042780749 and parameters: {'learning_rate': 0.028353032312501553, 'max_depth': 9, 'min_child_weight': 10, 'subsample': 0.7254350096265543, 'colsample_bytree': 0.6645546647005928, 'reg_alpha': 4.404199760178213e-06, 'reg_lambda': 8.584734287907518e-05}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:10:19,308] Trial 37 finished with value: 0.6350710900473934 and parameters: {'learning_rate': 0.017757978373303233, 'max_depth': 12, 'min_child_weight': 33, 'subsample': 0.6563102388157668, 'colsample_bytree': 0.8748803873602624, 'reg_alpha': 0.08658086781452067, 'reg_lambda': 6.374389220029342e-08}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:10:28,219] Trial 38 finished with value: 0.5647058823529412 and parameters: {'learning_rate': 0.019345808097414492, 'max_depth': 8, 'min_child_weight': 87, 'subsample': 0.7983564315422655, 'colsample_bytree': 0.6284732204579436, 'reg_alpha': 0.0023879969550795453, 'reg_lambda': 1.3211731701183197e-06}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:10:53,695] Trial 39 finished with value: 0.6535626535626535 and parameters: {'learning_rate': 0.015094288125796246, 'max_depth': 9, 'min_child_weight': 26, 'subsample': 0.6936184590529507, 'colsample_bytree': 0.8195046393143326, 'reg_alpha': 0.7675904096027302, 'reg_lambda': 3.303914407677981e-05}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:11:07,101] Trial 40 finished with value: 0.6311111111111111 and parameters: {'learning_rate': 0.04508932243875855, 'max_depth': 8, 'min_child_weight': 42, 'subsample': 0.8703412918323513, 'colsample_bytree': 0.7340991289203062, 'reg_alpha': 2.141235175079648e-05, 'reg_lambda': 4.2966812414672385e-06}. Best is trial 2 with value: 0.6714975845410628.\n",
      "[I 2025-10-19 21:11:23,264] Trial 41 finished with value: 0.6715686274509803 and parameters: {'learning_rate': 0.03249809919794662, 'max_depth': 6, 'min_child_weight': 18, 'subsample': 0.7704282390375292, 'colsample_bytree': 0.760136654715778, 'reg_alpha': 2.3722172028889658e-08, 'reg_lambda': 1.8044219047151194e-08}. Best is trial 41 with value: 0.6715686274509803.\n",
      "[I 2025-10-19 21:11:41,401] Trial 42 finished with value: 0.6522781774580336 and parameters: {'learning_rate': 0.022126807937618346, 'max_depth': 5, 'min_child_weight': 21, 'subsample': 0.8181146762951397, 'colsample_bytree': 0.774955815088032, 'reg_alpha': 1.1980442535614284e-08, 'reg_lambda': 4.5310207290684485e-08}. Best is trial 41 with value: 0.6715686274509803.\n",
      "[I 2025-10-19 21:11:52,823] Trial 43 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.03520939569424234, 'max_depth': 3, 'min_child_weight': 16, 'subsample': 0.7746284467744706, 'colsample_bytree': 0.6875267124291691, 'reg_alpha': 0.00013506604064458414, 'reg_lambda': 2.1499227321538352e-07}. Best is trial 41 with value: 0.6715686274509803.\n",
      "[I 2025-10-19 21:12:08,238] Trial 44 finished with value: 0.6737400530503979 and parameters: {'learning_rate': 0.027950037127883125, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.7489847097588108, 'colsample_bytree': 0.9989216742824987, 'reg_alpha': 1.0399102306537346e-06, 'reg_lambda': 2.5263574437184806}. Best is trial 44 with value: 0.6737400530503979.\n",
      "[I 2025-10-19 21:12:19,651] Trial 45 finished with value: 0.680628272251309 and parameters: {'learning_rate': 0.04086914206891263, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.744429186257533, 'colsample_bytree': 0.9593773501164281, 'reg_alpha': 3.0629980821246204e-08, 'reg_lambda': 2.065609141733248}. Best is trial 45 with value: 0.680628272251309.\n",
      "[I 2025-10-19 21:12:29,467] Trial 46 finished with value: 0.6650366748166259 and parameters: {'learning_rate': 0.04317338490867534, 'max_depth': 4, 'min_child_weight': 10, 'subsample': 0.7506723767471275, 'colsample_bytree': 0.9764880430444874, 'reg_alpha': 3.483483949406384e-08, 'reg_lambda': 1.2664716087854582}. Best is trial 45 with value: 0.680628272251309.\n",
      "[I 2025-10-19 21:12:37,550] Trial 47 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.05758608991263834, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.704922376263833, 'colsample_bytree': 0.9944592034541185, 'reg_alpha': 6.397301057250223e-08, 'reg_lambda': 4.750566094744937}. Best is trial 45 with value: 0.680628272251309.\n",
      "[I 2025-10-19 21:12:45,451] Trial 48 finished with value: 0.6757493188010899 and parameters: {'learning_rate': 0.06792110773001994, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.7473744556269944, 'colsample_bytree': 0.9361049228055051, 'reg_alpha': 2.990125220561783e-08, 'reg_lambda': 3.982990531733506}. Best is trial 45 with value: 0.680628272251309.\n",
      "[I 2025-10-19 21:12:54,505] Trial 49 finished with value: 0.6428571428571429 and parameters: {'learning_rate': 0.07679997285430652, 'max_depth': 4, 'min_child_weight': 29, 'subsample': 0.7467668302491123, 'colsample_bytree': 0.9405841284801792, 'reg_alpha': 5.906471852937623e-08, 'reg_lambda': 2.963508973111031}. Best is trial 45 with value: 0.680628272251309.\n",
      "[I 2025-10-19 21:13:04,400] Trial 50 finished with value: 0.6545454545454545 and parameters: {'learning_rate': 0.0693131517720116, 'max_depth': 3, 'min_child_weight': 21, 'subsample': 0.7171075214781837, 'colsample_bytree': 0.8987048802276827, 'reg_alpha': 2.4887729952747437e-08, 'reg_lambda': 0.527533133656303}. Best is trial 45 with value: 0.680628272251309.\n",
      "[I 2025-10-19 21:13:12,867] Trial 51 finished with value: 0.6703601108033241 and parameters: {'learning_rate': 0.04972403040432549, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.7596432199852919, 'colsample_bytree': 0.9460878817178098, 'reg_alpha': 1.618997126926263e-07, 'reg_lambda': 0.14154771449565526}. Best is trial 45 with value: 0.680628272251309.\n",
      "[I 2025-10-19 21:13:20,840] Trial 52 finished with value: 0.6774193548387096 and parameters: {'learning_rate': 0.05178247195082826, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.8049615750508924, 'colsample_bytree': 0.9430566649158814, 'reg_alpha': 1.9956892237865423e-07, 'reg_lambda': 0.11590285487829971}. Best is trial 45 with value: 0.680628272251309.\n",
      "[I 2025-10-19 21:13:31,840] Trial 53 finished with value: 0.6631016042780749 and parameters: {'learning_rate': 0.051960785650184166, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.8371365065128297, 'colsample_bytree': 0.9644722527095222, 'reg_alpha': 1.0199078665279995e-08, 'reg_lambda': 8.324206351209362}. Best is trial 45 with value: 0.680628272251309.\n",
      "[I 2025-10-19 21:13:43,935] Trial 54 finished with value: 0.6506024096385542 and parameters: {'learning_rate': 0.040394381913849996, 'max_depth': 3, 'min_child_weight': 18, 'subsample': 0.8064418581994759, 'colsample_bytree': 0.9162463785188466, 'reg_alpha': 7.040197929716317e-07, 'reg_lambda': 0.030506573379112324}. Best is trial 45 with value: 0.680628272251309.\n",
      "[I 2025-10-19 21:13:53,539] Trial 55 finished with value: 0.6229508196721312 and parameters: {'learning_rate': 0.0634609311069306, 'max_depth': 4, 'min_child_weight': 53, 'subsample': 0.8029978753411683, 'colsample_bytree': 0.9813516194437999, 'reg_alpha': 1.6929765715604953e-07, 'reg_lambda': 2.6229348139193496}. Best is trial 45 with value: 0.680628272251309.\n",
      "[I 2025-10-19 21:13:58,957] Trial 56 finished with value: 0.6610169491525424 and parameters: {'learning_rate': 0.08092584910444275, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.7848628899039639, 'colsample_bytree': 0.8573438315032651, 'reg_alpha': 2.0754787711262888e-08, 'reg_lambda': 0.011820395316590201}. Best is trial 45 with value: 0.680628272251309.\n",
      "[I 2025-10-19 21:14:07,200] Trial 57 finished with value: 0.665 and parameters: {'learning_rate': 0.05305782956586561, 'max_depth': 6, 'min_child_weight': 10, 'subsample': 0.8729174627157948, 'colsample_bytree': 0.9999275196853683, 'reg_alpha': 3.163290599064612e-07, 'reg_lambda': 0.5867231906980976}. Best is trial 45 with value: 0.680628272251309.\n",
      "[I 2025-10-19 21:14:12,734] Trial 58 finished with value: 0.5594149908592322 and parameters: {'learning_rate': 0.09672546878182126, 'max_depth': 4, 'min_child_weight': 79, 'subsample': 0.7352095943315424, 'colsample_bytree': 0.9213610553817803, 'reg_alpha': 4.194098212186862e-08, 'reg_lambda': 1.2215052325927567}. Best is trial 45 with value: 0.680628272251309.\n",
      "[I 2025-10-19 21:14:27,036] Trial 59 finished with value: 0.6374695863746959 and parameters: {'learning_rate': 0.06644472972498591, 'max_depth': 5, 'min_child_weight': 24, 'subsample': 0.7137842934377215, 'colsample_bytree': 0.9634265511132482, 'reg_alpha': 9.512567214128778, 'reg_lambda': 0.13451701917246656}. Best is trial 45 with value: 0.680628272251309.\n",
      "[I 2025-10-19 21:14:42,040] Trial 60 finished with value: 0.6596306068601583 and parameters: {'learning_rate': 0.036426237789591566, 'max_depth': 4, 'min_child_weight': 18, 'subsample': 0.9666716229055435, 'colsample_bytree': 0.8926219741928999, 'reg_alpha': 1.0239540838665259e-07, 'reg_lambda': 0.0009509354492051162}. Best is trial 45 with value: 0.680628272251309.\n",
      "[I 2025-10-19 21:14:50,533] Trial 61 finished with value: 0.6649076517150396 and parameters: {'learning_rate': 0.05054184444068212, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.7586973415056342, 'colsample_bytree': 0.945414643807924, 'reg_alpha': 1.6701242032248887e-07, 'reg_lambda': 4.144012699361159}. Best is trial 45 with value: 0.680628272251309.\n",
      "[I 2025-10-19 21:14:58,416] Trial 62 finished with value: 0.6736842105263158 and parameters: {'learning_rate': 0.05547268711945372, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.760813143084845, 'colsample_bytree': 0.9528402084983408, 'reg_alpha': 1.7063860696012996e-06, 'reg_lambda': 0.11346953846513005}. Best is trial 45 with value: 0.680628272251309.\n",
      "[I 2025-10-19 21:15:06,438] Trial 63 finished with value: 0.6729411764705883 and parameters: {'learning_rate': 0.05812243848847197, 'max_depth': 3, 'min_child_weight': 14, 'subsample': 0.7789997369003404, 'colsample_bytree': 0.9281208429525204, 'reg_alpha': 3.448357106266229e-06, 'reg_lambda': 0.010403196155072795}. Best is trial 45 with value: 0.680628272251309.\n",
      "[I 2025-10-19 21:15:15,383] Trial 64 finished with value: 0.6633416458852868 and parameters: {'learning_rate': 0.05708403500597458, 'max_depth': 3, 'min_child_weight': 13, 'subsample': 0.7845717489035069, 'colsample_bytree': 0.9251138983226229, 'reg_alpha': 2.9320593004262956e-06, 'reg_lambda': 0.23597352365003516}. Best is trial 45 with value: 0.680628272251309.\n",
      "[I 2025-10-19 21:15:21,910] Trial 65 finished with value: 0.6807387862796834 and parameters: {'learning_rate': 0.07513423764757644, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.7413321497250928, 'colsample_bytree': 0.969859901939038, 'reg_alpha': 1.1435777162179903e-06, 'reg_lambda': 0.06938285777686445}. Best is trial 65 with value: 0.6807387862796834.\n",
      "[I 2025-10-19 21:15:28,665] Trial 66 finished with value: 0.6827956989247311 and parameters: {'learning_rate': 0.077513566951611, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.7480586089700577, 'colsample_bytree': 0.958109586416719, 'reg_alpha': 1.3262613361528793e-06, 'reg_lambda': 0.05605833622307848}. Best is trial 66 with value: 0.6827956989247311.\n",
      "[I 2025-10-19 21:15:34,604] Trial 67 finished with value: 0.6902173913043478 and parameters: {'learning_rate': 0.08352096444095193, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.7475874099837331, 'colsample_bytree': 0.9567585499377098, 'reg_alpha': 8.386330656625298e-07, 'reg_lambda': 0.07497349653592147}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:15:41,486] Trial 68 finished with value: 0.6650366748166259 and parameters: {'learning_rate': 0.08197240938026601, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.742329042934812, 'colsample_bytree': 0.9851589660836215, 'reg_alpha': 8.460392182734019e-07, 'reg_lambda': 0.7089673366902887}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:15:47,662] Trial 69 finished with value: 0.6648501362397821 and parameters: {'learning_rate': 0.07320764928016628, 'max_depth': 4, 'min_child_weight': 11, 'subsample': 0.7217558712107152, 'colsample_bytree': 0.9611524838067533, 'reg_alpha': 5.432790746783295e-07, 'reg_lambda': 0.05350311123779141}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:15:53,866] Trial 70 finished with value: 0.6821705426356589 and parameters: {'learning_rate': 0.08894447479655054, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.701172627408009, 'colsample_bytree': 0.9723240525276284, 'reg_alpha': 3.379620359399425e-07, 'reg_lambda': 0.025682380396530678}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:16:00,967] Trial 71 finished with value: 0.6702127659574468 and parameters: {'learning_rate': 0.08736899909300339, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.6991296880478122, 'colsample_bytree': 0.9710206636748289, 'reg_alpha': 9.508112535873198e-06, 'reg_lambda': 0.005634254024197427}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:16:06,569] Trial 72 finished with value: 0.6683046683046683 and parameters: {'learning_rate': 0.0956201636281109, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.7382278011879301, 'colsample_bytree': 0.9075282672178249, 'reg_alpha': 3.393349271519787e-07, 'reg_lambda': 0.029366340682282093}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:16:11,805] Trial 73 finished with value: 0.6490765171503958 and parameters: {'learning_rate': 0.08777469731784684, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.7096681530111809, 'colsample_bytree': 0.9856064197059774, 'reg_alpha': 1.7994742020773041e-06, 'reg_lambda': 0.23837400474700723}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:16:20,350] Trial 74 finished with value: 0.6634146341463415 and parameters: {'learning_rate': 0.07779357165896268, 'max_depth': 3, 'min_child_weight': 14, 'subsample': 0.6867635482858624, 'colsample_bytree': 0.934014779182515, 'reg_alpha': 3.249778168251342e-07, 'reg_lambda': 0.021362708887784836}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:16:28,616] Trial 75 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.06170782969363878, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.7516725363820211, 'colsample_bytree': 0.9532252749426355, 'reg_alpha': 1.0669174072268564e-07, 'reg_lambda': 1.4947467946208255}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:16:36,200] Trial 76 finished with value: 0.6804123711340206 and parameters: {'learning_rate': 0.07322679864572487, 'max_depth': 4, 'min_child_weight': 12, 'subsample': 0.7312786595651183, 'colsample_bytree': 0.9906015049285382, 'reg_alpha': 9.562372085724904e-07, 'reg_lambda': 0.06889118636416733}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:16:43,859] Trial 77 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.07235686417353905, 'max_depth': 4, 'min_child_weight': 15, 'subsample': 0.7329415229342816, 'colsample_bytree': 0.9704584912713061, 'reg_alpha': 2.3547325124979594e-07, 'reg_lambda': 0.0881232025418515}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:16:51,497] Trial 78 finished with value: 0.6617647058823529 and parameters: {'learning_rate': 0.06715214282022286, 'max_depth': 4, 'min_child_weight': 12, 'subsample': 0.7918361225375534, 'colsample_bytree': 0.9539935158527587, 'reg_alpha': 5.68086533931519e-06, 'reg_lambda': 0.002002432273551874}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:16:57,529] Trial 79 finished with value: 0.6747572815533981 and parameters: {'learning_rate': 0.08568266289857267, 'max_depth': 3, 'min_child_weight': 12, 'subsample': 0.7219877607775228, 'colsample_bytree': 0.9347574462323904, 'reg_alpha': 5.498193616673517e-08, 'reg_lambda': 0.04135914442805513}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:17:04,132] Trial 80 finished with value: 0.6533665835411472 and parameters: {'learning_rate': 0.09160693942330426, 'max_depth': 3, 'min_child_weight': 23, 'subsample': 0.6842350815679841, 'colsample_bytree': 0.9888051957691706, 'reg_alpha': 5.955461396539405e-07, 'reg_lambda': 0.35198350622757824}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:17:10,827] Trial 81 finished with value: 0.6717171717171717 and parameters: {'learning_rate': 0.08366248624983717, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.7147681268751394, 'colsample_bytree': 0.9373611542526339, 'reg_alpha': 4.1547111160561806e-08, 'reg_lambda': 0.05930774078212832}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:17:16,436] Trial 82 finished with value: 0.6531531531531531 and parameters: {'learning_rate': 0.09882980428474626, 'max_depth': 4, 'min_child_weight': 11, 'subsample': 0.7254558471769718, 'colsample_bytree': 0.9731796861309915, 'reg_alpha': 9.129085132458154e-08, 'reg_lambda': 0.04910039974725278}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:17:23,742] Trial 83 finished with value: 0.6716791979949874 and parameters: {'learning_rate': 0.07781254934113654, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.7031577474330848, 'colsample_bytree': 0.9100579868045837, 'reg_alpha': 1.614033646884618e-08, 'reg_lambda': 0.019511362363558216}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:17:31,575] Trial 84 finished with value: 0.6683937823834197 and parameters: {'learning_rate': 0.06512824786787083, 'max_depth': 3, 'min_child_weight': 12, 'subsample': 0.7654225656483381, 'colsample_bytree': 0.8814739841051382, 'reg_alpha': 5.673287934349546e-08, 'reg_lambda': 0.009708247656368614}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:17:37,615] Trial 85 finished with value: 0.579185520361991 and parameters: {'learning_rate': 0.07471292089788512, 'max_depth': 4, 'min_child_weight': 65, 'subsample': 0.7295903808402335, 'colsample_bytree': 0.9577049067628042, 'reg_alpha': 1.2416369822365312e-06, 'reg_lambda': 0.003243906497582895}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:17:39,865] Trial 86 finished with value: 0.38870792616720956 and parameters: {'learning_rate': 0.06984961479280763, 'max_depth': 4, 'min_child_weight': 100, 'subsample': 0.6752337818915862, 'colsample_bytree': 0.933810223773833, 'reg_alpha': 3.2604038835303577e-08, 'reg_lambda': 0.18580110057741522}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:17:47,955] Trial 87 finished with value: 0.6588785046728972 and parameters: {'learning_rate': 0.0854497735411361, 'max_depth': 3, 'min_child_weight': 19, 'subsample': 0.7436522890046317, 'colsample_bytree': 0.9482241327810812, 'reg_alpha': 4.0894429644302494e-07, 'reg_lambda': 0.07864335274247923}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:17:55,052] Trial 88 finished with value: 0.6786632390745502 and parameters: {'learning_rate': 0.09176509001765129, 'max_depth': 5, 'min_child_weight': 15, 'subsample': 0.7197971059158472, 'colsample_bytree': 0.9770840176508854, 'reg_alpha': 2.1462370742537096e-06, 'reg_lambda': 0.03082990638544077}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:18:03,156] Trial 89 finished with value: 0.6394230769230769 and parameters: {'learning_rate': 0.09354658048310893, 'max_depth': 5, 'min_child_weight': 39, 'subsample': 0.8098886876455283, 'colsample_bytree': 0.9895182505938217, 'reg_alpha': 2.2037369197821485e-06, 'reg_lambda': 0.006251114704575161}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:18:11,023] Trial 90 finished with value: 0.670076726342711 and parameters: {'learning_rate': 0.07960357644165729, 'max_depth': 5, 'min_child_weight': 16, 'subsample': 0.7931717807012741, 'colsample_bytree': 0.9809770778622996, 'reg_alpha': 1.3734955025826741e-05, 'reg_lambda': 0.41043370575566046}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:18:16,998] Trial 91 finished with value: 0.6650124069478908 and parameters: {'learning_rate': 0.08936053894104674, 'max_depth': 4, 'min_child_weight': 11, 'subsample': 0.6912393116660843, 'colsample_bytree': 0.9673138103668366, 'reg_alpha': 2.0601819798866732e-07, 'reg_lambda': 0.030232445838217173}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:18:22,464] Trial 92 finished with value: 0.6505376344086021 and parameters: {'learning_rate': 0.09950455428639811, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.7158641350384152, 'colsample_bytree': 0.9762384976767774, 'reg_alpha': 1.1246918774870756e-06, 'reg_lambda': 0.0177893823042361}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:18:29,782] Trial 93 finished with value: 0.592901878914405 and parameters: {'learning_rate': 0.08408626161330345, 'max_depth': 4, 'min_child_weight': 51, 'subsample': 0.698271896987697, 'colsample_bytree': 0.9418273610237347, 'reg_alpha': 1.1792372378333418e-07, 'reg_lambda': 0.9664891869985479}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:18:37,076] Trial 94 finished with value: 0.6807387862796834 and parameters: {'learning_rate': 0.07347643112942187, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.8326033835740924, 'colsample_bytree': 0.9633190280151784, 'reg_alpha': 7.613987800081632e-07, 'reg_lambda': 0.038989107620142904}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:18:43,550] Trial 95 finished with value: 0.671957671957672 and parameters: {'learning_rate': 0.06995074303799641, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.8263560325458543, 'colsample_bytree': 0.9608500249408525, 'reg_alpha': 7.770264652353208e-07, 'reg_lambda': 0.07650133730806827}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:18:52,099] Trial 96 finished with value: 0.6843501326259946 and parameters: {'learning_rate': 0.060762971827677766, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7542716619671658, 'colsample_bytree': 0.978193696512663, 'reg_alpha': 6.343213199584241e-06, 'reg_lambda': 0.0007909464905925701}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:19:00,235] Trial 97 finished with value: 0.6737967914438503 and parameters: {'learning_rate': 0.06217470446210728, 'max_depth': 3, 'min_child_weight': 15, 'subsample': 0.8354728233904254, 'colsample_bytree': 0.9932463930084354, 'reg_alpha': 5.768348160884828e-06, 'reg_lambda': 0.1581237726702434}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:19:09,018] Trial 98 finished with value: 0.6649076517150396 and parameters: {'learning_rate': 0.046255944480426664, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.7723850508281311, 'colsample_bytree': 0.9823356199439017, 'reg_alpha': 3.3755377479845483e-06, 'reg_lambda': 0.000499769736589165}. Best is trial 67 with value: 0.6902173913043478.\n",
      "[I 2025-10-19 21:19:16,485] Trial 99 finished with value: 0.6684491978609626 and parameters: {'learning_rate': 0.07447500163040432, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.8500573045584476, 'colsample_bytree': 0.9748447939994327, 'reg_alpha': 2.1745885131443654e-06, 'reg_lambda': 0.007572173169612456}. Best is trial 67 with value: 0.6902173913043478.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optimization Finished ---\n",
      "Best trial for xgboost:\n",
      "  Value (Best F1 Score): 0.69022\n",
      "  Best Params:\n",
      "    learning_rate: 0.08352096444095193\n",
      "    max_depth: 3\n",
      "    min_child_weight: 5\n",
      "    subsample: 0.7475874099837331\n",
      "    colsample_bytree: 0.9567585499377098\n",
      "    reg_alpha: 8.386330656625298e-07\n",
      "    reg_lambda: 0.07497349653592147\n"
     ]
    }
   ],
   "source": [
    "# 基本パラメータ\n",
    "xgb_params_base = {\n",
    "    'objective': 'binary:logistic', \n",
    "    'eval_metric': 'logloss',       \n",
    "    'n_estimators': 1000,\n",
    "    'scale_pos_weight': (y_train_df == 0).sum() / (y_train_df == 1).sum(), # 'is_unbalance' の代わり\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'verbosity': 0,                 # 'verbose': -1 -> 'verbosity': 0\n",
    "    'booster': 'gbtree'             # デフォルトだが明記\n",
    "    }\n",
    "\n",
    "# 探索するパラメータを定義する「関数」\n",
    "def define_xgb_params(trial):\n",
    "    return {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "    }\n",
    "\n",
    "# XGBoostモデルの最適化実行\n",
    "xgb_results = optimize_model(\n",
    "    X_train_df,\n",
    "    y_train_df,\n",
    "    model_name=\"xgboost\",\n",
    "    params_base=xgb_params_base,\n",
    "    define_params_func=define_xgb_params,\n",
    "    n_trials=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77aad114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-19 21:19:16,502] A new study created in memory with name: no-name-4fef5cfc-bbc0-48fa-a7af-3b3b89857e43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Optimizing catboost ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-19 21:19:19,104] Trial 0 finished with value: 0.5560975609756098 and parameters: {'learning_rate': 0.06905717371069192, 'depth': 4, 'min_data_in_leaf': 23, 'subsample': 0.8335577978053137, 'l2_leaf_reg': 4.7242340724272985e-07}. Best is trial 0 with value: 0.5560975609756098.\n",
      "[I 2025-10-19 21:19:25,640] Trial 1 finished with value: 0.6594594594594595 and parameters: {'learning_rate': 0.03068748881000565, 'depth': 5, 'min_data_in_leaf': 66, 'subsample': 0.8629278353153673, 'l2_leaf_reg': 0.9987342502931277}. Best is trial 1 with value: 0.6594594594594595.\n",
      "[I 2025-10-19 21:19:40,669] Trial 2 finished with value: 0.6432160804020101 and parameters: {'learning_rate': 0.0454161193456705, 'depth': 7, 'min_data_in_leaf': 67, 'subsample': 0.750245663938685, 'l2_leaf_reg': 2.2269903830407562}. Best is trial 1 with value: 0.6594594594594595.\n",
      "[I 2025-10-19 21:19:45,820] Trial 3 finished with value: 0.578125 and parameters: {'learning_rate': 0.07222271540322885, 'depth': 7, 'min_data_in_leaf': 66, 'subsample': 0.9217051199162846, 'l2_leaf_reg': 0.0008552803354556044}. Best is trial 1 with value: 0.6594594594594595.\n",
      "[I 2025-10-19 21:19:50,816] Trial 4 finished with value: 0.6192893401015228 and parameters: {'learning_rate': 0.020782813299476406, 'depth': 5, 'min_data_in_leaf': 76, 'subsample': 0.7918149746811649, 'l2_leaf_reg': 3.957287242579169e-08}. Best is trial 1 with value: 0.6594594594594595.\n",
      "[I 2025-10-19 21:20:11,414] Trial 5 finished with value: 0.6521739130434783 and parameters: {'learning_rate': 0.03220001055416003, 'depth': 7, 'min_data_in_leaf': 18, 'subsample': 0.6258048131595875, 'l2_leaf_reg': 8.877480706744608}. Best is trial 1 with value: 0.6594594594594595.\n",
      "[I 2025-10-19 21:20:28,505] Trial 6 finished with value: 0.6169154228855721 and parameters: {'learning_rate': 0.06103670369472567, 'depth': 9, 'min_data_in_leaf': 10, 'subsample': 0.6823426665773334, 'l2_leaf_reg': 0.36443869995926026}. Best is trial 1 with value: 0.6594594594594595.\n",
      "[I 2025-10-19 21:20:34,207] Trial 7 finished with value: 0.6436170212765957 and parameters: {'learning_rate': 0.04985325198128772, 'depth': 5, 'min_data_in_leaf': 91, 'subsample': 0.6437281943116658, 'l2_leaf_reg': 0.6914389369385108}. Best is trial 1 with value: 0.6594594594594595.\n",
      "[I 2025-10-19 21:21:16,562] Trial 8 finished with value: 0.6113989637305699 and parameters: {'learning_rate': 0.012283535791635594, 'depth': 10, 'min_data_in_leaf': 63, 'subsample': 0.801115597392476, 'l2_leaf_reg': 0.0005176269668081712}. Best is trial 1 with value: 0.6594594594594595.\n",
      "[I 2025-10-19 21:21:30,341] Trial 9 finished with value: 0.6430379746835443 and parameters: {'learning_rate': 0.012381540224591103, 'depth': 8, 'min_data_in_leaf': 58, 'subsample': 0.9809037727280627, 'l2_leaf_reg': 2.6451365458546263e-05}. Best is trial 1 with value: 0.6594594594594595.\n",
      "[I 2025-10-19 21:21:37,006] Trial 10 finished with value: 0.6602870813397129 and parameters: {'learning_rate': 0.023201954961987493, 'depth': 3, 'min_data_in_leaf': 40, 'subsample': 0.889408371916114, 'l2_leaf_reg': 0.008841593765959633}. Best is trial 10 with value: 0.6602870813397129.\n",
      "[I 2025-10-19 21:21:43,671] Trial 11 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.022304843948482568, 'depth': 3, 'min_data_in_leaf': 40, 'subsample': 0.8798264796090728, 'l2_leaf_reg': 0.021404575393395412}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:21:50,085] Trial 12 finished with value: 0.6522781774580336 and parameters: {'learning_rate': 0.02035014664598749, 'depth': 3, 'min_data_in_leaf': 37, 'subsample': 0.9037609597743316, 'l2_leaf_reg': 0.014468422676587737}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:21:56,964] Trial 13 finished with value: 0.6476190476190476 and parameters: {'learning_rate': 0.019474272102350136, 'depth': 3, 'min_data_in_leaf': 39, 'subsample': 0.9738401857438859, 'l2_leaf_reg': 0.01770956225050654}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:22:02,058] Trial 14 finished with value: 0.6432160804020101 and parameters: {'learning_rate': 0.02940101583885892, 'depth': 3, 'min_data_in_leaf': 40, 'subsample': 0.9085503094512535, 'l2_leaf_reg': 0.035525953233370426}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:22:08,798] Trial 15 finished with value: 0.6437346437346437 and parameters: {'learning_rate': 0.015976032322453707, 'depth': 4, 'min_data_in_leaf': 45, 'subsample': 0.7334531976239428, 'l2_leaf_reg': 1.1867366918037547e-05}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:22:13,456] Trial 16 finished with value: 0.6421052631578947 and parameters: {'learning_rate': 0.03840369723590717, 'depth': 4, 'min_data_in_leaf': 29, 'subsample': 0.85636445751453, 'l2_leaf_reg': 0.0023646976512581575}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:22:19,087] Trial 17 finished with value: 0.6109785202863962 and parameters: {'learning_rate': 0.024424201188956177, 'depth': 6, 'min_data_in_leaf': 50, 'subsample': 0.9478732710564107, 'l2_leaf_reg': 2.130250042744856e-05}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:22:21,781] Trial 18 finished with value: 0.6448598130841121 and parameters: {'learning_rate': 0.0907861288540607, 'depth': 3, 'min_data_in_leaf': 30, 'subsample': 0.8813669052395549, 'l2_leaf_reg': 0.11497988312560282}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:22:29,932] Trial 19 finished with value: 0.6616161616161617 and parameters: {'learning_rate': 0.01802976702104205, 'depth': 6, 'min_data_in_leaf': 7, 'subsample': 0.8097785063704941, 'l2_leaf_reg': 0.005106683657088887}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:22:36,573] Trial 20 finished with value: 0.6149584487534626 and parameters: {'learning_rate': 0.015080152705438225, 'depth': 6, 'min_data_in_leaf': 11, 'subsample': 0.8145405124384274, 'l2_leaf_reg': 0.00010719547775454871}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:22:42,319] Trial 21 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.02513788752242426, 'depth': 4, 'min_data_in_leaf': 6, 'subsample': 0.7681115739246588, 'l2_leaf_reg': 0.006767893868288521}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:22:48,930] Trial 22 finished with value: 0.6357308584686775 and parameters: {'learning_rate': 0.01578846732470044, 'depth': 4, 'min_data_in_leaf': 5, 'subsample': 0.76715586245197, 'l2_leaf_reg': 0.002174440374034999}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:23:05,022] Trial 23 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.010397292182268125, 'depth': 5, 'min_data_in_leaf': 19, 'subsample': 0.7097617148103025, 'l2_leaf_reg': 0.09251051373633515}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:23:27,666] Trial 24 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.010050300557112533, 'depth': 5, 'min_data_in_leaf': 21, 'subsample': 0.7010015367537026, 'l2_leaf_reg': 0.057326918817116476}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:23:38,220] Trial 25 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.010805004602747048, 'depth': 4, 'min_data_in_leaf': 17, 'subsample': 0.7038564200783467, 'l2_leaf_reg': 0.1823768502944538}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:23:41,312] Trial 26 finished with value: 0.6060606060606061 and parameters: {'learning_rate': 0.025816089782249453, 'depth': 5, 'min_data_in_leaf': 28, 'subsample': 0.6636845062543022, 'l2_leaf_reg': 0.00011558458284973584}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:23:46,077] Trial 27 finished with value: 0.6485148514851485 and parameters: {'learning_rate': 0.04178491444960629, 'depth': 4, 'min_data_in_leaf': 14, 'subsample': 0.6024634195286453, 'l2_leaf_reg': 7.710896435575446}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:23:50,558] Trial 28 finished with value: 0.6568627450980392 and parameters: {'learning_rate': 0.03586504984147306, 'depth': 5, 'min_data_in_leaf': 26, 'subsample': 0.7197548721498218, 'l2_leaf_reg': 0.0862926495153796}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:23:55,643] Trial 29 finished with value: 0.6487935656836461 and parameters: {'learning_rate': 0.013644002567552724, 'depth': 4, 'min_data_in_leaf': 22, 'subsample': 0.7722107517984316, 'l2_leaf_reg': 4.041678905299283e-06}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:23:59,344] Trial 30 finished with value: 0.6512820512820513 and parameters: {'learning_rate': 0.0254659192048124, 'depth': 3, 'min_data_in_leaf': 33, 'subsample': 0.8294528425719166, 'l2_leaf_reg': 0.00024136081412801317}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:24:08,809] Trial 31 finished with value: 0.6478149100257069 and parameters: {'learning_rate': 0.010154958023381563, 'depth': 5, 'min_data_in_leaf': 19, 'subsample': 0.6759652109105023, 'l2_leaf_reg': 0.03926263192353147}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[I 2025-10-19 21:24:16,919] Trial 32 finished with value: 0.6451612903225806 and parameters: {'learning_rate': 0.011890568634683268, 'depth': 6, 'min_data_in_leaf': 22, 'subsample': 0.710023453303898, 'l2_leaf_reg': 0.003663814368533419}. Best is trial 11 with value: 0.6666666666666666.\n",
      "[W 2025-10-20 07:28:32,563] Trial 33 failed with parameters: {'learning_rate': 0.010056607155120132, 'depth': 5, 'min_data_in_leaf': 48, 'subsample': 0.7564498858303831, 'l2_leaf_reg': 1.1295095931677217} because of the following error: KeyboardInterrupt('').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\takumi_inoue\\projects\\github\\TakumiInoue0628\\manufacturing-dx-purchase-prediction\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\takumi_inoue\\AppData\\Local\\Temp\\ipykernel_19848\\731976496.py\", line 73, in objective\n",
      "    model.fit(X_train_fold, y_train_fold,\n",
      "  File \"c:\\Users\\takumi_inoue\\projects\\github\\TakumiInoue0628\\manufacturing-dx-purchase-prediction\\venv\\Lib\\site-packages\\catboost\\core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"c:\\Users\\takumi_inoue\\projects\\github\\TakumiInoue0628\\manufacturing-dx-purchase-prediction\\venv\\Lib\\site-packages\\catboost\\core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"c:\\Users\\takumi_inoue\\projects\\github\\TakumiInoue0628\\manufacturing-dx-purchase-prediction\\venv\\Lib\\site-packages\\catboost\\core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n",
      "[W 2025-10-20 07:28:32,626] Trial 33 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     14\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_float(\u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m0.01\u001b[39m, \u001b[32m0.1\u001b[39m, log=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m     15\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mdepth\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_int(\u001b[33m'\u001b[39m\u001b[33mdepth\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m10\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m         \u001b[33m'\u001b[39m\u001b[33ml2_leaf_reg\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_float(\u001b[33m'\u001b[39m\u001b[33ml2_leaf_reg\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m1e-8\u001b[39m, \u001b[32m10.0\u001b[39m, log=\u001b[38;5;28;01mTrue\u001b[39;00m), \u001b[38;5;66;03m# L2正則化\u001b[39;00m\n\u001b[32m     19\u001b[39m     }\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# CatBoostモデルの最適化実行\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m ctb_results = \u001b[43moptimize_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcatboost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mctb_params_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdefine_params_func\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefine_ctb_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\n\u001b[32m     29\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 88\u001b[39m, in \u001b[36moptimize_model\u001b[39m\u001b[34m(X_train, y_train, model_name, params_base, define_params_func, n_folds, n_trials, early_stopping_rounds, thresholds, random_state)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# Optunaによる最適化実行\u001b[39;00m\n\u001b[32m     87\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Optimization Finished ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     91\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest trial for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\takumi_inoue\\projects\\github\\TakumiInoue0628\\manufacturing-dx-purchase-prediction\\venv\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\takumi_inoue\\projects\\github\\TakumiInoue0628\\manufacturing-dx-purchase-prediction\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\takumi_inoue\\projects\\github\\TakumiInoue0628\\manufacturing-dx-purchase-prediction\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\takumi_inoue\\projects\\github\\TakumiInoue0628\\manufacturing-dx-purchase-prediction\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:258\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    254\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    255\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    257\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\takumi_inoue\\projects\\github\\TakumiInoue0628\\manufacturing-dx-purchase-prediction\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 73\u001b[39m, in \u001b[36moptimize_model.<locals>.objective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m model_name == \u001b[33m\"\u001b[39m\u001b[33mcatboost\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     72\u001b[39m     model = CatBoostClassifier(**params)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m                \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_valid_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid_fold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m                \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m                \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsupported model_name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\takumi_inoue\\projects\\github\\TakumiInoue0628\\manufacturing-dx-purchase-prediction\\venv\\Lib\\site-packages\\catboost\\core.py:5245\u001b[39m, in \u001b[36mCatBoostClassifier.fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   5242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m   5243\u001b[39m     CatBoostClassifier._check_is_compatible_loss(params[\u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m5245\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5246\u001b[39m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5247\u001b[39m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\takumi_inoue\\projects\\github\\TakumiInoue0628\\manufacturing-dx-purchase-prediction\\venv\\Lib\\site-packages\\catboost\\core.py:2410\u001b[39m, in \u001b[36mCatBoost._fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   2407\u001b[39m allow_clear_pool = train_params[\u001b[33m\"\u001b[39m\u001b[33mallow_clear_pool\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2409\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[33m'\u001b[39m\u001b[33mTraining plots\u001b[39m\u001b[33m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m.get_params())]):\n\u001b[32m-> \u001b[39m\u001b[32m2410\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_sets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minit_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2418\u001b[39m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[32m   2419\u001b[39m loss = \u001b[38;5;28mself\u001b[39m._object._get_loss_function_name()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\takumi_inoue\\projects\\github\\TakumiInoue0628\\manufacturing-dx-purchase-prediction\\venv\\Lib\\site-packages\\catboost\\core.py:1790\u001b[39m, in \u001b[36m_CatBoostBase._train\u001b[39m\u001b[34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_trained_model_attributes()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5023\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5072\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 基本パラメータ\n",
    "ctb_params_base = {\n",
    "    'objective': 'Logloss', # CatBoostでは'Logloss'を指定\n",
    "        'iterations': 1000,\n",
    "        'scale_pos_weight': (y_train_df == 0).sum() / (y_train_df == 1).sum(), # 不均衡データへの対処\n",
    "        'random_seed': 42,\n",
    "        'verbose': 0, # 学習ログを非表示\n",
    "        'early_stopping_rounds': 50 # 早期停止\n",
    "    }\n",
    "\n",
    "# 探索するパラメータを定義する「関数」\n",
    "def define_ctb_params(trial):\n",
    "    return {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True), # L2正則化\n",
    "    }\n",
    "\n",
    "# CatBoostモデルの最適化実行\n",
    "ctb_results = optimize_model(\n",
    "    X_train_df,\n",
    "    y_train_df,\n",
    "    model_name=\"catboost\",\n",
    "    params_base=ctb_params_base,\n",
    "    define_params_func=define_ctb_params,\n",
    "    n_trials=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa22c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start Ensemble Training ---\n",
      "Fold 1/5 started...\n",
      "Fold 2/5 started...\n",
      "Fold 3/5 started...\n",
      "Fold 4/5 started...\n",
      "Fold 5/5 started...\n",
      "--- Ensemble Training Finished ---\n",
      "\n",
      "--- Evaluation with OOF Predictions ---\n",
      "Best F1 score: 0.68493\n",
      "Best threshold: 0.49\n",
      "\n",
      "Individual Best F1 Scores (for reference):\n",
      "  LightGBM: 0.69474 (Threshold: 0.46)\n",
      "  XGBoost:  0.67895 (Threshold: 0.46)\n",
      "  CatBoost: 0.67848 (Threshold: 0.42)\n",
      "Ensemble submission file saved.\n",
      "\n",
      "--- LightGBM performed better than ensemble. Generating submission file... ---\n",
      "LightGBM submission file saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 最適化済みパラメータの設定\n",
    "lgb_best_params = lgbm_results['best_params']\n",
    "xgb_best_params = xgb_results['best_params']\n",
    "cat_best_params = ctb_results['best_params']\n",
    "\n",
    "# アンサンブルモデルの学習と予測 ---\n",
    "# K-Foldの設定\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "early_stopping_rounds = 50\n",
    "\n",
    "# OOF (Out-of-Fold) 予測値を格納する配列\n",
    "n_trains = X_train_df.shape[0]\n",
    "oof_preds_lgb = np.zeros(n_trains)\n",
    "oof_preds_xgb = np.zeros(n_trains)\n",
    "oof_preds_cat = np.zeros(n_trains)\n",
    "\n",
    "# テストデータに対する予測値を格納する配列\n",
    "# 各Foldで学習したモデルの予測値の平均を取る\n",
    "n_tests = X_test_df.shape[0]\n",
    "test_preds_lgb = np.zeros(n_tests)\n",
    "test_preds_xgb = np.zeros(n_tests)\n",
    "test_preds_cat = np.zeros(n_tests)\n",
    "\n",
    "\n",
    "print(\"--- Start Ensemble Training ---\")\n",
    "for fold, (train_idx, valid_idx) in enumerate(folds.split(X_train_df, y_train_df)):\n",
    "    print(f\"Fold {fold+1}/{folds.n_splits} started...\")\n",
    "    X_train_fold, y_train_fold = X_train_df.iloc[train_idx], y_train_df.iloc[train_idx]\n",
    "    X_valid_fold, y_valid_fold = X_train_df.iloc[valid_idx], y_train_df.iloc[valid_idx]\n",
    "    # --- LightGBM ---\n",
    "    lgb_model = lgb.LGBMClassifier(**lgb_best_params)\n",
    "    lgb_model.fit(X_train_fold, y_train_fold,\n",
    "                  eval_set=[(X_valid_fold, y_valid_fold)],\n",
    "                  callbacks=[lgb.early_stopping(early_stopping_rounds, verbose=False)])\n",
    "    oof_preds_lgb[valid_idx] = lgb_model.predict_proba(X_valid_fold)[:, 1]\n",
    "    test_preds_lgb += lgb_model.predict_proba(X_test_df)[:, 1] / folds.n_splits\n",
    "    # --- XGBoost ---\n",
    "    # XGBoost v2.0.0以降ではearly_stopping_roundsはfitの引数ではなくなりました\n",
    "    # コンストラクタで設定します\n",
    "    xgb_best_params['early_stopping_rounds'] = early_stopping_rounds\n",
    "    xgb_model = xgb.XGBClassifier(**xgb_best_params)\n",
    "    xgb_model.fit(X_train_fold, y_train_fold,\n",
    "                  eval_set=[(X_valid_fold, y_valid_fold)],\n",
    "                  verbose=False)\n",
    "    oof_preds_xgb[valid_idx] = xgb_model.predict_proba(X_valid_fold)[:, 1]\n",
    "    test_preds_xgb += xgb_model.predict_proba(X_test_df)[:, 1] / folds.n_splits\n",
    "    # --- CatBoost ---\n",
    "    cat_model = CatBoostClassifier(**cat_best_params)\n",
    "    cat_model.fit(X_train_fold, y_train_fold,\n",
    "                  eval_set=[(X_valid_fold, y_valid_fold)],\n",
    "                  use_best_model=True,\n",
    "                  early_stopping_rounds=early_stopping_rounds)\n",
    "    oof_preds_cat[valid_idx] = cat_model.predict_proba(X_valid_fold)[:, 1]\n",
    "    test_preds_cat += cat_model.predict_proba(X_test_df)[:, 1] / folds.n_splits\n",
    "print(\"--- Ensemble Training Finished ---\")\n",
    "\n",
    "\n",
    "# アンサンブル予測と評価\n",
    "# 各モデルのOOF予測値を平均して、アンサンブルのOOF予測値とする\n",
    "oof_preds_ensemble = (oof_preds_lgb + oof_preds_xgb + oof_preds_cat) / 3\n",
    "# F1スコアを最大化する最適な閾値を探す\n",
    "thresholds = np.arange(0.1, 0.5, 0.01)\n",
    "f1_scores = [f1_score(y_train_df, (oof_preds_ensemble > t).astype(int)) for t in thresholds]\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "best_f1_score = np.max(f1_scores)\n",
    "print(\"\\n--- Evaluation with OOF Predictions ---\")\n",
    "print(f\"Best F1 score: {best_f1_score:.5f}\")\n",
    "print(f\"Best threshold: {best_threshold:.2f}\")\n",
    "# 各モデル単体の最適な閾値とF1スコアを計算\n",
    "f1_scores_lgb = [f1_score(y_train_df, (oof_preds_lgb > t).astype(int)) for t in thresholds]\n",
    "best_threshold_lgb = thresholds[np.argmax(f1_scores_lgb)]\n",
    "best_f1_lgb = np.max(f1_scores_lgb)\n",
    "f1_scores_xgb = [f1_score(y_train_df, (oof_preds_xgb > t).astype(int)) for t in thresholds]\n",
    "best_threshold_xgb = thresholds[np.argmax(f1_scores_xgb)]\n",
    "best_f1_xgb = np.max(f1_scores_xgb)\n",
    "f1_scores_cat = [f1_score(y_train_df, (oof_preds_cat > t).astype(int)) for t in thresholds]\n",
    "best_threshold_cat = thresholds[np.argmax(f1_scores_cat)]\n",
    "best_f1_cat = np.max(f1_scores_cat)\n",
    "print(f\"\\nIndividual Best F1 Scores (for reference):\")\n",
    "print(f\"  LightGBM: {best_f1_lgb:.5f} (Threshold: {best_threshold_lgb:.2f})\")\n",
    "print(f\"  XGBoost:  {best_f1_xgb:.5f} (Threshold: {best_threshold_xgb:.2f})\")\n",
    "print(f\"  CatBoost: {best_f1_cat:.5f} (Threshold: {best_threshold_cat:.2f})\")\n",
    "\n",
    "# 最終的なテストデータ予測\n",
    "# テストデータに対する予測も平均化\n",
    "test_preds_ensemble = (test_preds_lgb + test_preds_xgb + test_preds_cat) / 3\n",
    "# 最適な閾値で0/1に変換\n",
    "final_predictions = (test_preds_ensemble > best_threshold).astype(int)\n",
    "# 提出用ファイルの作成\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%m%d%H%M\")\n",
    "submit_df_ensemble = sample_submit.copy()\n",
    "submit_df_ensemble[1] = final_predictions\n",
    "submit_df_ensemble.to_csv('submission_'+timestamp+'.csv', index=False, header=False)\n",
    "print(f\"Ensemble submission file saved.\")\n",
    "\n",
    "# 単体モデルの提出ファイル生成（アンサンブルを上回った場合）\n",
    "# LightGBM\n",
    "if best_f1_lgb > best_f1_score:\n",
    "    print(\"\\n--- LightGBM performed better than ensemble. Generating submission file... ---\")\n",
    "    final_predictions_lgb = (test_preds_lgb > best_threshold_lgb).astype(int)\n",
    "    submit_df_lgb = sample_submit.copy()\n",
    "    submit_df_lgb[1] = final_predictions_lgb\n",
    "    submit_df_lgb.to_csv('submission_lgb_'+timestamp+'.csv', index=False, header=False)\n",
    "    print(f\"LightGBM submission file saved.\")\n",
    "# XGBoost\n",
    "if best_f1_xgb > best_f1_score:\n",
    "    print(\"\\n--- XGBoost performed better than ensemble. Generating submission file... ---\")\n",
    "    final_predictions_xgb = (test_preds_xgb > best_threshold_xgb).astype(int)\n",
    "    submit_df_xgb = sample_submit.copy()\n",
    "    submit_df_xgb[1] = final_predictions_xgb\n",
    "    submit_df_xgb.to_csv('submission_xgb_'+timestamp+'.csv', index=False, header=False)\n",
    "    print(f\"XGBoost submission file saved.\")\n",
    "# CatBoost\n",
    "if best_f1_cat > best_f1_score:\n",
    "    print(\"\\n--- CatBoost performed better than ensemble. Generating submission file... ---\")\n",
    "    final_predictions_cat = (test_preds_cat > best_threshold_cat).astype(int)\n",
    "    submit_df_cat = sample_submit.copy()\n",
    "    submit_df_cat[1] = final_predictions_cat\n",
    "    submit_df_cat.to_csv('submission_cat_'+timestamp+'.csv', index=False, header=False)\n",
    "    print(f\"CatBoost submission file saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ad2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 企業概要に対するTF-IDFの追加 ---\n",
    "tfidf_desc_vectorizer = TfidfVectorizer(max_features=50, ngram_range=(1, 2)) # 特徴量は50個に絞る\n",
    "all_desc_text = pd.concat([train_df['企業概要'], test_df['企業概要']])\n",
    "tfidf_desc_vectorizer.fit(all_desc_text)\n",
    "\n",
    "train_tfidf_desc = tfidf_desc_vectorizer.transform(train_df['企業概要']).toarray()\n",
    "test_tfidf_desc = tfidf_desc_vectorizer.transform(test_df['企業概要']).toarray()\n",
    "\n",
    "train_tfidf_desc_df = pd.DataFrame(train_tfidf_desc, columns=[f'tfidf_desc_{i}' for i in range(train_tfidf_desc.shape[1])])\n",
    "test_tfidf_desc_df = pd.DataFrame(test_tfidf_desc, columns=[f'tfidf_desc_{i}' for i in range(test_tfidf_desc.shape[1])])\n",
    "\n",
    "# 既存のデータフレームと結合\n",
    "X_train = pd.concat([X_train, train_tfidf_desc_df], axis=1)\n",
    "X_test = pd.concat([X_test, test_tfidf_desc_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f8dd658",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, encoders = encode_categorical(train, ['業界', '上場種別', '特徴'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e33d8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'業界': LabelEncoder(), '上場種別': LabelEncoder(), '特徴': LabelEncoder()}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed586b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習に使用する特徴量の数: 44\n",
      "学習データのサイズ: (742, 44)\n",
      "テストデータのサイズ: (800, 44)\n",
      "学習データの購入フラグ1の数: 179\n",
      "学習データの購入フラグ0の数: 563\n",
      "購入フラグ1の割合: 0.2412\n"
     ]
    }
   ],
   "source": [
    "# 特徴量エンジニアリング関数\n",
    "def feature_engineering(df):\n",
    "    \"\"\"財務指標などを追加する関数\"\"\"\n",
    "    # 財務指標の作成 (分母が0になる可能性を考慮)\n",
    "    df['自己資本比率'] = df['自己資本'] / (df['総資産'] + 1e-6)\n",
    "    df['売上高営業利益率'] = df['営業利益'] / (df['売上'] + 1e-6)\n",
    "    df['総資産回転率'] = df['売上'] / (df['総資産'] + 1e-6)\n",
    "    df['負債比率'] = df['負債'] / (df['自己資本'] + 1e-6)\n",
    "    # 新しい特徴量を追加\n",
    "    df['従業員数_x_売上高営業利益率'] = df['従業員数'] * df['売上高営業利益率']\n",
    "    # アンケートの平均と標準偏差を追加\n",
    "    zenkaku_table = str.maketrans('0123456789', '０１２３４５６７８９')\n",
    "    survey_cols = [f\"アンケート{str(i).translate(zenkaku_table)}\" for i in range(1, 12)]\n",
    "    df['アンケート_平均'] = df[survey_cols].mean(axis=1)\n",
    "    df['アンケート_標準偏差'] = df[survey_cols].std(axis=1)\n",
    "    # 欠損値を-9999で埋める (LightGBMは欠損値を扱えるが、比率計算でのNaN/infに対応)\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.fillna(-9999, inplace=True)\n",
    "    return df\n",
    "\n",
    "# train/testに特徴量エンジニアリングを適用\n",
    "train_df = feature_engineering(train.copy())\n",
    "test_df = feature_engineering(test.copy())\n",
    "\n",
    "# カテゴリ変数のエンコーディング\n",
    "categorical_features = ['業界', '上場種別', '特徴']\n",
    "for col in categorical_features:\n",
    "    # trainとtestを結合して語彙を作成し、未知のカテゴリに対応\n",
    "    combined_data = pd.concat([train_df[col], test_df[col]]).astype(str)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(combined_data)\n",
    "    train_df[col] = le.transform(train_df[col].astype(str))\n",
    "    test_df[col] = le.transform(test_df[col].astype(str))\n",
    "\n",
    "# 特徴量とターゲットの定義\n",
    "target = '購入フラグ'\n",
    "# テキストデータやIDなど、学習から除外するカラム\n",
    "drop_cols = ['企業ID', '企業名', '企業概要', '組織図', '今後のDX展望', '購入フラグ']\n",
    "# trainとtestで共通して存在するカラムのみを特徴量として使用\n",
    "common_cols = list(set(train_df.columns) & set(test_df.columns))\n",
    "features = [col for col in common_cols if col not in drop_cols]\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[target]\n",
    "X_test = test_df[features]\n",
    "\n",
    "print(f\"学習に使用する特徴量の数: {len(features)}\")\n",
    "print(f\"学習データのサイズ: {X_train.shape}\")\n",
    "print(f\"テストデータのサイズ: {X_test.shape}\")\n",
    "\n",
    "# 学習データの購入フラグ1と0の数と割合を表示\n",
    "y_train_positive = (y_train==1).sum()\n",
    "y_train_negative = (y_train==0).sum()\n",
    "print(f\"学習データの購入フラグ1の数: {y_train_positive}\")\n",
    "print(f\"学習データの購入フラグ0の数: {y_train_negative}\")\n",
    "print(f\"購入フラグ1の割合: {y_train_positive / len(y_train):.4f}\")\n",
    "\n",
    "# 学習時のpositiveデータの重要度を引き上げる\n",
    "scale_pos_weight = y_train_negative / y_train_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc5b37ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習に使用する特徴量の数: 144\n",
      "学習データのサイズ: (742, 144)\n",
      "テストデータのサイズ: (800, 144)\n"
     ]
    }
   ],
   "source": [
    "# テキストデータの特徴量化\n",
    "\n",
    "# TF-IDFの適用 (今後のDX展望)\n",
    "#tfidf = TfidfVectorizer(max_features=50) # まずは50個の重要単語に絞る\n",
    "#train_text_features = tfidf.fit_transform(train_df['今後のDX展望']).toarray()\n",
    "#test_text_features = tfidf.transform(test_df['今後のDX展望']).toarray()\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=100, ngram_range=(1, 2)) # 100個の重要単語・バイグラムも考慮\n",
    "all_text = pd.concat([train_df['今後のDX展望'], test_df['今後のDX展望']])\n",
    "tfidf_vectorizer.fit(all_text)\n",
    "train_tfidf_features = tfidf_vectorizer.transform(train_df['今後のDX展望']).toarray()\n",
    "test_tfidf_features = tfidf_vectorizer.transform(test_df['今後のDX展望']).toarray()\n",
    "\n",
    "# 特徴量データフレームに変換\n",
    "#train_text_df = pd.DataFrame(train_text_features, columns=[f'tfidf_{i}' for i in range(train_text_features.shape[1])])\n",
    "#test_text_df = pd.DataFrame(test_text_features, columns=[f'tfidf_{i}' for i in range(test_text_features.shape[1])])\n",
    "train_tfidf_df = pd.DataFrame(train_tfidf_features, columns=[f'tfidf_outlook_{i}' for i in range(train_tfidf_features.shape[1])])\n",
    "test_tfidf_df = pd.DataFrame(test_tfidf_features, columns=[f'tfidf_outlook_{i}' for i in range(test_tfidf_features.shape[1])])\n",
    "\n",
    "# 元のデータと結合\n",
    "#X_train = pd.concat([X_train, train_text_df], axis=1)\n",
    "#X_test = pd.concat([X_test, test_text_df], axis=1)\n",
    "X_train = pd.concat([X_train, train_tfidf_df], axis=1)\n",
    "X_test = pd.concat([X_test, test_tfidf_df], axis=1)\n",
    "\n",
    "# featureリストも更新\n",
    "features = list(X_train.columns)\n",
    "\n",
    "print(f\"学習に使用する特徴量の数: {len(features)}\")\n",
    "print(f\"学習データのサイズ: {X_train.shape}\")\n",
    "print(f\"テストデータのサイズ: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b5f0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習に使用する特徴量の数: 196\n",
      "学習データのサイズ: (742, 196)\n",
      "テストデータのサイズ: (800, 196)\n"
     ]
    }
   ],
   "source": [
    "# --- 企業概要に対するTF-IDFの追加 ---\n",
    "tfidf_desc_vectorizer = TfidfVectorizer(max_features=50, ngram_range=(1, 2)) # 特徴量は50個に絞る\n",
    "all_desc_text = pd.concat([train_df['企業概要'], test_df['企業概要']])\n",
    "tfidf_desc_vectorizer.fit(all_desc_text)\n",
    "\n",
    "train_tfidf_desc = tfidf_desc_vectorizer.transform(train_df['企業概要']).toarray()\n",
    "test_tfidf_desc = tfidf_desc_vectorizer.transform(test_df['企業概要']).toarray()\n",
    "\n",
    "train_tfidf_desc_df = pd.DataFrame(train_tfidf_desc, columns=[f'tfidf_desc_{i}' for i in range(train_tfidf_desc.shape[1])])\n",
    "test_tfidf_desc_df = pd.DataFrame(test_tfidf_desc, columns=[f'tfidf_desc_{i}' for i in range(test_tfidf_desc.shape[1])])\n",
    "\n",
    "# 既存のデータフレームと結合\n",
    "X_train = pd.concat([X_train, train_tfidf_desc_df], axis=1)\n",
    "X_test = pd.concat([X_test, test_tfidf_desc_df], axis=1)\n",
    "\n",
    "\n",
    "# --- DX展望の簡易的な感情分析特徴量の追加 ---\n",
    "# ポジティブな単語とネガティブな単語を定義\n",
    "positive_words = ['積極', '強化', '推進', '投資', '拡大', '創出']\n",
    "negative_words = ['慎重', '課題', '懸念', '限定的', '検討']\n",
    "\n",
    "# 各単語の出現回数をカウント\n",
    "for word in positive_words:\n",
    "    train_df[f'word_{word}'] = train_df['今後のDX展望'].str.count(word)\n",
    "    test_df[f'word_{word}'] = test_df['今後のDX展望'].str.count(word)\n",
    "\n",
    "for word in negative_words:\n",
    "    train_df[f'word_{word}'] = train_df['今後のDX展望'].str.count(word)\n",
    "    test_df[f'word_{word}'] = test_df['今後のDX展望'].str.count(word)\n",
    "\n",
    "# ポジティブ/ネガティブスコアを作成\n",
    "X_train['positive_score'] = train_df[[f'word_{w}' for w in positive_words]].sum(axis=1)\n",
    "X_test['positive_score'] = test_df[[f'word_{w}' for w in positive_words]].sum(axis=1)\n",
    "X_train['negative_score'] = train_df[[f'word_{w}' for w in negative_words]].sum(axis=1)\n",
    "X_test['negative_score'] = test_df[[f'word_{w}' for w in negative_words]].sum(axis=1)\n",
    "\n",
    "# featureリストも更新\n",
    "features = list(X_train.columns)\n",
    "\n",
    "print(f\"学習に使用する特徴量の数: {len(features)}\")\n",
    "print(f\"学習データのサイズ: {X_train.shape}\")\n",
    "print(f\"テストデータのサイズ: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5b8ece",
   "metadata": {},
   "source": [
    "モデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a89f7998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 143, number of negative: 450\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7032\n",
      "[LightGBM] [Info] Number of data points in the train set: 593, number of used features: 181\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241147 -> initscore=-1.146403\n",
      "[LightGBM] [Info] Start training from score -1.146403\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 143, number of negative: 450\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6931\n",
      "[LightGBM] [Info] Number of data points in the train set: 593, number of used features: 177\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241147 -> initscore=-1.146403\n",
      "[LightGBM] [Info] Start training from score -1.146403\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 144, number of negative: 450\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7018\n",
      "[LightGBM] [Info] Number of data points in the train set: 594, number of used features: 180\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242424 -> initscore=-1.139434\n",
      "[LightGBM] [Info] Start training from score -1.139434\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 143, number of negative: 451\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6977\n",
      "[LightGBM] [Info] Number of data points in the train set: 594, number of used features: 179\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240741 -> initscore=-1.148623\n",
      "[LightGBM] [Info] Start training from score -1.148623\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 143, number of negative: 451\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6978\n",
      "[LightGBM] [Info] Number of data points in the train set: 594, number of used features: 175\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240741 -> initscore=-1.148623\n",
      "[LightGBM] [Info] Start training from score -1.148623\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "------------------------------\n",
      "OOF（Out-of-Fold）予測でのベストF1スコア: 0.6280\n",
      "ベストスコアを達成した閾値: 0.34\n"
     ]
    }
   ],
   "source": [
    "# LightGBMモデルの学習（StratifiedKFoldによる交差検証）\n",
    "NFOLDS = 5\n",
    "folds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=42)\n",
    "oof_preds = np.zeros(train_df.shape[0])\n",
    "sub_preds = np.zeros(test_df.shape[0])\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_valid_fold, y_valid_fold = X_train.iloc[valid_idx], y_train.iloc[valid_idx]\n",
    "\n",
    "    # LightGBMのパラメータ設定\n",
    "    # is_unbalance=True または scale_pos_weight を追加\n",
    "    model = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        metric='binary_logloss',\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.01,\n",
    "        num_leaves=31,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        colsample_bytree=0.8,\n",
    "        subsample=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        # === ここを追加 ===\n",
    "        is_unbalance=True,\n",
    "        #scale_pos_weight=scale_pos_weight  # (陰性サンプル数 / 陽性サンプル数)\n",
    "        min_child_samples=10,\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_fold, y_train_fold,\n",
    "              eval_set=[(X_valid_fold, y_valid_fold)],\n",
    "              eval_metric='logloss',\n",
    "              callbacks=[lgb.early_stopping(100, verbose=False)])\n",
    "\n",
    "    oof_preds[valid_idx] = model.predict_proba(X_valid_fold)[:, 1]\n",
    "    sub_preds += model.predict_proba(X_test)[:, 1] / folds.n_splits\n",
    "    \n",
    "    # 特徴量重要度の保存\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = model.feature_importances_\n",
    "    fold_importance_df[\"fold\"] = n_fold + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "\n",
    "print(\"-\" * 30)\n",
    "# --- 最適な閾値の探索 ---\n",
    "thresholds = np.arange(0.1, 0.5, 0.01)\n",
    "f1_scores = [f1_score(y_train, (oof_preds > t).astype(int)) for t in thresholds]\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "best_f1 = np.max(f1_scores)\n",
    "\n",
    "print(f\"OOF（Out-of-Fold）予測でのベストF1スコア: {best_f1:.4f}\")\n",
    "print(f\"ベストスコアを達成した閾値: {best_threshold:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd338b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "OOF（Out-of-Fold）予測でのベストF1スコア: 0.6109\n",
    "ベストスコアを達成した閾値: 0.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7ed0fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-17 00:49:56,340] A new study created in memory with name: no-name-e45d2f0f-69c0-4921-ba85-e027a07c6ddd\n",
      "[I 2025-10-17 00:49:58,878] Trial 0 finished with value: 0.6558139534883721 and parameters: {'learning_rate': 0.010098354336778663, 'num_leaves': 66, 'max_depth': 6, 'min_child_samples': 40, 'subsample': 0.9462852032422089, 'colsample_bytree': 0.9858667034847988, 'reg_alpha': 0.005710096579921643, 'reg_lambda': 0.007618058451519296}. Best is trial 0 with value: 0.6558139534883721.\n",
      "[I 2025-10-17 00:50:00,079] Trial 1 finished with value: 0.6617647058823529 and parameters: {'learning_rate': 0.028382926903424865, 'num_leaves': 49, 'max_depth': 11, 'min_child_samples': 40, 'subsample': 0.6068137866664104, 'colsample_bytree': 0.8905093443075198, 'reg_alpha': 7.300082402069525e-06, 'reg_lambda': 3.010627941031705e-06}. Best is trial 1 with value: 0.6617647058823529.\n",
      "[I 2025-10-17 00:50:00,919] Trial 2 finished with value: 0.6618004866180048 and parameters: {'learning_rate': 0.05935666882733018, 'num_leaves': 74, 'max_depth': 4, 'min_child_samples': 58, 'subsample': 0.6979511264371474, 'colsample_bytree': 0.6918337550656879, 'reg_alpha': 8.230277722949304e-06, 'reg_lambda': 0.07750139774850584}. Best is trial 2 with value: 0.6618004866180048.\n",
      "[I 2025-10-17 00:50:01,754] Trial 3 finished with value: 0.6580976863753213 and parameters: {'learning_rate': 0.04433766771073496, 'num_leaves': 64, 'max_depth': 6, 'min_child_samples': 55, 'subsample': 0.9583892700434483, 'colsample_bytree': 0.8455225036348119, 'reg_alpha': 3.352276596511742e-08, 'reg_lambda': 1.8143586436748236}. Best is trial 2 with value: 0.6618004866180048.\n",
      "[I 2025-10-17 00:50:02,941] Trial 4 finished with value: 0.6576576576576577 and parameters: {'learning_rate': 0.030822636081012444, 'num_leaves': 74, 'max_depth': 11, 'min_child_samples': 75, 'subsample': 0.8991746167714385, 'colsample_bytree': 0.7927194697569915, 'reg_alpha': 3.648785747408321e-08, 'reg_lambda': 0.09389421154019718}. Best is trial 2 with value: 0.6618004866180048.\n",
      "[I 2025-10-17 00:50:03,442] Trial 5 finished with value: 0.6433566433566433 and parameters: {'learning_rate': 0.07846254790062719, 'num_leaves': 36, 'max_depth': 12, 'min_child_samples': 90, 'subsample': 0.7321407578445907, 'colsample_bytree': 0.9429880433644996, 'reg_alpha': 7.510906590845694, 'reg_lambda': 8.88451818546748e-06}. Best is trial 2 with value: 0.6618004866180048.\n",
      "[I 2025-10-17 00:50:04,196] Trial 6 finished with value: 0.657074340527578 and parameters: {'learning_rate': 0.06451710283093588, 'num_leaves': 39, 'max_depth': 5, 'min_child_samples': 63, 'subsample': 0.9315320412173421, 'colsample_bytree': 0.6308006534208122, 'reg_alpha': 0.005817001797758196, 'reg_lambda': 0.5720600514335}. Best is trial 2 with value: 0.6618004866180048.\n",
      "[I 2025-10-17 00:50:04,995] Trial 7 finished with value: 0.6635071090047393 and parameters: {'learning_rate': 0.06760338286522281, 'num_leaves': 71, 'max_depth': 3, 'min_child_samples': 23, 'subsample': 0.8028988648280347, 'colsample_bytree': 0.6626540430604418, 'reg_alpha': 1.090355729028211e-05, 'reg_lambda': 0.000223964270134175}. Best is trial 7 with value: 0.6635071090047393.\n",
      "[I 2025-10-17 00:50:05,621] Trial 8 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.06772083527609242, 'num_leaves': 36, 'max_depth': 3, 'min_child_samples': 47, 'subsample': 0.8903245391694916, 'colsample_bytree': 0.827717764843285, 'reg_alpha': 0.04095243452534754, 'reg_lambda': 0.11936449184836254}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:07,089] Trial 9 finished with value: 0.6540284360189573 and parameters: {'learning_rate': 0.02028981203377143, 'num_leaves': 58, 'max_depth': 5, 'min_child_samples': 73, 'subsample': 0.9772183796817622, 'colsample_bytree': 0.8237648157568641, 'reg_alpha': 1.4643182629865104e-05, 'reg_lambda': 0.4386060539619272}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:07,665] Trial 10 finished with value: 0.6483516483516484 and parameters: {'learning_rate': 0.09147584017356414, 'num_leaves': 22, 'max_depth': 8, 'min_child_samples': 16, 'subsample': 0.8383697403839465, 'colsample_bytree': 0.7497673836332981, 'reg_alpha': 4.598771819617123, 'reg_lambda': 1.754426273760609e-08}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:08,954] Trial 11 finished with value: 0.6650943396226415 and parameters: {'learning_rate': 0.04725859930772829, 'num_leaves': 31, 'max_depth': 3, 'min_child_samples': 12, 'subsample': 0.8352761134563716, 'colsample_bytree': 0.6013003626041058, 'reg_alpha': 0.044248837579337036, 'reg_lambda': 0.0015328212252484323}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:09,846] Trial 12 finished with value: 0.6595744680851063 and parameters: {'learning_rate': 0.046009910887450246, 'num_leaves': 23, 'max_depth': 3, 'min_child_samples': 8, 'subsample': 0.8636768946902955, 'colsample_bytree': 0.7482706613855404, 'reg_alpha': 0.0986246845430709, 'reg_lambda': 0.0015489283574375108}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:10,881] Trial 13 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.04327455256602441, 'num_leaves': 34, 'max_depth': 8, 'min_child_samples': 31, 'subsample': 0.7517005210180333, 'colsample_bytree': 0.6039447745706138, 'reg_alpha': 0.07876860871771285, 'reg_lambda': 5.912129283053401e-05}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:12,998] Trial 14 finished with value: 0.6480186480186481 and parameters: {'learning_rate': 0.021043351755960796, 'num_leaves': 45, 'max_depth': 8, 'min_child_samples': 34, 'subsample': 0.7464442573809367, 'colsample_bytree': 0.8777959287980139, 'reg_alpha': 0.2789744283609027, 'reg_lambda': 1.8971661531367654e-05}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:13,715] Trial 15 finished with value: 0.6487804878048781 and parameters: {'learning_rate': 0.09956273862570961, 'num_leaves': 32, 'max_depth': 9, 'min_child_samples': 31, 'subsample': 0.6375816167449639, 'colsample_bytree': 0.7251104783548581, 'reg_alpha': 0.00040313313735999194, 'reg_lambda': 3.5438784176540644e-07}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:15,549] Trial 16 finished with value: 0.6477024070021882 and parameters: {'learning_rate': 0.039012356538720296, 'num_leaves': 42, 'max_depth': 9, 'min_child_samples': 47, 'subsample': 0.7699196014465247, 'colsample_bytree': 0.7824932206814025, 'reg_alpha': 0.7440343346499544, 'reg_lambda': 6.4094918865970145}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:16,893] Trial 17 finished with value: 0.6543535620052771 and parameters: {'learning_rate': 0.05423002645795758, 'num_leaves': 55, 'max_depth': 7, 'min_child_samples': 23, 'subsample': 0.8918153032527047, 'colsample_bytree': 0.8977156067534571, 'reg_alpha': 0.0060975744173868045, 'reg_lambda': 9.362087960869881e-05}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:18,383] Trial 18 finished with value: 0.6455026455026455 and parameters: {'learning_rate': 0.023870456713466593, 'num_leaves': 28, 'max_depth': 10, 'min_child_samples': 97, 'subsample': 0.69161510539511, 'colsample_bytree': 0.6843647028152512, 'reg_alpha': 0.0003758178673876686, 'reg_lambda': 0.014358563173062923}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:20,394] Trial 19 finished with value: 0.6443298969072165 and parameters: {'learning_rate': 0.01586000206060493, 'num_leaves': 47, 'max_depth': 7, 'min_child_samples': 47, 'subsample': 0.7925413531346874, 'colsample_bytree': 0.84021080286131, 'reg_alpha': 0.028226005317934694, 'reg_lambda': 5.667161667367202e-07}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:21,442] Trial 20 finished with value: 0.6529680365296804 and parameters: {'learning_rate': 0.04069229270756069, 'num_leaves': 34, 'max_depth': 9, 'min_child_samples': 69, 'subsample': 0.9961270096125124, 'colsample_bytree': 0.9439100928578766, 'reg_alpha': 0.001717048236621317, 'reg_lambda': 0.0008661143196802162}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:22,518] Trial 21 finished with value: 0.6495726495726496 and parameters: {'learning_rate': 0.053778299830399515, 'num_leaves': 29, 'max_depth': 4, 'min_child_samples': 6, 'subsample': 0.8466750336320135, 'colsample_bytree': 0.6014204964030061, 'reg_alpha': 0.055257557199056374, 'reg_lambda': 0.007681427482946739}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:23,840] Trial 22 finished with value: 0.6649874055415617 and parameters: {'learning_rate': 0.03527596516347506, 'num_leaves': 27, 'max_depth': 4, 'min_child_samples': 18, 'subsample': 0.8243030075238683, 'colsample_bytree': 0.6022157505155247, 'reg_alpha': 0.7701307357068063, 'reg_lambda': 0.0001291525058126392}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:24,791] Trial 23 finished with value: 0.6873385012919897 and parameters: {'learning_rate': 0.07695074516306853, 'num_leaves': 39, 'max_depth': 3, 'min_child_samples': 30, 'subsample': 0.8915856859820709, 'colsample_bytree': 0.6497439382521284, 'reg_alpha': 0.018342465397323954, 'reg_lambda': 0.0014512535195673494}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:25,510] Trial 24 finished with value: 0.6814404432132964 and parameters: {'learning_rate': 0.07968175904152103, 'num_leaves': 40, 'max_depth': 5, 'min_child_samples': 30, 'subsample': 0.8919585475366564, 'colsample_bytree': 0.650322804079651, 'reg_alpha': 0.00011350068959882118, 'reg_lambda': 0.0313454717161185}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:26,165] Trial 25 finished with value: 0.6714628297362111 and parameters: {'learning_rate': 0.07717274770351905, 'num_leaves': 41, 'max_depth': 5, 'min_child_samples': 45, 'subsample': 0.908505094399216, 'colsample_bytree': 0.6641685699964797, 'reg_alpha': 5.936357494463923e-05, 'reg_lambda': 0.034458070707686736}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:26,858] Trial 26 finished with value: 0.6516290726817042 and parameters: {'learning_rate': 0.08141112089767363, 'num_leaves': 55, 'max_depth': 5, 'min_child_samples': 39, 'subsample': 0.9266233039684479, 'colsample_bytree': 0.657197661445815, 'reg_alpha': 7.92439954758859e-05, 'reg_lambda': 0.041247393307996885}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:27,611] Trial 27 finished with value: 0.6785714285714286 and parameters: {'learning_rate': 0.07758314767954856, 'num_leaves': 41, 'max_depth': 6, 'min_child_samples': 25, 'subsample': 0.8761878290006878, 'colsample_bytree': 0.7084019894325848, 'reg_alpha': 7.052290381819405e-05, 'reg_lambda': 0.004597793222800884}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:28,531] Trial 28 finished with value: 0.6631853785900783 and parameters: {'learning_rate': 0.08683243156132911, 'num_leaves': 44, 'max_depth': 6, 'min_child_samples': 24, 'subsample': 0.8850469639842788, 'colsample_bytree': 0.7135360312322311, 'reg_alpha': 4.970930160558407e-07, 'reg_lambda': 0.0008172190735051698}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:31,259] Trial 29 finished with value: 0.665158371040724 and parameters: {'learning_rate': 0.011456829448409617, 'num_leaves': 50, 'max_depth': 6, 'min_child_samples': 26, 'subsample': 0.864521461920151, 'colsample_bytree': 0.6464947309015497, 'reg_alpha': 3.0567159790281545e-07, 'reg_lambda': 0.0037418690679014857}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:31,907] Trial 30 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.07397730315603229, 'num_leaves': 39, 'max_depth': 4, 'min_child_samples': 38, 'subsample': 0.9409037804069234, 'colsample_bytree': 0.6982874068463313, 'reg_alpha': 0.0016169940491926572, 'reg_lambda': 0.007214718745705337}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:32,469] Trial 31 finished with value: 0.6721763085399449 and parameters: {'learning_rate': 0.09717417534876052, 'num_leaves': 41, 'max_depth': 5, 'min_child_samples': 33, 'subsample': 0.957910261422387, 'colsample_bytree': 0.6735178397155452, 'reg_alpha': 8.131755205068654e-05, 'reg_lambda': 0.027253833734812577}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:33,169] Trial 32 finished with value: 0.6863270777479893 and parameters: {'learning_rate': 0.08545921842465107, 'num_leaves': 52, 'max_depth': 7, 'min_child_samples': 32, 'subsample': 0.9589995683405819, 'colsample_bytree': 0.63320146900325, 'reg_alpha': 6.525470946014419e-05, 'reg_lambda': 0.3656161640954137}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:34,178] Trial 33 finished with value: 0.6449704142011834 and parameters: {'learning_rate': 0.0579891566982289, 'num_leaves': 52, 'max_depth': 7, 'min_child_samples': 18, 'subsample': 0.9216332613977852, 'colsample_bytree': 0.6335085438164212, 'reg_alpha': 1.6693326875767425e-06, 'reg_lambda': 1.018475554547957}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:35,195] Trial 34 finished with value: 0.6428571428571429 and parameters: {'learning_rate': 0.0699074870472249, 'num_leaves': 48, 'max_depth': 6, 'min_child_samples': 27, 'subsample': 0.9707572747078028, 'colsample_bytree': 0.62632392043386, 'reg_alpha': 0.0013249217750382915, 'reg_lambda': 0.20047463306074376}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:36,089] Trial 35 finished with value: 0.6558265582655827 and parameters: {'learning_rate': 0.0858509780530546, 'num_leaves': 63, 'max_depth': 6, 'min_child_samples': 40, 'subsample': 0.9990973037944475, 'colsample_bytree': 0.7402233375832836, 'reg_alpha': 2.954069032340514e-05, 'reg_lambda': 3.1085016792999824}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:37,007] Trial 36 finished with value: 0.6561085972850679 and parameters: {'learning_rate': 0.06145764601705688, 'num_leaves': 53, 'max_depth': 7, 'min_child_samples': 53, 'subsample': 0.8703571112301961, 'colsample_bytree': 0.703232348658638, 'reg_alpha': 3.4909088259347894e-06, 'reg_lambda': 0.23543812110015908}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:38,009] Trial 37 finished with value: 0.665 and parameters: {'learning_rate': 0.05015970977551262, 'num_leaves': 59, 'max_depth': 4, 'min_child_samples': 13, 'subsample': 0.9117852311379705, 'colsample_bytree': 0.639028450186496, 'reg_alpha': 0.00017005402680154308, 'reg_lambda': 0.0033556245171528706}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:38,587] Trial 38 finished with value: 0.6550868486352357 and parameters: {'learning_rate': 0.0777826115965868, 'num_leaves': 38, 'max_depth': 5, 'min_child_samples': 58, 'subsample': 0.9500868127133079, 'colsample_bytree': 0.7755908492482599, 'reg_alpha': 0.00041649067496881434, 'reg_lambda': 0.00037304369479198}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:39,411] Trial 39 finished with value: 0.6829268292682927 and parameters: {'learning_rate': 0.0631173729295851, 'num_leaves': 46, 'max_depth': 6, 'min_child_samples': 20, 'subsample': 0.8196035704583003, 'colsample_bytree': 0.6835035381756215, 'reg_alpha': 0.00932697841659977, 'reg_lambda': 0.07196879094912763}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:40,208] Trial 40 finished with value: 0.6682134570765661 and parameters: {'learning_rate': 0.062238225984662096, 'num_leaves': 70, 'max_depth': 3, 'min_child_samples': 83, 'subsample': 0.8108441018748754, 'colsample_bytree': 0.6797560961023162, 'reg_alpha': 0.005638040175240175, 'reg_lambda': 1.7719243899991532}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:40,893] Trial 41 finished with value: 0.6609686609686609 and parameters: {'learning_rate': 0.08827904080425211, 'num_leaves': 45, 'max_depth': 6, 'min_child_samples': 21, 'subsample': 0.8674042918294093, 'colsample_bytree': 0.6227037509368296, 'reg_alpha': 0.010670798232860657, 'reg_lambda': 0.05795552603401066}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:41,582] Trial 42 finished with value: 0.6543535620052771 and parameters: {'learning_rate': 0.07041628335804959, 'num_leaves': 47, 'max_depth': 7, 'min_child_samples': 35, 'subsample': 0.886129970791811, 'colsample_bytree': 0.6545687420646568, 'reg_alpha': 0.0009150325428904467, 'reg_lambda': 0.013049170922697797}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:42,321] Trial 43 finished with value: 0.6649746192893401 and parameters: {'learning_rate': 0.08003611306132559, 'num_leaves': 50, 'max_depth': 5, 'min_child_samples': 28, 'subsample': 0.7846926730672882, 'colsample_bytree': 0.7193096223450748, 'reg_alpha': 2.9042077071649553e-05, 'reg_lambda': 0.5148493861062445}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:43,101] Trial 44 finished with value: 0.6365795724465558 and parameters: {'learning_rate': 0.09903227472892177, 'num_leaves': 37, 'max_depth': 6, 'min_child_samples': 11, 'subsample': 0.852707119667568, 'colsample_bytree': 0.6948686677111688, 'reg_alpha': 0.014290347024488633, 'reg_lambda': 0.1232536291572126}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:44,261] Trial 45 finished with value: 0.6589861751152074 and parameters: {'learning_rate': 0.06475887233222251, 'num_leaves': 80, 'max_depth': 8, 'min_child_samples': 19, 'subsample': 0.8203883490032815, 'colsample_bytree': 0.625532518286149, 'reg_alpha': 0.00015174928003769533, 'reg_lambda': 0.0032506493810228044}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:45,166] Trial 46 finished with value: 0.6522781774580336 and parameters: {'learning_rate': 0.07223757552578003, 'num_leaves': 43, 'max_depth': 12, 'min_child_samples': 44, 'subsample': 0.9071647123368594, 'colsample_bytree': 0.6749689248808205, 'reg_alpha': 3.7142984516030084e-06, 'reg_lambda': 9.084406232179477}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:45,954] Trial 47 finished with value: 0.6571428571428571 and parameters: {'learning_rate': 0.05487509424246707, 'num_leaves': 61, 'max_depth': 6, 'min_child_samples': 28, 'subsample': 0.9386579184808567, 'colsample_bytree': 0.730651565344586, 'reg_alpha': 0.003673389502726434, 'reg_lambda': 0.01640573074605089}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:46,747] Trial 48 finished with value: 0.6359223300970874 and parameters: {'learning_rate': 0.08939472339719223, 'num_leaves': 35, 'max_depth': 7, 'min_child_samples': 15, 'subsample': 0.9745004927688867, 'colsample_bytree': 0.6469560602401896, 'reg_alpha': 1.6320299333162033e-05, 'reg_lambda': 0.08259524262837463}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:48,074] Trial 49 finished with value: 0.6685393258426966 and parameters: {'learning_rate': 0.028770726553603448, 'num_leaves': 40, 'max_depth': 3, 'min_child_samples': 36, 'subsample': 0.7137462688779872, 'colsample_bytree': 0.7591918366116202, 'reg_alpha': 0.26129425323647354, 'reg_lambda': 0.0004204857852202928}. Best is trial 23 with value: 0.6873385012919897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial for LightGBM:\n",
      "  Value (Best F1 Score): 0.6873385012919897\n",
      "  Best Params: \n",
      "    learning_rate: 0.07695074516306853\n",
      "    num_leaves: 39\n",
      "    max_depth: 3\n",
      "    min_child_samples: 30\n",
      "    subsample: 0.8915856859820709\n",
      "    colsample_bytree: 0.6497439382521284\n",
      "    reg_alpha: 0.018342465397323954\n",
      "    reg_lambda: 0.0014512535195673494\n"
     ]
    }
   ],
   "source": [
    "NFOLDS = 5\n",
    "\n",
    "params_base = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'n_estimators': 1000,\n",
    "        'is_unbalance': True,  # 成功した設定は維持\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "def objective_lightgbm(trial):\n",
    "    # パラメータの探索範囲を定義\n",
    "    params_opt = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 80),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "    }\n",
    "    params = params_base | params_opt\n",
    "\n",
    "    # 交差検証ループ\n",
    "    oof_preds_trial = np.zeros(train_df.shape[0])\n",
    "    folds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "        X_valid_fold, y_valid_fold = X_train.iloc[valid_idx], y_train.iloc[valid_idx]\n",
    "\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(X_train_fold, y_train_fold,\n",
    "                  eval_set=[(X_valid_fold, y_valid_fold)],\n",
    "                  callbacks=[lgb.early_stopping(50, verbose=False)])\n",
    "\n",
    "        oof_preds_trial[valid_idx] = model.predict_proba(X_valid_fold)[:, 1]\n",
    "    \n",
    "    # このトライアルでの最適なF1スコアを閾値探索で見つける\n",
    "    thresholds = np.arange(0.1, 0.5, 0.01)\n",
    "    f1_scores = [f1_score(y_train, (oof_preds_trial > t).astype(int)) for t in thresholds]\n",
    "    \n",
    "    return np.max(f1_scores)\n",
    "\n",
    "# # --- 最適化を実行する場合 (時間がかかることがあります) ---\n",
    "study_lightgbm = optuna.create_study(direction='maximize')\n",
    "study_lightgbm.optimize(objective_lightgbm, n_trials=50) # 50回の試行で探索\n",
    "\n",
    "print('Best trial for LightGBM:')\n",
    "trial_lightgbm = study_lightgbm.best_trial\n",
    "print(f'  Value (Best F1 Score): {trial_lightgbm.value}')\n",
    "print('  Best Params: ')\n",
    "for key, value in trial_lightgbm.params.items():\n",
    "    print(f'    {key}: {value}')\n",
    "\n",
    "best_params_lightgbm = params_base | trial_lightgbm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10a71c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary',\n",
       " 'metric': 'binary_logloss',\n",
       " 'n_estimators': 1000,\n",
       " 'is_unbalance': True,\n",
       " 'random_state': 42,\n",
       " 'n_jobs': -1,\n",
       " 'verbose': -1,\n",
       " 'learning_rate': 0.07695074516306853,\n",
       " 'num_leaves': 39,\n",
       " 'max_depth': 3,\n",
       " 'min_child_samples': 30,\n",
       " 'subsample': 0.8915856859820709,\n",
       " 'colsample_bytree': 0.6497439382521284,\n",
       " 'reg_alpha': 0.018342465397323954,\n",
       " 'reg_lambda': 0.0014512535195673494}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0bd79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=43, state=1, values=[0.6852791878172588], datetime_start=datetime.datetime(2025, 10, 17, 0, 23, 5, 156096), datetime_complete=datetime.datetime(2025, 10, 17, 0, 23, 5, 997304), params={'learning_rate': 0.049226097491479354, 'num_leaves': 24, 'max_depth': 4, 'min_child_samples': 35, 'subsample': 0.9766010179115259, 'colsample_bytree': 0.9743416839508543, 'reg_alpha': 4.6044002895687174e-08, 'reg_lambda': 0.0006790440644320187}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.1, log=True, low=0.01, step=None), 'num_leaves': IntDistribution(high=80, log=False, low=20, step=1), 'max_depth': IntDistribution(high=12, log=False, low=3, step=1), 'min_child_samples': IntDistribution(high=100, log=False, low=5, step=1), 'subsample': FloatDistribution(high=1.0, log=False, low=0.6, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.6, step=None), 'reg_alpha': FloatDistribution(high=10.0, log=True, low=1e-08, step=None), 'reg_lambda': FloatDistribution(high=10.0, log=True, low=1e-08, step=None)}, trial_id=43, value=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best trial:\n",
    "  Value (Best F1 Score): 0.6852791878172588\n",
    "  Best Params: \n",
    "    learning_rate: 0.049226097491479354\n",
    "    num_leaves: 24\n",
    "    max_depth: 4\n",
    "    min_child_samples: 35\n",
    "    subsample: 0.9766010179115259\n",
    "    colsample_bytree: 0.9743416839508543\n",
    "    reg_alpha: 4.6044002895687174e-08\n",
    "    reg_lambda: 0.0006790440644320187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2491985f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-17 00:52:14,062] A new study created in memory with name: no-name-946674c9-376d-4c76-b6b8-757f624bbdda\n",
      "[I 2025-10-17 00:52:25,075] Trial 0 finished with value: 0.5747126436781609 and parameters: {'learning_rate': 0.018423847690538526, 'depth': 9, 'min_data_in_leaf': 66, 'subsample': 0.9521487048759372, 'l2_leaf_reg': 2.4858460314250773e-08}. Best is trial 0 with value: 0.5747126436781609.\n",
      "[I 2025-10-17 00:52:29,042] Trial 1 finished with value: 0.6582278481012658 and parameters: {'learning_rate': 0.039858000909430626, 'depth': 4, 'min_data_in_leaf': 67, 'subsample': 0.8513048227639659, 'l2_leaf_reg': 6.014034306844379}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:52:43,902] Trial 2 finished with value: 0.6368159203980099 and parameters: {'learning_rate': 0.05792108705590046, 'depth': 9, 'min_data_in_leaf': 88, 'subsample': 0.6815510882022893, 'l2_leaf_reg': 0.4130198022189027}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:53:05,949] Trial 3 finished with value: 0.5759162303664922 and parameters: {'learning_rate': 0.03510326020734444, 'depth': 10, 'min_data_in_leaf': 53, 'subsample': 0.6826377878357996, 'l2_leaf_reg': 2.687840771883139e-06}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:53:15,243] Trial 4 finished with value: 0.5348837209302325 and parameters: {'learning_rate': 0.037911632526819894, 'depth': 9, 'min_data_in_leaf': 33, 'subsample': 0.7971740670768848, 'l2_leaf_reg': 1.8326321576602733e-07}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:53:34,242] Trial 5 finished with value: 0.5343811394891945 and parameters: {'learning_rate': 0.04653112491118769, 'depth': 10, 'min_data_in_leaf': 25, 'subsample': 0.9444281960488955, 'l2_leaf_reg': 1.0666193570783481e-06}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:53:37,641] Trial 6 finished with value: 0.6550868486352357 and parameters: {'learning_rate': 0.04038345570001488, 'depth': 4, 'min_data_in_leaf': 17, 'subsample': 0.8840878303905424, 'l2_leaf_reg': 0.28188831181229107}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:53:40,582] Trial 7 finished with value: 0.6294416243654822 and parameters: {'learning_rate': 0.03193767314611346, 'depth': 3, 'min_data_in_leaf': 22, 'subsample': 0.9122122665373196, 'l2_leaf_reg': 0.0015803782949780458}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:53:45,559] Trial 8 finished with value: 0.6391184573002755 and parameters: {'learning_rate': 0.014622491939880796, 'depth': 6, 'min_data_in_leaf': 38, 'subsample': 0.8918221316048195, 'l2_leaf_reg': 1.2993303558646107e-07}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:53:48,112] Trial 9 finished with value: 0.5934959349593496 and parameters: {'learning_rate': 0.031982755170511856, 'depth': 5, 'min_data_in_leaf': 38, 'subsample': 0.6758922324953682, 'l2_leaf_reg': 2.702070309074827e-07}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:53:55,485] Trial 10 finished with value: 0.6542553191489362 and parameters: {'learning_rate': 0.07893455077856963, 'depth': 7, 'min_data_in_leaf': 89, 'subsample': 0.7864021807789594, 'l2_leaf_reg': 4.464986073401033}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:54:00,263] Trial 11 finished with value: 0.6433915211970075 and parameters: {'learning_rate': 0.020155001255113915, 'depth': 3, 'min_data_in_leaf': 6, 'subsample': 0.8618182420480848, 'l2_leaf_reg': 0.04415282708168859}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:54:02,985] Trial 12 finished with value: 0.6553398058252428 and parameters: {'learning_rate': 0.0993080353954933, 'depth': 4, 'min_data_in_leaf': 71, 'subsample': 0.9989771435420421, 'l2_leaf_reg': 9.92869368169427}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:54:06,276] Trial 13 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.09809307263372187, 'depth': 5, 'min_data_in_leaf': 71, 'subsample': 0.9976081106479759, 'l2_leaf_reg': 5.362052332712974}. Best is trial 13 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:54:08,719] Trial 14 finished with value: 0.5676392572944297 and parameters: {'learning_rate': 0.06345269442009524, 'depth': 6, 'min_data_in_leaf': 72, 'subsample': 0.7339178963421698, 'l2_leaf_reg': 0.0009170386911305068}. Best is trial 13 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:54:13,712] Trial 15 finished with value: 0.6387434554973822 and parameters: {'learning_rate': 0.02461022195236975, 'depth': 5, 'min_data_in_leaf': 54, 'subsample': 0.8405141547550226, 'l2_leaf_reg': 0.012897860122533538}. Best is trial 13 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:54:20,527] Trial 16 finished with value: 0.6093023255813953 and parameters: {'learning_rate': 0.010298865112750905, 'depth': 7, 'min_data_in_leaf': 95, 'subsample': 0.6165857035803493, 'l2_leaf_reg': 5.2481469432835636e-05}. Best is trial 13 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:54:23,052] Trial 17 finished with value: 0.6338028169014085 and parameters: {'learning_rate': 0.0976178236673965, 'depth': 5, 'min_data_in_leaf': 80, 'subsample': 0.9993640739229591, 'l2_leaf_reg': 0.8467441646721866}. Best is trial 13 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:54:25,757] Trial 18 finished with value: 0.631578947368421 and parameters: {'learning_rate': 0.05269211622437583, 'depth': 4, 'min_data_in_leaf': 59, 'subsample': 0.8238459667087487, 'l2_leaf_reg': 0.016553344609684457}. Best is trial 13 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:54:27,392] Trial 19 finished with value: 0.6153846153846154 and parameters: {'learning_rate': 0.07555412923392844, 'depth': 3, 'min_data_in_leaf': 78, 'subsample': 0.7682677952118993, 'l2_leaf_reg': 4.227783010704926e-05}. Best is trial 13 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:54:37,243] Trial 20 finished with value: 0.6597938144329897 and parameters: {'learning_rate': 0.02375526500531929, 'depth': 6, 'min_data_in_leaf': 100, 'subsample': 0.9497783587594637, 'l2_leaf_reg': 1.8418531876469617}. Best is trial 13 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:54:45,912] Trial 21 finished with value: 0.6701030927835051 and parameters: {'learning_rate': 0.025063357484826267, 'depth': 6, 'min_data_in_leaf': 99, 'subsample': 0.9504455908968431, 'l2_leaf_reg': 1.8912349938338942}. Best is trial 21 with value: 0.6701030927835051.\n",
      "[I 2025-10-17 00:54:53,860] Trial 22 finished with value: 0.6428571428571429 and parameters: {'learning_rate': 0.024647673478947623, 'depth': 7, 'min_data_in_leaf': 100, 'subsample': 0.9544605432267698, 'l2_leaf_reg': 0.11923634278988784}. Best is trial 21 with value: 0.6701030927835051.\n",
      "[I 2025-10-17 00:55:01,014] Trial 23 finished with value: 0.6504065040650406 and parameters: {'learning_rate': 0.027391319872366714, 'depth': 6, 'min_data_in_leaf': 88, 'subsample': 0.9305364142798608, 'l2_leaf_reg': 0.9584119604075167}. Best is trial 21 with value: 0.6701030927835051.\n",
      "[I 2025-10-17 00:55:25,911] Trial 24 finished with value: 0.6385809312638581 and parameters: {'learning_rate': 0.016505193111779323, 'depth': 8, 'min_data_in_leaf': 98, 'subsample': 0.9817936718442396, 'l2_leaf_reg': 1.6163430354077233}. Best is trial 21 with value: 0.6701030927835051.\n",
      "[I 2025-10-17 00:55:33,125] Trial 25 finished with value: 0.6737967914438503 and parameters: {'learning_rate': 0.012893567859358891, 'depth': 5, 'min_data_in_leaf': 83, 'subsample': 0.9700324489092532, 'l2_leaf_reg': 0.004589013293714057}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:55:40,744] Trial 26 finished with value: 0.659217877094972 and parameters: {'learning_rate': 0.011674304211620216, 'depth': 5, 'min_data_in_leaf': 80, 'subsample': 0.97237054670164, 'l2_leaf_reg': 0.00483682420319681}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:55:48,856] Trial 27 finished with value: 0.6470588235294118 and parameters: {'learning_rate': 0.012940299529104082, 'depth': 5, 'min_data_in_leaf': 85, 'subsample': 0.913570091767838, 'l2_leaf_reg': 0.0662854690884104}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:55:56,883] Trial 28 finished with value: 0.6117021276595744 and parameters: {'learning_rate': 0.015114717322585167, 'depth': 8, 'min_data_in_leaf': 61, 'subsample': 0.8996973513518466, 'l2_leaf_reg': 0.000100806990181624}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:56:03,376] Trial 29 finished with value: 0.5764966740576497 and parameters: {'learning_rate': 0.01931357417969139, 'depth': 8, 'min_data_in_leaf': 74, 'subsample': 0.9696105965081774, 'l2_leaf_reg': 6.851532932379381e-06}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:56:09,320] Trial 30 finished with value: 0.6153846153846154 and parameters: {'learning_rate': 0.01258656712078224, 'depth': 6, 'min_data_in_leaf': 63, 'subsample': 0.9236211166453652, 'l2_leaf_reg': 0.0003384924720023078}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:56:19,195] Trial 31 finished with value: 0.6617283950617284 and parameters: {'learning_rate': 0.0227545992565256, 'depth': 6, 'min_data_in_leaf': 95, 'subsample': 0.9571487490248246, 'l2_leaf_reg': 3.105325803108103}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:56:28,343] Trial 32 finished with value: 0.6603325415676959 and parameters: {'learning_rate': 0.020232114625055943, 'depth': 5, 'min_data_in_leaf': 93, 'subsample': 0.9714112707967877, 'l2_leaf_reg': 9.719349281453047}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:56:32,528] Trial 33 finished with value: 0.6494845360824743 and parameters: {'learning_rate': 0.028562553006324157, 'depth': 4, 'min_data_in_leaf': 83, 'subsample': 0.9391799609026484, 'l2_leaf_reg': 0.3663340087714565}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:56:51,193] Trial 34 finished with value: 0.6648648648648648 and parameters: {'learning_rate': 0.017281122457745386, 'depth': 7, 'min_data_in_leaf': 92, 'subsample': 0.9970720540766619, 'l2_leaf_reg': 2.3665702796733132}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:57:01,746] Trial 35 finished with value: 0.6575342465753424 and parameters: {'learning_rate': 0.016870463923877543, 'depth': 7, 'min_data_in_leaf': 90, 'subsample': 0.9926588487500948, 'l2_leaf_reg': 0.19874011948223985}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:57:13,682] Trial 36 finished with value: 0.6282722513089005 and parameters: {'learning_rate': 0.010339254873423995, 'depth': 7, 'min_data_in_leaf': 69, 'subsample': 0.9746135815611622, 'l2_leaf_reg': 0.013439337278936198}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:57:33,229] Trial 37 finished with value: 0.6509433962264151 and parameters: {'learning_rate': 0.01370265120896095, 'depth': 8, 'min_data_in_leaf': 76, 'subsample': 0.8787558015656529, 'l2_leaf_reg': 0.525359485717566}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:57:52,079] Trial 38 finished with value: 0.6473684210526316 and parameters: {'learning_rate': 0.01738219398988785, 'depth': 9, 'min_data_in_leaf': 85, 'subsample': 0.9331481300040508, 'l2_leaf_reg': 0.07245624264407526}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:57:55,384] Trial 39 finished with value: 0.672316384180791 and parameters: {'learning_rate': 0.04197116292981179, 'depth': 5, 'min_data_in_leaf': 66, 'subsample': 0.8650832463826937, 'l2_leaf_reg': 0.003522994506949654}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:57:58,397] Trial 40 finished with value: 0.631578947368421 and parameters: {'learning_rate': 0.04186641305273787, 'depth': 5, 'min_data_in_leaf': 66, 'subsample': 0.8648708744582574, 'l2_leaf_reg': 0.0030745987470795497}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:58:02,947] Trial 41 finished with value: 0.6263736263736264 and parameters: {'learning_rate': 0.046650799540280015, 'depth': 6, 'min_data_in_leaf': 44, 'subsample': 0.9059237496552369, 'l2_leaf_reg': 0.0313546536400084}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:58:05,497] Trial 42 finished with value: 0.6165413533834586 and parameters: {'learning_rate': 0.03621913958244908, 'depth': 5, 'min_data_in_leaf': 49, 'subsample': 0.9564223448409186, 'l2_leaf_reg': 0.0003704551041285099}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:58:08,439] Trial 43 finished with value: 0.6572769953051644 and parameters: {'learning_rate': 0.06929265047405161, 'depth': 4, 'min_data_in_leaf': 92, 'subsample': 0.8301294141288038, 'l2_leaf_reg': 2.808022191777718}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:58:12,919] Trial 44 finished with value: 0.6217616580310881 and parameters: {'learning_rate': 0.02179926287283071, 'depth': 6, 'min_data_in_leaf': 57, 'subsample': 0.9834655950803188, 'l2_leaf_reg': 0.002946918715433291}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:58:17,182] Trial 45 finished with value: 0.6596858638743456 and parameters: {'learning_rate': 0.028039088925839156, 'depth': 4, 'min_data_in_leaf': 85, 'subsample': 0.9216686962266236, 'l2_leaf_reg': 0.2248298983820473}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:58:19,029] Trial 46 finished with value: 0.5776699029126213 and parameters: {'learning_rate': 0.08464751314679786, 'depth': 5, 'min_data_in_leaf': 74, 'subsample': 0.999479674795856, 'l2_leaf_reg': 1.840669435528615e-08}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:58:22,399] Trial 47 finished with value: 0.5435684647302904 and parameters: {'learning_rate': 0.05566507202286371, 'depth': 7, 'min_data_in_leaf': 64, 'subsample': 0.8812713208737369, 'l2_leaf_reg': 6.692182351001453e-06}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:58:27,579] Trial 48 finished with value: 0.6408839779005525 and parameters: {'learning_rate': 0.015428356148300194, 'depth': 6, 'min_data_in_leaf': 81, 'subsample': 0.8096173062334631, 'l2_leaf_reg': 0.0008008010913296667}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:58:50,531] Trial 49 finished with value: 0.5754985754985755 and parameters: {'learning_rate': 0.03346837247792573, 'depth': 10, 'min_data_in_leaf': 89, 'subsample': 0.716177751060012, 'l2_leaf_reg': 0.007024444921988573}. Best is trial 25 with value: 0.6737967914438503.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial for CatBoost:\n",
      "  Value (Best F1 Score): 0.6737967914438503\n",
      "  Best Params: \n",
      "    learning_rate: 0.012893567859358891\n",
      "    depth: 5\n",
      "    min_data_in_leaf: 83\n",
      "    subsample: 0.9700324489092532\n",
      "    l2_leaf_reg: 0.004589013293714057\n"
     ]
    }
   ],
   "source": [
    "NFOLDS = 5\n",
    "\n",
    "params_base = {\n",
    "        'objective': 'Logloss', # CatBoostでは'Logloss'を指定\n",
    "        'iterations': 1000,\n",
    "        'scale_pos_weight': (y_train == 0).sum() / (y_train == 1).sum(), # 不均衡データへの対処\n",
    "        'random_seed': 42,\n",
    "        'verbose': 0, # 学習ログを非表示\n",
    "        'early_stopping_rounds': 50 # 早期停止\n",
    "    }\n",
    "\n",
    "def objective_catboost(trial):\n",
    "    # 不均衡データ対策のための重みを計算\n",
    "\n",
    "    # パラメータの探索範囲を定義\n",
    "    params_opt = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True), # L2正則化\n",
    "    }\n",
    "\n",
    "    params = params_base | params_opt\n",
    "\n",
    "    # 交差検証ループ\n",
    "    oof_preds_trial = np.zeros(train_df.shape[0])\n",
    "    folds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "        X_valid_fold, y_valid_fold = X_train.iloc[valid_idx], y_train.iloc[valid_idx]\n",
    "\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(X_train_fold, y_train_fold,\n",
    "                  eval_set=[(X_valid_fold, y_valid_fold)],\n",
    "                  use_best_model=True)\n",
    "\n",
    "        oof_preds_trial[valid_idx] = model.predict_proba(X_valid_fold)[:, 1]\n",
    "    \n",
    "    # このトライアルでの最適なF1スコアを閾値探索で見つける\n",
    "    thresholds = np.arange(0.1, 0.5, 0.01)\n",
    "    f1_scores = [f1_score(y_train, (oof_preds_trial > t).astype(int)) for t in thresholds]\n",
    "    \n",
    "    return np.max(f1_scores)\n",
    "\n",
    "study_catboost = optuna.create_study(direction='maximize')\n",
    "study_catboost.optimize(objective_catboost, n_trials=50) # 50回の試行で探索\n",
    "\n",
    "print('Best trial for CatBoost:')\n",
    "trial_catboost = study_catboost.best_trial\n",
    "print(f'  Value (Best F1 Score): {trial_catboost.value}')\n",
    "print('  Best Params: ')\n",
    "for key, value in trial_catboost.params.items():\n",
    "    print(f'    {key}: {value}')\n",
    "\n",
    "best_params_catboost = params_base | trial_catboost.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0224d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.049226097491479354,\n",
       " 'num_leaves': 24,\n",
       " 'max_depth': 4,\n",
       " 'min_child_samples': 35,\n",
       " 'subsample': 0.9766010179115259,\n",
       " 'colsample_bytree': 0.9743416839508543,\n",
       " 'reg_alpha': 4.6044002895687174e-08,\n",
       " 'reg_lambda': 0.0006790440644320187}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best trial for CatBoost:\n",
    "  Value (Best F1 Score): 0.685\n",
    "  Best Params: \n",
    "    learning_rate: 0.01506366663492991\n",
    "    depth: 4\n",
    "    min_data_in_leaf: 93\n",
    "    subsample: 0.7518354099061272\n",
    "    l2_leaf_reg: 0.07096168454986888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d856c024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting LightGBM and CatBoost Training ---\n",
      "Fold 1 finished.\n",
      "Fold 2 finished.\n",
      "Fold 3 finished.\n",
      "Fold 4 finished.\n",
      "Fold 5 finished.\n",
      "\n",
      "--- Training Finished ---\n",
      "----------------------------------------\n",
      "LightGBM単体のOOF F1スコア (参考): 0.6793\n",
      "CatBoost単体のOOF F1スコア (参考): 0.6590\n",
      "----------------------------------------\n",
      "アンサンブルモデルのベストOOF F1スコア: 0.6856\n",
      "アンサンブルモデルの最適閾値: 0.49\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- 交差検証の準備 ---\n",
    "NFOLDS = 5\n",
    "folds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# OOF予測値とテストデータ予測値を格納する配列を初期化\n",
    "oof_preds_lgbm = np.zeros(train_df.shape[0])\n",
    "sub_preds_lgbm = np.zeros(test_df.shape[0])\n",
    "oof_preds_cat = np.zeros(train_df.shape[0])\n",
    "sub_preds_cat = np.zeros(test_df.shape[0])\n",
    "\n",
    "\n",
    "# --- モデル学習ループ ---\n",
    "print(\"--- Starting LightGBM and CatBoost Training ---\")\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_valid_fold, y_valid_fold = X_train.iloc[valid_idx], y_train.iloc[valid_idx]\n",
    "\n",
    "    # --- LightGBMの学習 ---\n",
    "    lgbm = lgb.LGBMClassifier(**best_params_lightgbm)\n",
    "    lgbm.fit(X_train_fold, y_train_fold,\n",
    "             eval_set=[(X_valid_fold, y_valid_fold)],\n",
    "             callbacks=[lgb.early_stopping(50, verbose=False)])\n",
    "    oof_preds_lgbm[valid_idx] = lgbm.predict_proba(X_valid_fold)[:, 1]\n",
    "    sub_preds_lgbm += lgbm.predict_proba(X_test)[:, 1] / folds.n_splits\n",
    "\n",
    "    # --- CatBoostの学習 ---\n",
    "    cat = CatBoostClassifier(**best_params_catboost)\n",
    "    cat.fit(X_train_fold, y_train_fold,\n",
    "            eval_set=[(X_valid_fold, y_valid_fold)],\n",
    "            use_best_model=True,\n",
    "            verbose=0)\n",
    "    oof_preds_cat[valid_idx] = cat.predict_proba(X_valid_fold)[:, 1]\n",
    "    sub_preds_cat += cat.predict_proba(X_test)[:, 1] / folds.n_splits\n",
    "    \n",
    "    print(f\"Fold {n_fold+1} finished.\")\n",
    "\n",
    "print(\"\\n--- Training Finished ---\")\n",
    "\n",
    "\n",
    "# --- アンサンブルと閾値最適化 ---\n",
    "# 2つのモデルのOOF予測値を単純平均\n",
    "ensemble_oof_preds = (oof_preds_lgbm + oof_preds_cat) / 2\n",
    "\n",
    "# 最適な閾値を探索\n",
    "thresholds = np.arange(0.1, 0.5, 0.01)\n",
    "f1_scores = [f1_score(y_train, (ensemble_oof_preds > t).astype(int)) for t in thresholds]\n",
    "best_threshold_ensemble = thresholds[np.argmax(f1_scores)]\n",
    "best_f1_ensemble = np.max(f1_scores)\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"LightGBM単体のOOF F1スコア (参考): {f1_score(y_train, (oof_preds_lgbm > best_threshold_ensemble).astype(int)):.4f}\")\n",
    "print(f\"CatBoost単体のOOF F1スコア (参考): {f1_score(y_train, (oof_preds_cat > best_threshold_ensemble).astype(int)):.4f}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"アンサンブルモデルのベストOOF F1スコア: {best_f1_ensemble:.4f}\")\n",
    "print(f\"アンサンブルモデルの最適閾値: {best_threshold_ensemble:.2f}\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191ceebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "アンサンブルモデルの提出ファイル 'submission_ensemble.csv' を作成しました。\n",
      "提出ファイルでの購入予測数: 174\n"
     ]
    }
   ],
   "source": [
    "# 提出ファイルの作成\n",
    "# テストデータに対する予測値も同様に平均\n",
    "ensemble_sub_preds = (sub_preds_lgbm + sub_preds_cat) / 2\n",
    "\n",
    "# 最適化された閾値を使って最終的な予測を決定\n",
    "predictions_ensemble = (ensemble_sub_preds > best_threshold_ensemble).astype(int)\n",
    "\n",
    "# 提出用DataFrameを作成\n",
    "submit_df_ensemble = sample_submit.copy()\n",
    "submit_df_ensemble[1] = predictions_ensemble\n",
    "submit_df_ensemble.to_csv('submission_ensemble.csv', index=False, header=False)\n",
    "\n",
    "print(\"\\nアンサンブルモデルの提出ファイル 'submission_ensemble.csv' を作成しました。\")\n",
    "print(f\"提出ファイルでの購入予測数: {np.sum(predictions_ensemble)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
