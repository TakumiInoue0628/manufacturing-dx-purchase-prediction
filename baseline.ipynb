{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75d937c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\takumi_inoue\\projects\\github\\TakumiInoue0628\\manufacturing-dx-purchase-prediction\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import optuna\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a721af",
   "metadata": {},
   "source": [
    "データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a440e75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "sample_submit = pd.read_csv(\"data/sample_submit.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae42767f",
   "metadata": {},
   "source": [
    "データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed586b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習に使用する特徴量の数: 44\n",
      "学習データのサイズ: (742, 44)\n",
      "テストデータのサイズ: (800, 44)\n",
      "学習データの購入フラグ1の数: 179\n",
      "学習データの購入フラグ0の数: 563\n",
      "購入フラグ1の割合: 0.2412\n"
     ]
    }
   ],
   "source": [
    "# 特徴量エンジニアリング関数\n",
    "def feature_engineering(df):\n",
    "    \"\"\"財務指標などを追加する関数\"\"\"\n",
    "    # 財務指標の作成 (分母が0になる可能性を考慮)\n",
    "    df['自己資本比率'] = df['自己資本'] / (df['総資産'] + 1e-6)\n",
    "    df['売上高営業利益率'] = df['営業利益'] / (df['売上'] + 1e-6)\n",
    "    df['総資産回転率'] = df['売上'] / (df['総資産'] + 1e-6)\n",
    "    df['負債比率'] = df['負債'] / (df['自己資本'] + 1e-6)\n",
    "    # 新しい特徴量を追加\n",
    "    df['従業員数_x_売上高営業利益率'] = df['従業員数'] * df['売上高営業利益率']\n",
    "    # アンケートの平均と標準偏差を追加\n",
    "    zenkaku_table = str.maketrans('0123456789', '０１２３４５６７８９')\n",
    "    survey_cols = [f\"アンケート{str(i).translate(zenkaku_table)}\" for i in range(1, 12)]\n",
    "    df['アンケート_平均'] = df[survey_cols].mean(axis=1)\n",
    "    df['アンケート_標準偏差'] = df[survey_cols].std(axis=1)\n",
    "    # 欠損値を-9999で埋める (LightGBMは欠損値を扱えるが、比率計算でのNaN/infに対応)\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.fillna(-9999, inplace=True)\n",
    "    return df\n",
    "\n",
    "# train/testに特徴量エンジニアリングを適用\n",
    "train_df = feature_engineering(train.copy())\n",
    "test_df = feature_engineering(test.copy())\n",
    "\n",
    "# カテゴリ変数のエンコーディング\n",
    "categorical_features = ['業界', '上場種別', '特徴']\n",
    "for col in categorical_features:\n",
    "    # trainとtestを結合して語彙を作成し、未知のカテゴリに対応\n",
    "    combined_data = pd.concat([train_df[col], test_df[col]]).astype(str)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(combined_data)\n",
    "    train_df[col] = le.transform(train_df[col].astype(str))\n",
    "    test_df[col] = le.transform(test_df[col].astype(str))\n",
    "\n",
    "# 特徴量とターゲットの定義\n",
    "target = '購入フラグ'\n",
    "# テキストデータやIDなど、学習から除外するカラム\n",
    "drop_cols = ['企業ID', '企業名', '企業概要', '組織図', '今後のDX展望', '購入フラグ']\n",
    "# trainとtestで共通して存在するカラムのみを特徴量として使用\n",
    "common_cols = list(set(train_df.columns) & set(test_df.columns))\n",
    "features = [col for col in common_cols if col not in drop_cols]\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[target]\n",
    "X_test = test_df[features]\n",
    "\n",
    "print(f\"学習に使用する特徴量の数: {len(features)}\")\n",
    "print(f\"学習データのサイズ: {X_train.shape}\")\n",
    "print(f\"テストデータのサイズ: {X_test.shape}\")\n",
    "\n",
    "# 学習データの購入フラグ1と0の数と割合を表示\n",
    "y_train_positive = (y_train==1).sum()\n",
    "y_train_negative = (y_train==0).sum()\n",
    "print(f\"学習データの購入フラグ1の数: {y_train_positive}\")\n",
    "print(f\"学習データの購入フラグ0の数: {y_train_negative}\")\n",
    "print(f\"購入フラグ1の割合: {y_train_positive / len(y_train):.4f}\")\n",
    "\n",
    "# 学習時のpositiveデータの重要度を引き上げる\n",
    "scale_pos_weight = y_train_negative / y_train_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc5b37ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習に使用する特徴量の数: 144\n",
      "学習データのサイズ: (742, 144)\n",
      "テストデータのサイズ: (800, 144)\n"
     ]
    }
   ],
   "source": [
    "# テキストデータの特徴量化\n",
    "\n",
    "# TF-IDFの適用 (今後のDX展望)\n",
    "#tfidf = TfidfVectorizer(max_features=50) # まずは50個の重要単語に絞る\n",
    "#train_text_features = tfidf.fit_transform(train_df['今後のDX展望']).toarray()\n",
    "#test_text_features = tfidf.transform(test_df['今後のDX展望']).toarray()\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=100, ngram_range=(1, 2)) # 100個の重要単語・バイグラムも考慮\n",
    "all_text = pd.concat([train_df['今後のDX展望'], test_df['今後のDX展望']])\n",
    "tfidf_vectorizer.fit(all_text)\n",
    "train_tfidf_features = tfidf_vectorizer.transform(train_df['今後のDX展望']).toarray()\n",
    "test_tfidf_features = tfidf_vectorizer.transform(test_df['今後のDX展望']).toarray()\n",
    "\n",
    "# 特徴量データフレームに変換\n",
    "#train_text_df = pd.DataFrame(train_text_features, columns=[f'tfidf_{i}' for i in range(train_text_features.shape[1])])\n",
    "#test_text_df = pd.DataFrame(test_text_features, columns=[f'tfidf_{i}' for i in range(test_text_features.shape[1])])\n",
    "train_tfidf_df = pd.DataFrame(train_tfidf_features, columns=[f'tfidf_outlook_{i}' for i in range(train_tfidf_features.shape[1])])\n",
    "test_tfidf_df = pd.DataFrame(test_tfidf_features, columns=[f'tfidf_outlook_{i}' for i in range(test_tfidf_features.shape[1])])\n",
    "\n",
    "# 元のデータと結合\n",
    "#X_train = pd.concat([X_train, train_text_df], axis=1)\n",
    "#X_test = pd.concat([X_test, test_text_df], axis=1)\n",
    "X_train = pd.concat([X_train, train_tfidf_df], axis=1)\n",
    "X_test = pd.concat([X_test, test_tfidf_df], axis=1)\n",
    "\n",
    "# featureリストも更新\n",
    "features = list(X_train.columns)\n",
    "\n",
    "print(f\"学習に使用する特徴量の数: {len(features)}\")\n",
    "print(f\"学習データのサイズ: {X_train.shape}\")\n",
    "print(f\"テストデータのサイズ: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b5f0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習に使用する特徴量の数: 196\n",
      "学習データのサイズ: (742, 196)\n",
      "テストデータのサイズ: (800, 196)\n"
     ]
    }
   ],
   "source": [
    "# --- 企業概要に対するTF-IDFの追加 ---\n",
    "tfidf_desc_vectorizer = TfidfVectorizer(max_features=50, ngram_range=(1, 2)) # 特徴量は50個に絞る\n",
    "all_desc_text = pd.concat([train_df['企業概要'], test_df['企業概要']])\n",
    "tfidf_desc_vectorizer.fit(all_desc_text)\n",
    "\n",
    "train_tfidf_desc = tfidf_desc_vectorizer.transform(train_df['企業概要']).toarray()\n",
    "test_tfidf_desc = tfidf_desc_vectorizer.transform(test_df['企業概要']).toarray()\n",
    "\n",
    "train_tfidf_desc_df = pd.DataFrame(train_tfidf_desc, columns=[f'tfidf_desc_{i}' for i in range(train_tfidf_desc.shape[1])])\n",
    "test_tfidf_desc_df = pd.DataFrame(test_tfidf_desc, columns=[f'tfidf_desc_{i}' for i in range(test_tfidf_desc.shape[1])])\n",
    "\n",
    "# 既存のデータフレームと結合\n",
    "X_train = pd.concat([X_train, train_tfidf_desc_df], axis=1)\n",
    "X_test = pd.concat([X_test, test_tfidf_desc_df], axis=1)\n",
    "\n",
    "\n",
    "# --- DX展望の簡易的な感情分析特徴量の追加 ---\n",
    "# ポジティブな単語とネガティブな単語を定義\n",
    "positive_words = ['積極', '強化', '推進', '投資', '拡大', '創出']\n",
    "negative_words = ['慎重', '課題', '懸念', '限定的', '検討']\n",
    "\n",
    "# 各単語の出現回数をカウント\n",
    "for word in positive_words:\n",
    "    train_df[f'word_{word}'] = train_df['今後のDX展望'].str.count(word)\n",
    "    test_df[f'word_{word}'] = test_df['今後のDX展望'].str.count(word)\n",
    "\n",
    "for word in negative_words:\n",
    "    train_df[f'word_{word}'] = train_df['今後のDX展望'].str.count(word)\n",
    "    test_df[f'word_{word}'] = test_df['今後のDX展望'].str.count(word)\n",
    "\n",
    "# ポジティブ/ネガティブスコアを作成\n",
    "X_train['positive_score'] = train_df[[f'word_{w}' for w in positive_words]].sum(axis=1)\n",
    "X_test['positive_score'] = test_df[[f'word_{w}' for w in positive_words]].sum(axis=1)\n",
    "X_train['negative_score'] = train_df[[f'word_{w}' for w in negative_words]].sum(axis=1)\n",
    "X_test['negative_score'] = test_df[[f'word_{w}' for w in negative_words]].sum(axis=1)\n",
    "\n",
    "# featureリストも更新\n",
    "features = list(X_train.columns)\n",
    "\n",
    "print(f\"学習に使用する特徴量の数: {len(features)}\")\n",
    "print(f\"学習データのサイズ: {X_train.shape}\")\n",
    "print(f\"テストデータのサイズ: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5b8ece",
   "metadata": {},
   "source": [
    "モデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a89f7998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 143, number of negative: 450\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7032\n",
      "[LightGBM] [Info] Number of data points in the train set: 593, number of used features: 181\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241147 -> initscore=-1.146403\n",
      "[LightGBM] [Info] Start training from score -1.146403\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 143, number of negative: 450\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6931\n",
      "[LightGBM] [Info] Number of data points in the train set: 593, number of used features: 177\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241147 -> initscore=-1.146403\n",
      "[LightGBM] [Info] Start training from score -1.146403\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 144, number of negative: 450\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7018\n",
      "[LightGBM] [Info] Number of data points in the train set: 594, number of used features: 180\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242424 -> initscore=-1.139434\n",
      "[LightGBM] [Info] Start training from score -1.139434\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 143, number of negative: 451\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6977\n",
      "[LightGBM] [Info] Number of data points in the train set: 594, number of used features: 179\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240741 -> initscore=-1.148623\n",
      "[LightGBM] [Info] Start training from score -1.148623\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 143, number of negative: 451\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6978\n",
      "[LightGBM] [Info] Number of data points in the train set: 594, number of used features: 175\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240741 -> initscore=-1.148623\n",
      "[LightGBM] [Info] Start training from score -1.148623\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "------------------------------\n",
      "OOF（Out-of-Fold）予測でのベストF1スコア: 0.6280\n",
      "ベストスコアを達成した閾値: 0.34\n"
     ]
    }
   ],
   "source": [
    "# LightGBMモデルの学習（StratifiedKFoldによる交差検証）\n",
    "NFOLDS = 5\n",
    "folds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=42)\n",
    "oof_preds = np.zeros(train_df.shape[0])\n",
    "sub_preds = np.zeros(test_df.shape[0])\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_valid_fold, y_valid_fold = X_train.iloc[valid_idx], y_train.iloc[valid_idx]\n",
    "\n",
    "    # LightGBMのパラメータ設定\n",
    "    # is_unbalance=True または scale_pos_weight を追加\n",
    "    model = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        metric='binary_logloss',\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.01,\n",
    "        num_leaves=31,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        colsample_bytree=0.8,\n",
    "        subsample=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        # === ここを追加 ===\n",
    "        is_unbalance=True,\n",
    "        #scale_pos_weight=scale_pos_weight  # (陰性サンプル数 / 陽性サンプル数)\n",
    "        min_child_samples=10,\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_fold, y_train_fold,\n",
    "              eval_set=[(X_valid_fold, y_valid_fold)],\n",
    "              eval_metric='logloss',\n",
    "              callbacks=[lgb.early_stopping(100, verbose=False)])\n",
    "\n",
    "    oof_preds[valid_idx] = model.predict_proba(X_valid_fold)[:, 1]\n",
    "    sub_preds += model.predict_proba(X_test)[:, 1] / folds.n_splits\n",
    "    \n",
    "    # 特徴量重要度の保存\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = model.feature_importances_\n",
    "    fold_importance_df[\"fold\"] = n_fold + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "\n",
    "print(\"-\" * 30)\n",
    "# --- 最適な閾値の探索 ---\n",
    "thresholds = np.arange(0.1, 0.5, 0.01)\n",
    "f1_scores = [f1_score(y_train, (oof_preds > t).astype(int)) for t in thresholds]\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "best_f1 = np.max(f1_scores)\n",
    "\n",
    "print(f\"OOF（Out-of-Fold）予測でのベストF1スコア: {best_f1:.4f}\")\n",
    "print(f\"ベストスコアを達成した閾値: {best_threshold:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd338b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "OOF（Out-of-Fold）予測でのベストF1スコア: 0.6109\n",
    "ベストスコアを達成した閾値: 0.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7ed0fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-17 00:49:56,340] A new study created in memory with name: no-name-e45d2f0f-69c0-4921-ba85-e027a07c6ddd\n",
      "[I 2025-10-17 00:49:58,878] Trial 0 finished with value: 0.6558139534883721 and parameters: {'learning_rate': 0.010098354336778663, 'num_leaves': 66, 'max_depth': 6, 'min_child_samples': 40, 'subsample': 0.9462852032422089, 'colsample_bytree': 0.9858667034847988, 'reg_alpha': 0.005710096579921643, 'reg_lambda': 0.007618058451519296}. Best is trial 0 with value: 0.6558139534883721.\n",
      "[I 2025-10-17 00:50:00,079] Trial 1 finished with value: 0.6617647058823529 and parameters: {'learning_rate': 0.028382926903424865, 'num_leaves': 49, 'max_depth': 11, 'min_child_samples': 40, 'subsample': 0.6068137866664104, 'colsample_bytree': 0.8905093443075198, 'reg_alpha': 7.300082402069525e-06, 'reg_lambda': 3.010627941031705e-06}. Best is trial 1 with value: 0.6617647058823529.\n",
      "[I 2025-10-17 00:50:00,919] Trial 2 finished with value: 0.6618004866180048 and parameters: {'learning_rate': 0.05935666882733018, 'num_leaves': 74, 'max_depth': 4, 'min_child_samples': 58, 'subsample': 0.6979511264371474, 'colsample_bytree': 0.6918337550656879, 'reg_alpha': 8.230277722949304e-06, 'reg_lambda': 0.07750139774850584}. Best is trial 2 with value: 0.6618004866180048.\n",
      "[I 2025-10-17 00:50:01,754] Trial 3 finished with value: 0.6580976863753213 and parameters: {'learning_rate': 0.04433766771073496, 'num_leaves': 64, 'max_depth': 6, 'min_child_samples': 55, 'subsample': 0.9583892700434483, 'colsample_bytree': 0.8455225036348119, 'reg_alpha': 3.352276596511742e-08, 'reg_lambda': 1.8143586436748236}. Best is trial 2 with value: 0.6618004866180048.\n",
      "[I 2025-10-17 00:50:02,941] Trial 4 finished with value: 0.6576576576576577 and parameters: {'learning_rate': 0.030822636081012444, 'num_leaves': 74, 'max_depth': 11, 'min_child_samples': 75, 'subsample': 0.8991746167714385, 'colsample_bytree': 0.7927194697569915, 'reg_alpha': 3.648785747408321e-08, 'reg_lambda': 0.09389421154019718}. Best is trial 2 with value: 0.6618004866180048.\n",
      "[I 2025-10-17 00:50:03,442] Trial 5 finished with value: 0.6433566433566433 and parameters: {'learning_rate': 0.07846254790062719, 'num_leaves': 36, 'max_depth': 12, 'min_child_samples': 90, 'subsample': 0.7321407578445907, 'colsample_bytree': 0.9429880433644996, 'reg_alpha': 7.510906590845694, 'reg_lambda': 8.88451818546748e-06}. Best is trial 2 with value: 0.6618004866180048.\n",
      "[I 2025-10-17 00:50:04,196] Trial 6 finished with value: 0.657074340527578 and parameters: {'learning_rate': 0.06451710283093588, 'num_leaves': 39, 'max_depth': 5, 'min_child_samples': 63, 'subsample': 0.9315320412173421, 'colsample_bytree': 0.6308006534208122, 'reg_alpha': 0.005817001797758196, 'reg_lambda': 0.5720600514335}. Best is trial 2 with value: 0.6618004866180048.\n",
      "[I 2025-10-17 00:50:04,995] Trial 7 finished with value: 0.6635071090047393 and parameters: {'learning_rate': 0.06760338286522281, 'num_leaves': 71, 'max_depth': 3, 'min_child_samples': 23, 'subsample': 0.8028988648280347, 'colsample_bytree': 0.6626540430604418, 'reg_alpha': 1.090355729028211e-05, 'reg_lambda': 0.000223964270134175}. Best is trial 7 with value: 0.6635071090047393.\n",
      "[I 2025-10-17 00:50:05,621] Trial 8 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.06772083527609242, 'num_leaves': 36, 'max_depth': 3, 'min_child_samples': 47, 'subsample': 0.8903245391694916, 'colsample_bytree': 0.827717764843285, 'reg_alpha': 0.04095243452534754, 'reg_lambda': 0.11936449184836254}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:07,089] Trial 9 finished with value: 0.6540284360189573 and parameters: {'learning_rate': 0.02028981203377143, 'num_leaves': 58, 'max_depth': 5, 'min_child_samples': 73, 'subsample': 0.9772183796817622, 'colsample_bytree': 0.8237648157568641, 'reg_alpha': 1.4643182629865104e-05, 'reg_lambda': 0.4386060539619272}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:07,665] Trial 10 finished with value: 0.6483516483516484 and parameters: {'learning_rate': 0.09147584017356414, 'num_leaves': 22, 'max_depth': 8, 'min_child_samples': 16, 'subsample': 0.8383697403839465, 'colsample_bytree': 0.7497673836332981, 'reg_alpha': 4.598771819617123, 'reg_lambda': 1.754426273760609e-08}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:08,954] Trial 11 finished with value: 0.6650943396226415 and parameters: {'learning_rate': 0.04725859930772829, 'num_leaves': 31, 'max_depth': 3, 'min_child_samples': 12, 'subsample': 0.8352761134563716, 'colsample_bytree': 0.6013003626041058, 'reg_alpha': 0.044248837579337036, 'reg_lambda': 0.0015328212252484323}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:09,846] Trial 12 finished with value: 0.6595744680851063 and parameters: {'learning_rate': 0.046009910887450246, 'num_leaves': 23, 'max_depth': 3, 'min_child_samples': 8, 'subsample': 0.8636768946902955, 'colsample_bytree': 0.7482706613855404, 'reg_alpha': 0.0986246845430709, 'reg_lambda': 0.0015489283574375108}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:10,881] Trial 13 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.04327455256602441, 'num_leaves': 34, 'max_depth': 8, 'min_child_samples': 31, 'subsample': 0.7517005210180333, 'colsample_bytree': 0.6039447745706138, 'reg_alpha': 0.07876860871771285, 'reg_lambda': 5.912129283053401e-05}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:12,998] Trial 14 finished with value: 0.6480186480186481 and parameters: {'learning_rate': 0.021043351755960796, 'num_leaves': 45, 'max_depth': 8, 'min_child_samples': 34, 'subsample': 0.7464442573809367, 'colsample_bytree': 0.8777959287980139, 'reg_alpha': 0.2789744283609027, 'reg_lambda': 1.8971661531367654e-05}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:13,715] Trial 15 finished with value: 0.6487804878048781 and parameters: {'learning_rate': 0.09956273862570961, 'num_leaves': 32, 'max_depth': 9, 'min_child_samples': 31, 'subsample': 0.6375816167449639, 'colsample_bytree': 0.7251104783548581, 'reg_alpha': 0.00040313313735999194, 'reg_lambda': 3.5438784176540644e-07}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:15,549] Trial 16 finished with value: 0.6477024070021882 and parameters: {'learning_rate': 0.039012356538720296, 'num_leaves': 42, 'max_depth': 9, 'min_child_samples': 47, 'subsample': 0.7699196014465247, 'colsample_bytree': 0.7824932206814025, 'reg_alpha': 0.7440343346499544, 'reg_lambda': 6.4094918865970145}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:16,893] Trial 17 finished with value: 0.6543535620052771 and parameters: {'learning_rate': 0.05423002645795758, 'num_leaves': 55, 'max_depth': 7, 'min_child_samples': 23, 'subsample': 0.8918153032527047, 'colsample_bytree': 0.8977156067534571, 'reg_alpha': 0.0060975744173868045, 'reg_lambda': 9.362087960869881e-05}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:18,383] Trial 18 finished with value: 0.6455026455026455 and parameters: {'learning_rate': 0.023870456713466593, 'num_leaves': 28, 'max_depth': 10, 'min_child_samples': 97, 'subsample': 0.69161510539511, 'colsample_bytree': 0.6843647028152512, 'reg_alpha': 0.0003758178673876686, 'reg_lambda': 0.014358563173062923}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:20,394] Trial 19 finished with value: 0.6443298969072165 and parameters: {'learning_rate': 0.01586000206060493, 'num_leaves': 47, 'max_depth': 7, 'min_child_samples': 47, 'subsample': 0.7925413531346874, 'colsample_bytree': 0.84021080286131, 'reg_alpha': 0.028226005317934694, 'reg_lambda': 5.667161667367202e-07}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:21,442] Trial 20 finished with value: 0.6529680365296804 and parameters: {'learning_rate': 0.04069229270756069, 'num_leaves': 34, 'max_depth': 9, 'min_child_samples': 69, 'subsample': 0.9961270096125124, 'colsample_bytree': 0.9439100928578766, 'reg_alpha': 0.001717048236621317, 'reg_lambda': 0.0008661143196802162}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:22,518] Trial 21 finished with value: 0.6495726495726496 and parameters: {'learning_rate': 0.053778299830399515, 'num_leaves': 29, 'max_depth': 4, 'min_child_samples': 6, 'subsample': 0.8466750336320135, 'colsample_bytree': 0.6014204964030061, 'reg_alpha': 0.055257557199056374, 'reg_lambda': 0.007681427482946739}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:23,840] Trial 22 finished with value: 0.6649874055415617 and parameters: {'learning_rate': 0.03527596516347506, 'num_leaves': 27, 'max_depth': 4, 'min_child_samples': 18, 'subsample': 0.8243030075238683, 'colsample_bytree': 0.6022157505155247, 'reg_alpha': 0.7701307357068063, 'reg_lambda': 0.0001291525058126392}. Best is trial 8 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:50:24,791] Trial 23 finished with value: 0.6873385012919897 and parameters: {'learning_rate': 0.07695074516306853, 'num_leaves': 39, 'max_depth': 3, 'min_child_samples': 30, 'subsample': 0.8915856859820709, 'colsample_bytree': 0.6497439382521284, 'reg_alpha': 0.018342465397323954, 'reg_lambda': 0.0014512535195673494}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:25,510] Trial 24 finished with value: 0.6814404432132964 and parameters: {'learning_rate': 0.07968175904152103, 'num_leaves': 40, 'max_depth': 5, 'min_child_samples': 30, 'subsample': 0.8919585475366564, 'colsample_bytree': 0.650322804079651, 'reg_alpha': 0.00011350068959882118, 'reg_lambda': 0.0313454717161185}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:26,165] Trial 25 finished with value: 0.6714628297362111 and parameters: {'learning_rate': 0.07717274770351905, 'num_leaves': 41, 'max_depth': 5, 'min_child_samples': 45, 'subsample': 0.908505094399216, 'colsample_bytree': 0.6641685699964797, 'reg_alpha': 5.936357494463923e-05, 'reg_lambda': 0.034458070707686736}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:26,858] Trial 26 finished with value: 0.6516290726817042 and parameters: {'learning_rate': 0.08141112089767363, 'num_leaves': 55, 'max_depth': 5, 'min_child_samples': 39, 'subsample': 0.9266233039684479, 'colsample_bytree': 0.657197661445815, 'reg_alpha': 7.92439954758859e-05, 'reg_lambda': 0.041247393307996885}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:27,611] Trial 27 finished with value: 0.6785714285714286 and parameters: {'learning_rate': 0.07758314767954856, 'num_leaves': 41, 'max_depth': 6, 'min_child_samples': 25, 'subsample': 0.8761878290006878, 'colsample_bytree': 0.7084019894325848, 'reg_alpha': 7.052290381819405e-05, 'reg_lambda': 0.004597793222800884}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:28,531] Trial 28 finished with value: 0.6631853785900783 and parameters: {'learning_rate': 0.08683243156132911, 'num_leaves': 44, 'max_depth': 6, 'min_child_samples': 24, 'subsample': 0.8850469639842788, 'colsample_bytree': 0.7135360312322311, 'reg_alpha': 4.970930160558407e-07, 'reg_lambda': 0.0008172190735051698}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:31,259] Trial 29 finished with value: 0.665158371040724 and parameters: {'learning_rate': 0.011456829448409617, 'num_leaves': 50, 'max_depth': 6, 'min_child_samples': 26, 'subsample': 0.864521461920151, 'colsample_bytree': 0.6464947309015497, 'reg_alpha': 3.0567159790281545e-07, 'reg_lambda': 0.0037418690679014857}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:31,907] Trial 30 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.07397730315603229, 'num_leaves': 39, 'max_depth': 4, 'min_child_samples': 38, 'subsample': 0.9409037804069234, 'colsample_bytree': 0.6982874068463313, 'reg_alpha': 0.0016169940491926572, 'reg_lambda': 0.007214718745705337}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:32,469] Trial 31 finished with value: 0.6721763085399449 and parameters: {'learning_rate': 0.09717417534876052, 'num_leaves': 41, 'max_depth': 5, 'min_child_samples': 33, 'subsample': 0.957910261422387, 'colsample_bytree': 0.6735178397155452, 'reg_alpha': 8.131755205068654e-05, 'reg_lambda': 0.027253833734812577}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:33,169] Trial 32 finished with value: 0.6863270777479893 and parameters: {'learning_rate': 0.08545921842465107, 'num_leaves': 52, 'max_depth': 7, 'min_child_samples': 32, 'subsample': 0.9589995683405819, 'colsample_bytree': 0.63320146900325, 'reg_alpha': 6.525470946014419e-05, 'reg_lambda': 0.3656161640954137}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:34,178] Trial 33 finished with value: 0.6449704142011834 and parameters: {'learning_rate': 0.0579891566982289, 'num_leaves': 52, 'max_depth': 7, 'min_child_samples': 18, 'subsample': 0.9216332613977852, 'colsample_bytree': 0.6335085438164212, 'reg_alpha': 1.6693326875767425e-06, 'reg_lambda': 1.018475554547957}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:35,195] Trial 34 finished with value: 0.6428571428571429 and parameters: {'learning_rate': 0.0699074870472249, 'num_leaves': 48, 'max_depth': 6, 'min_child_samples': 27, 'subsample': 0.9707572747078028, 'colsample_bytree': 0.62632392043386, 'reg_alpha': 0.0013249217750382915, 'reg_lambda': 0.20047463306074376}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:36,089] Trial 35 finished with value: 0.6558265582655827 and parameters: {'learning_rate': 0.0858509780530546, 'num_leaves': 63, 'max_depth': 6, 'min_child_samples': 40, 'subsample': 0.9990973037944475, 'colsample_bytree': 0.7402233375832836, 'reg_alpha': 2.954069032340514e-05, 'reg_lambda': 3.1085016792999824}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:37,007] Trial 36 finished with value: 0.6561085972850679 and parameters: {'learning_rate': 0.06145764601705688, 'num_leaves': 53, 'max_depth': 7, 'min_child_samples': 53, 'subsample': 0.8703571112301961, 'colsample_bytree': 0.703232348658638, 'reg_alpha': 3.4909088259347894e-06, 'reg_lambda': 0.23543812110015908}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:38,009] Trial 37 finished with value: 0.665 and parameters: {'learning_rate': 0.05015970977551262, 'num_leaves': 59, 'max_depth': 4, 'min_child_samples': 13, 'subsample': 0.9117852311379705, 'colsample_bytree': 0.639028450186496, 'reg_alpha': 0.00017005402680154308, 'reg_lambda': 0.0033556245171528706}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:38,587] Trial 38 finished with value: 0.6550868486352357 and parameters: {'learning_rate': 0.0777826115965868, 'num_leaves': 38, 'max_depth': 5, 'min_child_samples': 58, 'subsample': 0.9500868127133079, 'colsample_bytree': 0.7755908492482599, 'reg_alpha': 0.00041649067496881434, 'reg_lambda': 0.00037304369479198}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:39,411] Trial 39 finished with value: 0.6829268292682927 and parameters: {'learning_rate': 0.0631173729295851, 'num_leaves': 46, 'max_depth': 6, 'min_child_samples': 20, 'subsample': 0.8196035704583003, 'colsample_bytree': 0.6835035381756215, 'reg_alpha': 0.00932697841659977, 'reg_lambda': 0.07196879094912763}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:40,208] Trial 40 finished with value: 0.6682134570765661 and parameters: {'learning_rate': 0.062238225984662096, 'num_leaves': 70, 'max_depth': 3, 'min_child_samples': 83, 'subsample': 0.8108441018748754, 'colsample_bytree': 0.6797560961023162, 'reg_alpha': 0.005638040175240175, 'reg_lambda': 1.7719243899991532}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:40,893] Trial 41 finished with value: 0.6609686609686609 and parameters: {'learning_rate': 0.08827904080425211, 'num_leaves': 45, 'max_depth': 6, 'min_child_samples': 21, 'subsample': 0.8674042918294093, 'colsample_bytree': 0.6227037509368296, 'reg_alpha': 0.010670798232860657, 'reg_lambda': 0.05795552603401066}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:41,582] Trial 42 finished with value: 0.6543535620052771 and parameters: {'learning_rate': 0.07041628335804959, 'num_leaves': 47, 'max_depth': 7, 'min_child_samples': 35, 'subsample': 0.886129970791811, 'colsample_bytree': 0.6545687420646568, 'reg_alpha': 0.0009150325428904467, 'reg_lambda': 0.013049170922697797}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:42,321] Trial 43 finished with value: 0.6649746192893401 and parameters: {'learning_rate': 0.08003611306132559, 'num_leaves': 50, 'max_depth': 5, 'min_child_samples': 28, 'subsample': 0.7846926730672882, 'colsample_bytree': 0.7193096223450748, 'reg_alpha': 2.9042077071649553e-05, 'reg_lambda': 0.5148493861062445}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:43,101] Trial 44 finished with value: 0.6365795724465558 and parameters: {'learning_rate': 0.09903227472892177, 'num_leaves': 37, 'max_depth': 6, 'min_child_samples': 11, 'subsample': 0.852707119667568, 'colsample_bytree': 0.6948686677111688, 'reg_alpha': 0.014290347024488633, 'reg_lambda': 0.1232536291572126}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:44,261] Trial 45 finished with value: 0.6589861751152074 and parameters: {'learning_rate': 0.06475887233222251, 'num_leaves': 80, 'max_depth': 8, 'min_child_samples': 19, 'subsample': 0.8203883490032815, 'colsample_bytree': 0.625532518286149, 'reg_alpha': 0.00015174928003769533, 'reg_lambda': 0.0032506493810228044}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:45,166] Trial 46 finished with value: 0.6522781774580336 and parameters: {'learning_rate': 0.07223757552578003, 'num_leaves': 43, 'max_depth': 12, 'min_child_samples': 44, 'subsample': 0.9071647123368594, 'colsample_bytree': 0.6749689248808205, 'reg_alpha': 3.7142984516030084e-06, 'reg_lambda': 9.084406232179477}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:45,954] Trial 47 finished with value: 0.6571428571428571 and parameters: {'learning_rate': 0.05487509424246707, 'num_leaves': 61, 'max_depth': 6, 'min_child_samples': 28, 'subsample': 0.9386579184808567, 'colsample_bytree': 0.730651565344586, 'reg_alpha': 0.003673389502726434, 'reg_lambda': 0.01640573074605089}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:46,747] Trial 48 finished with value: 0.6359223300970874 and parameters: {'learning_rate': 0.08939472339719223, 'num_leaves': 35, 'max_depth': 7, 'min_child_samples': 15, 'subsample': 0.9745004927688867, 'colsample_bytree': 0.6469560602401896, 'reg_alpha': 1.6320299333162033e-05, 'reg_lambda': 0.08259524262837463}. Best is trial 23 with value: 0.6873385012919897.\n",
      "[I 2025-10-17 00:50:48,074] Trial 49 finished with value: 0.6685393258426966 and parameters: {'learning_rate': 0.028770726553603448, 'num_leaves': 40, 'max_depth': 3, 'min_child_samples': 36, 'subsample': 0.7137462688779872, 'colsample_bytree': 0.7591918366116202, 'reg_alpha': 0.26129425323647354, 'reg_lambda': 0.0004204857852202928}. Best is trial 23 with value: 0.6873385012919897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial for LightGBM:\n",
      "  Value (Best F1 Score): 0.6873385012919897\n",
      "  Best Params: \n",
      "    learning_rate: 0.07695074516306853\n",
      "    num_leaves: 39\n",
      "    max_depth: 3\n",
      "    min_child_samples: 30\n",
      "    subsample: 0.8915856859820709\n",
      "    colsample_bytree: 0.6497439382521284\n",
      "    reg_alpha: 0.018342465397323954\n",
      "    reg_lambda: 0.0014512535195673494\n"
     ]
    }
   ],
   "source": [
    "NFOLDS = 5\n",
    "\n",
    "params_base = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'n_estimators': 1000,\n",
    "        'is_unbalance': True,  # 成功した設定は維持\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "def objective_lightgbm(trial):\n",
    "    # パラメータの探索範囲を定義\n",
    "    params_opt = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 80),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "    }\n",
    "    params = params_base | params_opt\n",
    "\n",
    "    # 交差検証ループ\n",
    "    oof_preds_trial = np.zeros(train_df.shape[0])\n",
    "    folds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "        X_valid_fold, y_valid_fold = X_train.iloc[valid_idx], y_train.iloc[valid_idx]\n",
    "\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(X_train_fold, y_train_fold,\n",
    "                  eval_set=[(X_valid_fold, y_valid_fold)],\n",
    "                  callbacks=[lgb.early_stopping(50, verbose=False)])\n",
    "\n",
    "        oof_preds_trial[valid_idx] = model.predict_proba(X_valid_fold)[:, 1]\n",
    "    \n",
    "    # このトライアルでの最適なF1スコアを閾値探索で見つける\n",
    "    thresholds = np.arange(0.1, 0.5, 0.01)\n",
    "    f1_scores = [f1_score(y_train, (oof_preds_trial > t).astype(int)) for t in thresholds]\n",
    "    \n",
    "    return np.max(f1_scores)\n",
    "\n",
    "# # --- 最適化を実行する場合 (時間がかかることがあります) ---\n",
    "study_lightgbm = optuna.create_study(direction='maximize')\n",
    "study_lightgbm.optimize(objective_lightgbm, n_trials=50) # 50回の試行で探索\n",
    "\n",
    "print('Best trial for LightGBM:')\n",
    "trial_lightgbm = study_lightgbm.best_trial\n",
    "print(f'  Value (Best F1 Score): {trial_lightgbm.value}')\n",
    "print('  Best Params: ')\n",
    "for key, value in trial_lightgbm.params.items():\n",
    "    print(f'    {key}: {value}')\n",
    "\n",
    "best_params_lightgbm = params_base | trial_lightgbm.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10a71c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary',\n",
       " 'metric': 'binary_logloss',\n",
       " 'n_estimators': 1000,\n",
       " 'is_unbalance': True,\n",
       " 'random_state': 42,\n",
       " 'n_jobs': -1,\n",
       " 'verbose': -1,\n",
       " 'learning_rate': 0.07695074516306853,\n",
       " 'num_leaves': 39,\n",
       " 'max_depth': 3,\n",
       " 'min_child_samples': 30,\n",
       " 'subsample': 0.8915856859820709,\n",
       " 'colsample_bytree': 0.6497439382521284,\n",
       " 'reg_alpha': 0.018342465397323954,\n",
       " 'reg_lambda': 0.0014512535195673494}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0bd79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=43, state=1, values=[0.6852791878172588], datetime_start=datetime.datetime(2025, 10, 17, 0, 23, 5, 156096), datetime_complete=datetime.datetime(2025, 10, 17, 0, 23, 5, 997304), params={'learning_rate': 0.049226097491479354, 'num_leaves': 24, 'max_depth': 4, 'min_child_samples': 35, 'subsample': 0.9766010179115259, 'colsample_bytree': 0.9743416839508543, 'reg_alpha': 4.6044002895687174e-08, 'reg_lambda': 0.0006790440644320187}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.1, log=True, low=0.01, step=None), 'num_leaves': IntDistribution(high=80, log=False, low=20, step=1), 'max_depth': IntDistribution(high=12, log=False, low=3, step=1), 'min_child_samples': IntDistribution(high=100, log=False, low=5, step=1), 'subsample': FloatDistribution(high=1.0, log=False, low=0.6, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.6, step=None), 'reg_alpha': FloatDistribution(high=10.0, log=True, low=1e-08, step=None), 'reg_lambda': FloatDistribution(high=10.0, log=True, low=1e-08, step=None)}, trial_id=43, value=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best trial:\n",
    "  Value (Best F1 Score): 0.6852791878172588\n",
    "  Best Params: \n",
    "    learning_rate: 0.049226097491479354\n",
    "    num_leaves: 24\n",
    "    max_depth: 4\n",
    "    min_child_samples: 35\n",
    "    subsample: 0.9766010179115259\n",
    "    colsample_bytree: 0.9743416839508543\n",
    "    reg_alpha: 4.6044002895687174e-08\n",
    "    reg_lambda: 0.0006790440644320187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2491985f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-17 00:52:14,062] A new study created in memory with name: no-name-946674c9-376d-4c76-b6b8-757f624bbdda\n",
      "[I 2025-10-17 00:52:25,075] Trial 0 finished with value: 0.5747126436781609 and parameters: {'learning_rate': 0.018423847690538526, 'depth': 9, 'min_data_in_leaf': 66, 'subsample': 0.9521487048759372, 'l2_leaf_reg': 2.4858460314250773e-08}. Best is trial 0 with value: 0.5747126436781609.\n",
      "[I 2025-10-17 00:52:29,042] Trial 1 finished with value: 0.6582278481012658 and parameters: {'learning_rate': 0.039858000909430626, 'depth': 4, 'min_data_in_leaf': 67, 'subsample': 0.8513048227639659, 'l2_leaf_reg': 6.014034306844379}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:52:43,902] Trial 2 finished with value: 0.6368159203980099 and parameters: {'learning_rate': 0.05792108705590046, 'depth': 9, 'min_data_in_leaf': 88, 'subsample': 0.6815510882022893, 'l2_leaf_reg': 0.4130198022189027}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:53:05,949] Trial 3 finished with value: 0.5759162303664922 and parameters: {'learning_rate': 0.03510326020734444, 'depth': 10, 'min_data_in_leaf': 53, 'subsample': 0.6826377878357996, 'l2_leaf_reg': 2.687840771883139e-06}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:53:15,243] Trial 4 finished with value: 0.5348837209302325 and parameters: {'learning_rate': 0.037911632526819894, 'depth': 9, 'min_data_in_leaf': 33, 'subsample': 0.7971740670768848, 'l2_leaf_reg': 1.8326321576602733e-07}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:53:34,242] Trial 5 finished with value: 0.5343811394891945 and parameters: {'learning_rate': 0.04653112491118769, 'depth': 10, 'min_data_in_leaf': 25, 'subsample': 0.9444281960488955, 'l2_leaf_reg': 1.0666193570783481e-06}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:53:37,641] Trial 6 finished with value: 0.6550868486352357 and parameters: {'learning_rate': 0.04038345570001488, 'depth': 4, 'min_data_in_leaf': 17, 'subsample': 0.8840878303905424, 'l2_leaf_reg': 0.28188831181229107}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:53:40,582] Trial 7 finished with value: 0.6294416243654822 and parameters: {'learning_rate': 0.03193767314611346, 'depth': 3, 'min_data_in_leaf': 22, 'subsample': 0.9122122665373196, 'l2_leaf_reg': 0.0015803782949780458}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:53:45,559] Trial 8 finished with value: 0.6391184573002755 and parameters: {'learning_rate': 0.014622491939880796, 'depth': 6, 'min_data_in_leaf': 38, 'subsample': 0.8918221316048195, 'l2_leaf_reg': 1.2993303558646107e-07}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:53:48,112] Trial 9 finished with value: 0.5934959349593496 and parameters: {'learning_rate': 0.031982755170511856, 'depth': 5, 'min_data_in_leaf': 38, 'subsample': 0.6758922324953682, 'l2_leaf_reg': 2.702070309074827e-07}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:53:55,485] Trial 10 finished with value: 0.6542553191489362 and parameters: {'learning_rate': 0.07893455077856963, 'depth': 7, 'min_data_in_leaf': 89, 'subsample': 0.7864021807789594, 'l2_leaf_reg': 4.464986073401033}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:54:00,263] Trial 11 finished with value: 0.6433915211970075 and parameters: {'learning_rate': 0.020155001255113915, 'depth': 3, 'min_data_in_leaf': 6, 'subsample': 0.8618182420480848, 'l2_leaf_reg': 0.04415282708168859}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:54:02,985] Trial 12 finished with value: 0.6553398058252428 and parameters: {'learning_rate': 0.0993080353954933, 'depth': 4, 'min_data_in_leaf': 71, 'subsample': 0.9989771435420421, 'l2_leaf_reg': 9.92869368169427}. Best is trial 1 with value: 0.6582278481012658.\n",
      "[I 2025-10-17 00:54:06,276] Trial 13 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.09809307263372187, 'depth': 5, 'min_data_in_leaf': 71, 'subsample': 0.9976081106479759, 'l2_leaf_reg': 5.362052332712974}. Best is trial 13 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:54:08,719] Trial 14 finished with value: 0.5676392572944297 and parameters: {'learning_rate': 0.06345269442009524, 'depth': 6, 'min_data_in_leaf': 72, 'subsample': 0.7339178963421698, 'l2_leaf_reg': 0.0009170386911305068}. Best is trial 13 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:54:13,712] Trial 15 finished with value: 0.6387434554973822 and parameters: {'learning_rate': 0.02461022195236975, 'depth': 5, 'min_data_in_leaf': 54, 'subsample': 0.8405141547550226, 'l2_leaf_reg': 0.012897860122533538}. Best is trial 13 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:54:20,527] Trial 16 finished with value: 0.6093023255813953 and parameters: {'learning_rate': 0.010298865112750905, 'depth': 7, 'min_data_in_leaf': 95, 'subsample': 0.6165857035803493, 'l2_leaf_reg': 5.2481469432835636e-05}. Best is trial 13 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:54:23,052] Trial 17 finished with value: 0.6338028169014085 and parameters: {'learning_rate': 0.0976178236673965, 'depth': 5, 'min_data_in_leaf': 80, 'subsample': 0.9993640739229591, 'l2_leaf_reg': 0.8467441646721866}. Best is trial 13 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:54:25,757] Trial 18 finished with value: 0.631578947368421 and parameters: {'learning_rate': 0.05269211622437583, 'depth': 4, 'min_data_in_leaf': 59, 'subsample': 0.8238459667087487, 'l2_leaf_reg': 0.016553344609684457}. Best is trial 13 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:54:27,392] Trial 19 finished with value: 0.6153846153846154 and parameters: {'learning_rate': 0.07555412923392844, 'depth': 3, 'min_data_in_leaf': 78, 'subsample': 0.7682677952118993, 'l2_leaf_reg': 4.227783010704926e-05}. Best is trial 13 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:54:37,243] Trial 20 finished with value: 0.6597938144329897 and parameters: {'learning_rate': 0.02375526500531929, 'depth': 6, 'min_data_in_leaf': 100, 'subsample': 0.9497783587594637, 'l2_leaf_reg': 1.8418531876469617}. Best is trial 13 with value: 0.6666666666666666.\n",
      "[I 2025-10-17 00:54:45,912] Trial 21 finished with value: 0.6701030927835051 and parameters: {'learning_rate': 0.025063357484826267, 'depth': 6, 'min_data_in_leaf': 99, 'subsample': 0.9504455908968431, 'l2_leaf_reg': 1.8912349938338942}. Best is trial 21 with value: 0.6701030927835051.\n",
      "[I 2025-10-17 00:54:53,860] Trial 22 finished with value: 0.6428571428571429 and parameters: {'learning_rate': 0.024647673478947623, 'depth': 7, 'min_data_in_leaf': 100, 'subsample': 0.9544605432267698, 'l2_leaf_reg': 0.11923634278988784}. Best is trial 21 with value: 0.6701030927835051.\n",
      "[I 2025-10-17 00:55:01,014] Trial 23 finished with value: 0.6504065040650406 and parameters: {'learning_rate': 0.027391319872366714, 'depth': 6, 'min_data_in_leaf': 88, 'subsample': 0.9305364142798608, 'l2_leaf_reg': 0.9584119604075167}. Best is trial 21 with value: 0.6701030927835051.\n",
      "[I 2025-10-17 00:55:25,911] Trial 24 finished with value: 0.6385809312638581 and parameters: {'learning_rate': 0.016505193111779323, 'depth': 8, 'min_data_in_leaf': 98, 'subsample': 0.9817936718442396, 'l2_leaf_reg': 1.6163430354077233}. Best is trial 21 with value: 0.6701030927835051.\n",
      "[I 2025-10-17 00:55:33,125] Trial 25 finished with value: 0.6737967914438503 and parameters: {'learning_rate': 0.012893567859358891, 'depth': 5, 'min_data_in_leaf': 83, 'subsample': 0.9700324489092532, 'l2_leaf_reg': 0.004589013293714057}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:55:40,744] Trial 26 finished with value: 0.659217877094972 and parameters: {'learning_rate': 0.011674304211620216, 'depth': 5, 'min_data_in_leaf': 80, 'subsample': 0.97237054670164, 'l2_leaf_reg': 0.00483682420319681}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:55:48,856] Trial 27 finished with value: 0.6470588235294118 and parameters: {'learning_rate': 0.012940299529104082, 'depth': 5, 'min_data_in_leaf': 85, 'subsample': 0.913570091767838, 'l2_leaf_reg': 0.0662854690884104}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:55:56,883] Trial 28 finished with value: 0.6117021276595744 and parameters: {'learning_rate': 0.015114717322585167, 'depth': 8, 'min_data_in_leaf': 61, 'subsample': 0.8996973513518466, 'l2_leaf_reg': 0.000100806990181624}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:56:03,376] Trial 29 finished with value: 0.5764966740576497 and parameters: {'learning_rate': 0.01931357417969139, 'depth': 8, 'min_data_in_leaf': 74, 'subsample': 0.9696105965081774, 'l2_leaf_reg': 6.851532932379381e-06}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:56:09,320] Trial 30 finished with value: 0.6153846153846154 and parameters: {'learning_rate': 0.01258656712078224, 'depth': 6, 'min_data_in_leaf': 63, 'subsample': 0.9236211166453652, 'l2_leaf_reg': 0.0003384924720023078}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:56:19,195] Trial 31 finished with value: 0.6617283950617284 and parameters: {'learning_rate': 0.0227545992565256, 'depth': 6, 'min_data_in_leaf': 95, 'subsample': 0.9571487490248246, 'l2_leaf_reg': 3.105325803108103}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:56:28,343] Trial 32 finished with value: 0.6603325415676959 and parameters: {'learning_rate': 0.020232114625055943, 'depth': 5, 'min_data_in_leaf': 93, 'subsample': 0.9714112707967877, 'l2_leaf_reg': 9.719349281453047}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:56:32,528] Trial 33 finished with value: 0.6494845360824743 and parameters: {'learning_rate': 0.028562553006324157, 'depth': 4, 'min_data_in_leaf': 83, 'subsample': 0.9391799609026484, 'l2_leaf_reg': 0.3663340087714565}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:56:51,193] Trial 34 finished with value: 0.6648648648648648 and parameters: {'learning_rate': 0.017281122457745386, 'depth': 7, 'min_data_in_leaf': 92, 'subsample': 0.9970720540766619, 'l2_leaf_reg': 2.3665702796733132}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:57:01,746] Trial 35 finished with value: 0.6575342465753424 and parameters: {'learning_rate': 0.016870463923877543, 'depth': 7, 'min_data_in_leaf': 90, 'subsample': 0.9926588487500948, 'l2_leaf_reg': 0.19874011948223985}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:57:13,682] Trial 36 finished with value: 0.6282722513089005 and parameters: {'learning_rate': 0.010339254873423995, 'depth': 7, 'min_data_in_leaf': 69, 'subsample': 0.9746135815611622, 'l2_leaf_reg': 0.013439337278936198}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:57:33,229] Trial 37 finished with value: 0.6509433962264151 and parameters: {'learning_rate': 0.01370265120896095, 'depth': 8, 'min_data_in_leaf': 76, 'subsample': 0.8787558015656529, 'l2_leaf_reg': 0.525359485717566}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:57:52,079] Trial 38 finished with value: 0.6473684210526316 and parameters: {'learning_rate': 0.01738219398988785, 'depth': 9, 'min_data_in_leaf': 85, 'subsample': 0.9331481300040508, 'l2_leaf_reg': 0.07245624264407526}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:57:55,384] Trial 39 finished with value: 0.672316384180791 and parameters: {'learning_rate': 0.04197116292981179, 'depth': 5, 'min_data_in_leaf': 66, 'subsample': 0.8650832463826937, 'l2_leaf_reg': 0.003522994506949654}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:57:58,397] Trial 40 finished with value: 0.631578947368421 and parameters: {'learning_rate': 0.04186641305273787, 'depth': 5, 'min_data_in_leaf': 66, 'subsample': 0.8648708744582574, 'l2_leaf_reg': 0.0030745987470795497}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:58:02,947] Trial 41 finished with value: 0.6263736263736264 and parameters: {'learning_rate': 0.046650799540280015, 'depth': 6, 'min_data_in_leaf': 44, 'subsample': 0.9059237496552369, 'l2_leaf_reg': 0.0313546536400084}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:58:05,497] Trial 42 finished with value: 0.6165413533834586 and parameters: {'learning_rate': 0.03621913958244908, 'depth': 5, 'min_data_in_leaf': 49, 'subsample': 0.9564223448409186, 'l2_leaf_reg': 0.0003704551041285099}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:58:08,439] Trial 43 finished with value: 0.6572769953051644 and parameters: {'learning_rate': 0.06929265047405161, 'depth': 4, 'min_data_in_leaf': 92, 'subsample': 0.8301294141288038, 'l2_leaf_reg': 2.808022191777718}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:58:12,919] Trial 44 finished with value: 0.6217616580310881 and parameters: {'learning_rate': 0.02179926287283071, 'depth': 6, 'min_data_in_leaf': 57, 'subsample': 0.9834655950803188, 'l2_leaf_reg': 0.002946918715433291}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:58:17,182] Trial 45 finished with value: 0.6596858638743456 and parameters: {'learning_rate': 0.028039088925839156, 'depth': 4, 'min_data_in_leaf': 85, 'subsample': 0.9216686962266236, 'l2_leaf_reg': 0.2248298983820473}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:58:19,029] Trial 46 finished with value: 0.5776699029126213 and parameters: {'learning_rate': 0.08464751314679786, 'depth': 5, 'min_data_in_leaf': 74, 'subsample': 0.999479674795856, 'l2_leaf_reg': 1.840669435528615e-08}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:58:22,399] Trial 47 finished with value: 0.5435684647302904 and parameters: {'learning_rate': 0.05566507202286371, 'depth': 7, 'min_data_in_leaf': 64, 'subsample': 0.8812713208737369, 'l2_leaf_reg': 6.692182351001453e-06}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:58:27,579] Trial 48 finished with value: 0.6408839779005525 and parameters: {'learning_rate': 0.015428356148300194, 'depth': 6, 'min_data_in_leaf': 81, 'subsample': 0.8096173062334631, 'l2_leaf_reg': 0.0008008010913296667}. Best is trial 25 with value: 0.6737967914438503.\n",
      "[I 2025-10-17 00:58:50,531] Trial 49 finished with value: 0.5754985754985755 and parameters: {'learning_rate': 0.03346837247792573, 'depth': 10, 'min_data_in_leaf': 89, 'subsample': 0.716177751060012, 'l2_leaf_reg': 0.007024444921988573}. Best is trial 25 with value: 0.6737967914438503.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial for CatBoost:\n",
      "  Value (Best F1 Score): 0.6737967914438503\n",
      "  Best Params: \n",
      "    learning_rate: 0.012893567859358891\n",
      "    depth: 5\n",
      "    min_data_in_leaf: 83\n",
      "    subsample: 0.9700324489092532\n",
      "    l2_leaf_reg: 0.004589013293714057\n"
     ]
    }
   ],
   "source": [
    "NFOLDS = 5\n",
    "\n",
    "params_base = {\n",
    "        'objective': 'Logloss', # CatBoostでは'Logloss'を指定\n",
    "        'iterations': 1000,\n",
    "        'scale_pos_weight': (y_train == 0).sum() / (y_train == 1).sum(), # 不均衡データへの対処\n",
    "        'random_seed': 42,\n",
    "        'verbose': 0, # 学習ログを非表示\n",
    "        'early_stopping_rounds': 50 # 早期停止\n",
    "    }\n",
    "\n",
    "def objective_catboost(trial):\n",
    "    # 不均衡データ対策のための重みを計算\n",
    "\n",
    "    # パラメータの探索範囲を定義\n",
    "    params_opt = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True), # L2正則化\n",
    "    }\n",
    "\n",
    "    params = params_base | params_opt\n",
    "\n",
    "    # 交差検証ループ\n",
    "    oof_preds_trial = np.zeros(train_df.shape[0])\n",
    "    folds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "        X_valid_fold, y_valid_fold = X_train.iloc[valid_idx], y_train.iloc[valid_idx]\n",
    "\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(X_train_fold, y_train_fold,\n",
    "                  eval_set=[(X_valid_fold, y_valid_fold)],\n",
    "                  use_best_model=True)\n",
    "\n",
    "        oof_preds_trial[valid_idx] = model.predict_proba(X_valid_fold)[:, 1]\n",
    "    \n",
    "    # このトライアルでの最適なF1スコアを閾値探索で見つける\n",
    "    thresholds = np.arange(0.1, 0.5, 0.01)\n",
    "    f1_scores = [f1_score(y_train, (oof_preds_trial > t).astype(int)) for t in thresholds]\n",
    "    \n",
    "    return np.max(f1_scores)\n",
    "\n",
    "study_catboost = optuna.create_study(direction='maximize')\n",
    "study_catboost.optimize(objective_catboost, n_trials=50) # 50回の試行で探索\n",
    "\n",
    "print('Best trial for CatBoost:')\n",
    "trial_catboost = study_catboost.best_trial\n",
    "print(f'  Value (Best F1 Score): {trial_catboost.value}')\n",
    "print('  Best Params: ')\n",
    "for key, value in trial_catboost.params.items():\n",
    "    print(f'    {key}: {value}')\n",
    "\n",
    "best_params_catboost = params_base | trial_catboost.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0224d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.049226097491479354,\n",
       " 'num_leaves': 24,\n",
       " 'max_depth': 4,\n",
       " 'min_child_samples': 35,\n",
       " 'subsample': 0.9766010179115259,\n",
       " 'colsample_bytree': 0.9743416839508543,\n",
       " 'reg_alpha': 4.6044002895687174e-08,\n",
       " 'reg_lambda': 0.0006790440644320187}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best trial for CatBoost:\n",
    "  Value (Best F1 Score): 0.685\n",
    "  Best Params: \n",
    "    learning_rate: 0.01506366663492991\n",
    "    depth: 4\n",
    "    min_data_in_leaf: 93\n",
    "    subsample: 0.7518354099061272\n",
    "    l2_leaf_reg: 0.07096168454986888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d856c024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting LightGBM and CatBoost Training ---\n",
      "Fold 1 finished.\n",
      "Fold 2 finished.\n",
      "Fold 3 finished.\n",
      "Fold 4 finished.\n",
      "Fold 5 finished.\n",
      "\n",
      "--- Training Finished ---\n",
      "----------------------------------------\n",
      "LightGBM単体のOOF F1スコア (参考): 0.6793\n",
      "CatBoost単体のOOF F1スコア (参考): 0.6590\n",
      "----------------------------------------\n",
      "アンサンブルモデルのベストOOF F1スコア: 0.6856\n",
      "アンサンブルモデルの最適閾値: 0.49\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- 交差検証の準備 ---\n",
    "NFOLDS = 5\n",
    "folds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# OOF予測値とテストデータ予測値を格納する配列を初期化\n",
    "oof_preds_lgbm = np.zeros(train_df.shape[0])\n",
    "sub_preds_lgbm = np.zeros(test_df.shape[0])\n",
    "oof_preds_cat = np.zeros(train_df.shape[0])\n",
    "sub_preds_cat = np.zeros(test_df.shape[0])\n",
    "\n",
    "\n",
    "# --- モデル学習ループ ---\n",
    "print(\"--- Starting LightGBM and CatBoost Training ---\")\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_valid_fold, y_valid_fold = X_train.iloc[valid_idx], y_train.iloc[valid_idx]\n",
    "\n",
    "    # --- LightGBMの学習 ---\n",
    "    lgbm = lgb.LGBMClassifier(**best_params_lightgbm)\n",
    "    lgbm.fit(X_train_fold, y_train_fold,\n",
    "             eval_set=[(X_valid_fold, y_valid_fold)],\n",
    "             callbacks=[lgb.early_stopping(50, verbose=False)])\n",
    "    oof_preds_lgbm[valid_idx] = lgbm.predict_proba(X_valid_fold)[:, 1]\n",
    "    sub_preds_lgbm += lgbm.predict_proba(X_test)[:, 1] / folds.n_splits\n",
    "\n",
    "    # --- CatBoostの学習 ---\n",
    "    cat = CatBoostClassifier(**best_params_catboost)\n",
    "    cat.fit(X_train_fold, y_train_fold,\n",
    "            eval_set=[(X_valid_fold, y_valid_fold)],\n",
    "            use_best_model=True,\n",
    "            verbose=0)\n",
    "    oof_preds_cat[valid_idx] = cat.predict_proba(X_valid_fold)[:, 1]\n",
    "    sub_preds_cat += cat.predict_proba(X_test)[:, 1] / folds.n_splits\n",
    "    \n",
    "    print(f\"Fold {n_fold+1} finished.\")\n",
    "\n",
    "print(\"\\n--- Training Finished ---\")\n",
    "\n",
    "\n",
    "# --- アンサンブルと閾値最適化 ---\n",
    "# 2つのモデルのOOF予測値を単純平均\n",
    "ensemble_oof_preds = (oof_preds_lgbm + oof_preds_cat) / 2\n",
    "\n",
    "# 最適な閾値を探索\n",
    "thresholds = np.arange(0.1, 0.5, 0.01)\n",
    "f1_scores = [f1_score(y_train, (ensemble_oof_preds > t).astype(int)) for t in thresholds]\n",
    "best_threshold_ensemble = thresholds[np.argmax(f1_scores)]\n",
    "best_f1_ensemble = np.max(f1_scores)\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"LightGBM単体のOOF F1スコア (参考): {f1_score(y_train, (oof_preds_lgbm > best_threshold_ensemble).astype(int)):.4f}\")\n",
    "print(f\"CatBoost単体のOOF F1スコア (参考): {f1_score(y_train, (oof_preds_cat > best_threshold_ensemble).astype(int)):.4f}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"アンサンブルモデルのベストOOF F1スコア: {best_f1_ensemble:.4f}\")\n",
    "print(f\"アンサンブルモデルの最適閾値: {best_threshold_ensemble:.2f}\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191ceebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "アンサンブルモデルの提出ファイル 'submission_ensemble.csv' を作成しました。\n",
      "提出ファイルでの購入予測数: 174\n"
     ]
    }
   ],
   "source": [
    "# 提出ファイルの作成\n",
    "# テストデータに対する予測値も同様に平均\n",
    "ensemble_sub_preds = (sub_preds_lgbm + sub_preds_cat) / 2\n",
    "\n",
    "# 最適化された閾値を使って最終的な予測を決定\n",
    "predictions_ensemble = (ensemble_sub_preds > best_threshold_ensemble).astype(int)\n",
    "\n",
    "# 提出用DataFrameを作成\n",
    "submit_df_ensemble = sample_submit.copy()\n",
    "submit_df_ensemble[1] = predictions_ensemble\n",
    "submit_df_ensemble.to_csv('submission_ensemble.csv', index=False, header=False)\n",
    "\n",
    "print(\"\\nアンサンブルモデルの提出ファイル 'submission_ensemble.csv' を作成しました。\")\n",
    "print(f\"提出ファイルでの購入予測数: {np.sum(predictions_ensemble)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
